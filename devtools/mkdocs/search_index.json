{
    "docs": [
        {
            "location": "/",
            "text": "DevTools\n\n\nEasy containerized development environments based on Docker\n\n\nThe various projects within Phase2's DevTools ecosystem provide simple to manage\nproject environments for any technology and deployment architecture. These\nenvironments are based upon Docker and DevTools helps you tie the pieces\ntogether to provide:\n\n\n\n\nA Docker Machine based VM\n\n\nDNS services\n\n\nNetwork routing\n\n\nHigh speed filesystems\n\n\nPersistent data storage\n\n\n\n\nThe DevTools approach is to configure and use standard Docker tools. This allows\nyou the option to learn these tools when you want to and provides the\nflexibility to override or substitute components should it be necessary for your\nproject.\n\n\nIf you are brand new to DevTools and Docker, it is \nhighly recommended\n\nyou read the \nGlossary\n and\n\nArchitecture\n documents to get familiar with the\nconcepts and terminology used throughout this documentation.",
            "title": "Home"
        },
        {
            "location": "/#devtools",
            "text": "Easy containerized development environments based on Docker  The various projects within Phase2's DevTools ecosystem provide simple to manage\nproject environments for any technology and deployment architecture. These\nenvironments are based upon Docker and DevTools helps you tie the pieces\ntogether to provide:   A Docker Machine based VM  DNS services  Network routing  High speed filesystems  Persistent data storage   The DevTools approach is to configure and use standard Docker tools. This allows\nyou the option to learn these tools when you want to and provides the\nflexibility to override or substitute components should it be necessary for your\nproject.  If you are brand new to DevTools and Docker, it is  highly recommended \nyou read the  Glossary  and Architecture  documents to get familiar with the\nconcepts and terminology used throughout this documentation.",
            "title": "DevTools"
        },
        {
            "location": "/getting-started/system-requirements/",
            "text": "System Requirements\n\n\nHardware\n\n\nWe recommend 16 GB of RAM when working with containerization / virtualization. You can certainly\nget by with 8 GB but you may want to keep other applications to a minimum. It is also dependant on\nthe RAM configuration required if using virtualization. By default the DevTools Docker Host is\nconfigured to run with 4 GB of RAM.\n\n\nSoftware\n\n\nMac\n\n\nHomebrew\n is also required for package installation.\n\n\nFor Virtualization you can choose one of the following\n\n\n\n\nVirtualBox 5.0.20+\n (the default supported option)\n\n\nVMWare Fusion\n\n\nXhyve\n with \nDocker Machine Xhyve\n\n\n\n\nWindows\n\n\nVirtualBox is required.\n\n\nLinux\n\n\nDocker is required to be running as a system service.",
            "title": "System Requirements"
        },
        {
            "location": "/getting-started/system-requirements/#system-requirements",
            "text": "",
            "title": "System Requirements"
        },
        {
            "location": "/getting-started/system-requirements/#hardware",
            "text": "We recommend 16 GB of RAM when working with containerization / virtualization. You can certainly\nget by with 8 GB but you may want to keep other applications to a minimum. It is also dependant on\nthe RAM configuration required if using virtualization. By default the DevTools Docker Host is\nconfigured to run with 4 GB of RAM.",
            "title": "Hardware"
        },
        {
            "location": "/getting-started/system-requirements/#software",
            "text": "",
            "title": "Software"
        },
        {
            "location": "/getting-started/system-requirements/#mac",
            "text": "Homebrew  is also required for package installation.  For Virtualization you can choose one of the following   VirtualBox 5.0.20+  (the default supported option)  VMWare Fusion  Xhyve  with  Docker Machine Xhyve",
            "title": "Mac"
        },
        {
            "location": "/getting-started/system-requirements/#windows",
            "text": "VirtualBox is required.",
            "title": "Windows"
        },
        {
            "location": "/getting-started/system-requirements/#linux",
            "text": "Docker is required to be running as a system service.",
            "title": "Linux"
        },
        {
            "location": "/getting-started/mac-installation/",
            "text": "Installation\n\n\nMac Installation\n\n\nInstall VirtualBox\n\n\nVirtualBox Downloads\n\n\nInstall Homebrew\n\n\nHomebrew Website\n\n\nIf Homebrew is already installed, then be sure to do a \nbrew update\n \n\n\nTap the DevTools repository\n\n\nbrew tap phase2/devtools\n\n\nInstall DevTools (and dependencies)\n\n\nbrew install devtools\n\n\nThis will install the \ndevtools\n binary as well the Docker and other dependencies.\n\n\nCreate the Docker Host\n\n\nOnce everything checks out, run the following command to create a new docker host. \n(You will likely be prompted for your admin password)\n\n\ndevtools start\n\n\nHere are some configuration options available to you to customize your setup:\n\n\n\n\nname:\n The Docker Machine name for the VM. Defaults to \ndev\n\n\ndriver:\n The driver to create the Docker Machine with. Choices are:\n\n\nvirtualbox\n - default\n\n\nvmwarefusion\n\n\nxhyve\n\n\n\n\n\n\ncpuCount:\n The number of virtual CPU you want to allocate to this VM. Defaults to 2\n\n\nmemSize:\n The size memory you want to configure for this VM, in Megabytes. Defaults to 4096\n\n\ndiskSize:\n The size drive you want to configure for this VM, in Gigabytes. Defaults to 40\n\n\n\n\nConfigure your shell to set DevTools Docker environment\n\n\nTo configure the shell with the proper DevTools environment, run the following command\nafter the docker host has started from the previous step.\n\n\neval \"$(devtools config)\"\n\n\nFor convenience, you should make this automatic on every terminal you launch. To do that \nadd the following to your \n.bash_profile\n, \n.zshrc\n or equivalent:\n\n\n# Support for DevTools\neval \n$(devtools config)\n\nalias dte='eval \n$(devtools config)\n'\n\n\n\n\n\n\nRunning devtools config\n\n\nEven with automatic execution in your shell, this command must be run in any existing \nterminal windows after \ndevtools start\n or \ndevtools restart\n commands. To support that\nsee the \ndte\n alias in the shell init file above. Just run \ndte\n after a \ndevtools start\n\n\n\n\nSupport for Docker for Mac\n\n\nSee \nDocker for Mac Support",
            "title": "Mac Installation"
        },
        {
            "location": "/getting-started/mac-installation/#installation",
            "text": "",
            "title": "Installation"
        },
        {
            "location": "/getting-started/mac-installation/#mac-installation",
            "text": "",
            "title": "Mac Installation"
        },
        {
            "location": "/getting-started/mac-installation/#install-virtualbox",
            "text": "VirtualBox Downloads",
            "title": "Install VirtualBox"
        },
        {
            "location": "/getting-started/mac-installation/#install-homebrew",
            "text": "Homebrew Website  If Homebrew is already installed, then be sure to do a  brew update",
            "title": "Install Homebrew"
        },
        {
            "location": "/getting-started/mac-installation/#tap-the-devtools-repository",
            "text": "brew tap phase2/devtools",
            "title": "Tap the DevTools repository"
        },
        {
            "location": "/getting-started/mac-installation/#install-devtools-and-dependencies",
            "text": "brew install devtools  This will install the  devtools  binary as well the Docker and other dependencies.",
            "title": "Install DevTools (and dependencies)"
        },
        {
            "location": "/getting-started/mac-installation/#create-the-docker-host",
            "text": "Once everything checks out, run the following command to create a new docker host. \n(You will likely be prompted for your admin password)  devtools start  Here are some configuration options available to you to customize your setup:   name:  The Docker Machine name for the VM. Defaults to  dev  driver:  The driver to create the Docker Machine with. Choices are:  virtualbox  - default  vmwarefusion  xhyve    cpuCount:  The number of virtual CPU you want to allocate to this VM. Defaults to 2  memSize:  The size memory you want to configure for this VM, in Megabytes. Defaults to 4096  diskSize:  The size drive you want to configure for this VM, in Gigabytes. Defaults to 40",
            "title": "Create the Docker Host"
        },
        {
            "location": "/getting-started/mac-installation/#configure-your-shell-to-set-devtools-docker-environment",
            "text": "To configure the shell with the proper DevTools environment, run the following command\nafter the docker host has started from the previous step.  eval \"$(devtools config)\"  For convenience, you should make this automatic on every terminal you launch. To do that \nadd the following to your  .bash_profile ,  .zshrc  or equivalent:  # Support for DevTools\neval  $(devtools config) \nalias dte='eval  $(devtools config) '   Running devtools config  Even with automatic execution in your shell, this command must be run in any existing \nterminal windows after  devtools start  or  devtools restart  commands. To support that\nsee the  dte  alias in the shell init file above. Just run  dte  after a  devtools start",
            "title": "Configure your shell to set DevTools Docker environment"
        },
        {
            "location": "/getting-started/mac-installation/#support-for-docker-for-mac",
            "text": "See  Docker for Mac Support",
            "title": "Support for Docker for Mac"
        },
        {
            "location": "/getting-started/linux-installation/",
            "text": "Linux Installation\n\n\nWhen running Docker containers on Linux, it is not necessary to run the Docker Machine VM. The instructions here describe \nhow to run DevTools projects on Linux.\n\n\nLinux Requirements\n\n\n\n\nThe dnsdock container, used to support automatic creation and maintenance of DNS namespace for the containers\n\n\nUse of one of three options to forward DNS queries to the dnsdock container \n(see \nLinux DNS configuration options\n below)\n\n\n\n\nLinux installation on Fedora 22+\n\n\n\n\nInstall Docker 1.x.x and docker-compose\n\n\nsudo dnf install docker-engine docker-compose\n\n\n\n\n\n\nAdd your user to the Docker group\n\n\nsudo usermod -aG docker $USER\n\n\n\n\n\n\nLog out, then back in, in order to pick up your new group assignments\n\n\nSet the DNS configuration for dnsdock\n\n\nWe need to modify the command that docker uses within systemd\n\n\nsudo mkdir /etc/systemd/system/docker.service.d\n\n\nsudo vi /etc/systemd/system/docker.service.d/docker.conf\n\n\nIn that file put something like the following:  \n\n\n[Service]\n    ExecStart=\n    ExecStart=/usr/bin/dockerd -H fd:// --dns=172.17.0.1\n\n\n\n\n\n\nSet up the docker0 network as trusted\n\n\nsudo firewall-cmd --zone=trusted --add-interface=docker0 \n sudo firewall-cmd --zone=trusted --add-interface=docker0 --permanent\n\n\n\n\n\n\nStart the docker daemon\n\n\nsudo systemctl start docker\n\n\n\n\n\n\n\n\nLinux installation on Ubuntu/Linux Mint/Debian\n\n\n\n\nInstall Docker 1.x.x\n\n\nsudo apt-get install docker-engine\n\n\n\n\n\n\nInstall Pip\n\n\nsudo apt-get install python-pip\n\n\n\n\n\n\nInstall docker-compose\n\n\nsudo pip install docker-compose\n\n\n\n\n\n\nAdd your user to the Docker group\n\n\nsudo usermod -aG docker $USER\n\n\n\n\n\n\nLog out, then back in, in order to pick up your new group assignments\n\n\nSet the DNS configuration for dnsdock, as well as known RFC-1918 address space\n\n\nPlease note that the following command will over-write your existing Docker daemon configuration file.  Please \nset the -dns=172.17.0.1 option manually as an alternative\n\n\necho 'DOCKER_OPTS=\"-dns=172.17.0.1\"' | sudo tee /etc/default/docker\n\n\n\n\n\n\nStart the docker daemon\n\n\nsudo start docker\n\n\n\n\n\n\n\n\nLinux DNS configuration options\n\n\nMethod 1: dnsmasq via NetworkManager\n\n\nThis method works well with no other needed software provided that you have unfettered access to your system's \nconfiguration, and are using NetworkManager to maintain your networking stack\n\n\n\n\nAdd the line dns=dnsmasq to /etc/NetworkManager/NetworkManager.conf under the [main] configuration stanza. This will \ncause NetworkManager to spawn and use a dnsmasq process for all name resolution. If you already have a local configuration, \nensure that it is not configured to start on system boot.\n\n\nAdd a single rule to direct all DNS lookups for .vm addresses to the 172.17.0.1 address.\n\n\necho 'server=/vm/172.17.0.1' | sudo tee /etc/NetworkManager/dnsmasq.d/dnsdock.conf\n\n\n\n\n\n\nRestart NetworkManager, either through systemd, or by simply rebooting.  To restart via systemd:\n\n\nsystemctl restart NetworkManager\n\n\n\n\n\n\nRun the dnsdock container\n\n\ndocker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock aacebedo/dnsdock:latest-amd64 -domain=vm\n\n\nNote\n: if you want this container to run automatically when the docker daemon starts, add the \n--restart=always\n \nflag to the above command.\n\n\n\n\n\n\n\n\nMethod 2: dnsdock as main resolver\n\n\nThis method will probably only work well if this is a fixed computer or server with a consistent single upstream DNS \nserver. If you meet these criteria, you can very easily use this to set up .vm resolution for containers an delegate the \nrest to your normal DNS server.\n\n\nThis example assumes that the upstream DNS server for a Linux workstation is 192.168.0.1.\n\n\n\n\n\n\nRun the dnsdock container, specifying your upstream DNS server at the end.\n\n\n\n\ndocker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock aacebedo/dnsdock:latest-amd64 /opt/bin/dnsdock -domain=vm -nameserver=\"192.168.0.1:53\"\n\n\nNote\n: if you want this container to run automatically when the docker daemon starts, add the \n--restart=always\n \nflag to the above command.\n\n\n\n\n\n\n\n\nConfigure 172.17.0.1 as your first DNS resolver in your network configuration. The method for doing this may differ \nbased on whether you are using a desktop environment or running Linux on a server, but that nameserver should end up as \nthe first 'nameserver' line in your /etc/resolv.conf file.\n\n\n\n\n\n\nMethod 3: libnss-resolver\n\n\nlibnss-resolver is an app that adds Mac-style /etc/resolver/$FQDN files to the Linux NSS resolution stack to query a \ndifferent DNS server for any .vm address.  It may be the easiest option for most installations.\n\n\nThere are releases for Fedora 20, Ubuntu 12.04 and Ubuntu 14.04.\n\n\n\n\nInstall libnss-resolver from https://github.com/azukiapp/libnss-resolver/releases\n\n\nSet up .vm hostname resolution\n\n\necho 'nameserver 172.17.0.1:53' | sudo tee /etc/resolver/vm\n\n\n\n\n\n\nRun the dnsdock container\n\n\ndocker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock aacebedo/dnsdock:latest-amd64 -domain=vm\n\n\nNote\n: if you want this container to run automatically when the docker daemon starts, add the \n--restart=always\n \nflag to the above command.\n\n\n\n\n\n\n\n\nVerifying DNS is working\n\n\nOnce you have your environment set up, you can use the following tests to ensure things are running properly.\n\n\n\n\ndig @172.17.0.1 dnsdock.devtools.vm.\n\n\nYou should get a 172.17.0.0/16 address.\n\n\n\n\n\n\nping dnsdock.devtools.vm\n\n\nYou should get echo replies from a 172.17.0.0/16 address.\n\n\n\n\n\n\ngetent hosts dnsdock.devtools.vm\n\n\nYou should get a 172.17.0.0/16 address.",
            "title": "Linux Installation"
        },
        {
            "location": "/getting-started/linux-installation/#linux-installation",
            "text": "When running Docker containers on Linux, it is not necessary to run the Docker Machine VM. The instructions here describe \nhow to run DevTools projects on Linux.",
            "title": "Linux Installation"
        },
        {
            "location": "/getting-started/linux-installation/#linux-requirements",
            "text": "The dnsdock container, used to support automatic creation and maintenance of DNS namespace for the containers  Use of one of three options to forward DNS queries to the dnsdock container \n(see  Linux DNS configuration options  below)",
            "title": "Linux Requirements"
        },
        {
            "location": "/getting-started/linux-installation/#linux-installation-on-fedora-22",
            "text": "Install Docker 1.x.x and docker-compose  sudo dnf install docker-engine docker-compose    Add your user to the Docker group  sudo usermod -aG docker $USER    Log out, then back in, in order to pick up your new group assignments  Set the DNS configuration for dnsdock  We need to modify the command that docker uses within systemd  sudo mkdir /etc/systemd/system/docker.service.d  sudo vi /etc/systemd/system/docker.service.d/docker.conf  In that file put something like the following:    [Service]\n    ExecStart=\n    ExecStart=/usr/bin/dockerd -H fd:// --dns=172.17.0.1    Set up the docker0 network as trusted  sudo firewall-cmd --zone=trusted --add-interface=docker0   sudo firewall-cmd --zone=trusted --add-interface=docker0 --permanent    Start the docker daemon  sudo systemctl start docker",
            "title": "Linux installation on Fedora 22+"
        },
        {
            "location": "/getting-started/linux-installation/#linux-installation-on-ubuntulinux-mintdebian",
            "text": "Install Docker 1.x.x  sudo apt-get install docker-engine    Install Pip  sudo apt-get install python-pip    Install docker-compose  sudo pip install docker-compose    Add your user to the Docker group  sudo usermod -aG docker $USER    Log out, then back in, in order to pick up your new group assignments  Set the DNS configuration for dnsdock, as well as known RFC-1918 address space  Please note that the following command will over-write your existing Docker daemon configuration file.  Please \nset the -dns=172.17.0.1 option manually as an alternative  echo 'DOCKER_OPTS=\"-dns=172.17.0.1\"' | sudo tee /etc/default/docker    Start the docker daemon  sudo start docker",
            "title": "Linux installation on Ubuntu/Linux Mint/Debian"
        },
        {
            "location": "/getting-started/linux-installation/#linux-dns-configuration-options",
            "text": "",
            "title": "Linux DNS configuration options"
        },
        {
            "location": "/getting-started/linux-installation/#method-1-dnsmasq-via-networkmanager",
            "text": "This method works well with no other needed software provided that you have unfettered access to your system's \nconfiguration, and are using NetworkManager to maintain your networking stack   Add the line dns=dnsmasq to /etc/NetworkManager/NetworkManager.conf under the [main] configuration stanza. This will \ncause NetworkManager to spawn and use a dnsmasq process for all name resolution. If you already have a local configuration, \nensure that it is not configured to start on system boot.  Add a single rule to direct all DNS lookups for .vm addresses to the 172.17.0.1 address.  echo 'server=/vm/172.17.0.1' | sudo tee /etc/NetworkManager/dnsmasq.d/dnsdock.conf    Restart NetworkManager, either through systemd, or by simply rebooting.  To restart via systemd:  systemctl restart NetworkManager    Run the dnsdock container  docker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock aacebedo/dnsdock:latest-amd64 -domain=vm  Note : if you want this container to run automatically when the docker daemon starts, add the  --restart=always  \nflag to the above command.",
            "title": "Method 1: dnsmasq via NetworkManager"
        },
        {
            "location": "/getting-started/linux-installation/#method-2-dnsdock-as-main-resolver",
            "text": "This method will probably only work well if this is a fixed computer or server with a consistent single upstream DNS \nserver. If you meet these criteria, you can very easily use this to set up .vm resolution for containers an delegate the \nrest to your normal DNS server.  This example assumes that the upstream DNS server for a Linux workstation is 192.168.0.1.    Run the dnsdock container, specifying your upstream DNS server at the end.   docker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock aacebedo/dnsdock:latest-amd64 /opt/bin/dnsdock -domain=vm -nameserver=\"192.168.0.1:53\"  Note : if you want this container to run automatically when the docker daemon starts, add the  --restart=always  \nflag to the above command.     Configure 172.17.0.1 as your first DNS resolver in your network configuration. The method for doing this may differ \nbased on whether you are using a desktop environment or running Linux on a server, but that nameserver should end up as \nthe first 'nameserver' line in your /etc/resolv.conf file.",
            "title": "Method 2: dnsdock as main resolver"
        },
        {
            "location": "/getting-started/linux-installation/#method-3-libnss-resolver",
            "text": "libnss-resolver is an app that adds Mac-style /etc/resolver/$FQDN files to the Linux NSS resolution stack to query a \ndifferent DNS server for any .vm address.  It may be the easiest option for most installations.  There are releases for Fedora 20, Ubuntu 12.04 and Ubuntu 14.04.   Install libnss-resolver from https://github.com/azukiapp/libnss-resolver/releases  Set up .vm hostname resolution  echo 'nameserver 172.17.0.1:53' | sudo tee /etc/resolver/vm    Run the dnsdock container  docker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock aacebedo/dnsdock:latest-amd64 -domain=vm  Note : if you want this container to run automatically when the docker daemon starts, add the  --restart=always  \nflag to the above command.",
            "title": "Method 3: libnss-resolver"
        },
        {
            "location": "/getting-started/linux-installation/#verifying-dns-is-working",
            "text": "Once you have your environment set up, you can use the following tests to ensure things are running properly.   dig @172.17.0.1 dnsdock.devtools.vm.  You should get a 172.17.0.0/16 address.    ping dnsdock.devtools.vm  You should get echo replies from a 172.17.0.0/16 address.    getent hosts dnsdock.devtools.vm  You should get a 172.17.0.0/16 address.",
            "title": "Verifying DNS is working"
        },
        {
            "location": "/getting-started/windows-installation/",
            "text": "Windows Installation\n\n\nTo Be Done",
            "title": "Windows Installation"
        },
        {
            "location": "/getting-started/windows-installation/#windows-installation",
            "text": "To Be Done",
            "title": "Windows Installation"
        },
        {
            "location": "/getting-started/how-to-contribute/",
            "text": "To Be Done",
            "title": "How to contribute"
        },
        {
            "location": "/project-setup/common-setup/",
            "text": "Common Setup\n\n\nProject Code\n\n\nThe filesystem within containers is \nephemeral!\n Any changes made there \ndo not persist\n if the \ncontainer is restarted. (See \"Persistent Data Volume\" below for a storage area that is preserved.)\n\n\nIn typical Docker images the code is built \ndirectly into the container\n at the \n/code\n path. This \nis a great mechanism that allows the container to be \"self contained\" (pun intended), immutable and \nnot need any checkout/file system. You also know when you run a container exactly what code is in \nthere because you generally don\u2019t change the code unless you rebuild the image.  \n\n\nFor development purposes, however, this is problematic because it is burdensome to rebuild an image \nfor each code change. To solve this, we mount project code from the Host Machine into the running \ncontainer, effectively overriding the files built directly into the image. The running container is \nthen using the local project file system for the overridden paths rather than the file system built \ninto the image.  This allows a developer to use an IDE and edit code directly on the local file system \nof the Host Machine, but execute that code within the environment of the running container.\n\n\n\n\nNote on Project Code Location\n\n\nYour project code \nmust\n be located somewhere within your home directory (\n/Users\n for Macs) on \nyour local machine. This is because NFS shares your home directory into the Docker Host VM, and \nonly files on the Docker Host VM can be referenced in volume shares. \n\n\n\n\nPersistent Data Volume\n\n\nDevTools maintains a data volume on the Docker Host that is mounted at \n/data\n into every container. \nThis volume is persistent so long as you do not perform a \ndevtools remove\n operation. This ensures \nthat file access on the VM is done natively for things like databases and other things where filesystem\nperformance matters. If you configure a container to write to this area, you should use a project and \ncontainer based namespace to prevent conflicts as this is a shared resource. For example, you may want \nto use a namespacing method like \n/data/[project name]/[environment]/[service name]\n as a safe location \nto write data.\n\n\nAny code from your local directories is directly shared in to the Docker Machine VM via NFS at \n/Users\n. \nThis means that even if you destroy and re-create your Docker Host, your code will be safe since it \nlives on the Host Machine.\n\n\nNOTE ON FILE CHANGES WITHIN A CONTAINER\n\n\nAny files that are generated or changed within a running container that you want to persist after the \ncontainer is stopped \nshould be put onto a volume that is mounted into the container from the \nlocal machine\n.  A Docker container represents immutable infrastructure, the files on the image \nare able to be changed at runtime but typically do not persist. When the container is stopped and \nrun again it \"boots\" the files that were built into the original image. The volume at \n/data\n (mentioned \nabove) is a persistent volume that you can use.",
            "title": "Common Setup"
        },
        {
            "location": "/project-setup/common-setup/#common-setup",
            "text": "",
            "title": "Common Setup"
        },
        {
            "location": "/project-setup/common-setup/#project-code",
            "text": "The filesystem within containers is  ephemeral!  Any changes made there  do not persist  if the \ncontainer is restarted. (See \"Persistent Data Volume\" below for a storage area that is preserved.)  In typical Docker images the code is built  directly into the container  at the  /code  path. This \nis a great mechanism that allows the container to be \"self contained\" (pun intended), immutable and \nnot need any checkout/file system. You also know when you run a container exactly what code is in \nthere because you generally don\u2019t change the code unless you rebuild the image.    For development purposes, however, this is problematic because it is burdensome to rebuild an image \nfor each code change. To solve this, we mount project code from the Host Machine into the running \ncontainer, effectively overriding the files built directly into the image. The running container is \nthen using the local project file system for the overridden paths rather than the file system built \ninto the image.  This allows a developer to use an IDE and edit code directly on the local file system \nof the Host Machine, but execute that code within the environment of the running container.   Note on Project Code Location  Your project code  must  be located somewhere within your home directory ( /Users  for Macs) on \nyour local machine. This is because NFS shares your home directory into the Docker Host VM, and \nonly files on the Docker Host VM can be referenced in volume shares.",
            "title": "Project Code"
        },
        {
            "location": "/project-setup/common-setup/#persistent-data-volume",
            "text": "DevTools maintains a data volume on the Docker Host that is mounted at  /data  into every container. \nThis volume is persistent so long as you do not perform a  devtools remove  operation. This ensures \nthat file access on the VM is done natively for things like databases and other things where filesystem\nperformance matters. If you configure a container to write to this area, you should use a project and \ncontainer based namespace to prevent conflicts as this is a shared resource. For example, you may want \nto use a namespacing method like  /data/[project name]/[environment]/[service name]  as a safe location \nto write data.  Any code from your local directories is directly shared in to the Docker Machine VM via NFS at  /Users . \nThis means that even if you destroy and re-create your Docker Host, your code will be safe since it \nlives on the Host Machine.",
            "title": "Persistent Data Volume"
        },
        {
            "location": "/project-setup/common-setup/#note-on-file-changes-within-a-container",
            "text": "Any files that are generated or changed within a running container that you want to persist after the \ncontainer is stopped  should be put onto a volume that is mounted into the container from the \nlocal machine .  A Docker container represents immutable infrastructure, the files on the image \nare able to be changed at runtime but typically do not persist. When the container is stopped and \nrun again it \"boots\" the files that were built into the original image. The volume at  /data  (mentioned \nabove) is a persistent volume that you can use.",
            "title": "NOTE ON FILE CHANGES WITHIN A CONTAINER"
        },
        {
            "location": "/project-setup/new-projects/",
            "text": "New Projects\n\n\nTo set up a new project rather than just work on one, you'll need to understand how to create a \ndocker-compose file, how to configure DNS for your project's containers and how to configure \npersistent storage if your project needs it.\n\n\nManual Setup\n\n\nDevTools is intended to work with either raw Docker commands or Docker Compose files. Docker\nCompose is the preferred tool to use when setting up projects and in this section we will go\nover some basics to get a project setup.\n\n\nBe sure to read the \nDocker Compose compose file documentation\n\nso that you have a handle on how to setup the various configuration.\n\n\nPlease see the \nDevTools Examples Repository\n for \nhow to setup various technologies within DevTools.  Specifically, the \n\nDrupal 8 example\n covers all\nof the high points.\n\n\nChoosing Images\n\n\nAny valid Docker Image can work with DevTools. We also supply \na collection of crafted Docker\nimages\n that are easily configured and optimized. And example for\nan Apache / PHP image based on PHP7 is \nphase2/apache-php:php70\n or \nphp:7.1.1-apache\n  \n\n\n\n\nUse Image Tags\n\n\nWhen selecting and image to use, be sure to also specify a tag for that image. When you do not\nspecify a tag, the default tag of \nlatest\n is used and it is easy to get our of sync with other\nteam members or simply get unwanted changes if you do not explicitly specify an image tag.\n\n\n\n\nEnvironment Variables\n\n\nImages can take configuration through \nenvironment variables specified in the Docker Compose file\n. \nFor example, the \nphase2/apache-php\n image allows you to configure settings such as \nmax_execution_time\n with \nthe \nPHP_MAX_EXECUTION_TIME\n environment variable and \nmemory_limit\n with the \nPHP_MEMORY_LIMIT\n envirionment variables. \nYou can also turn on settings like Xdebug with the \nPHP_XDEBUG\n environment variable.\n\n\nDNS\n\n\nDNS Names for containers are managed with a service called dnsdock.  Dnsdock listens for containers started with certain label metadata\nspecified and creates DNS entries for those containers. Read the linked docs to learn about \nconfiguring label metadata in Compose\n\nand the key/values for \ndnsdock label configuration\n\n\nVolumes\n\n\nVolume mounting directories and files into containers are use for a variety of reasons.\n\n\n\n\nGetting your code base into a container\n\n\nSpecifying certain configuration files\n\n\nOverriding existing configuration files\n\n\nMaking SSH keys available within a container\n\n\nProviding directories that will hold data that lives longer than the container (e.g. database files, or website uploads)\n\n\n\n\nSee the \nCompose documentation for volumes\n to learn\nabout the various options. Also check out the DevTools examples linked above to see volume mounts in action.\n\n\nUsing Generators\n\n\nComing Soon with details on Yo P2 and Generator Gadget as tools that prompt for a few details and then generate the \nscaffolding of an entire project configuration.",
            "title": "New Projects"
        },
        {
            "location": "/project-setup/new-projects/#new-projects",
            "text": "To set up a new project rather than just work on one, you'll need to understand how to create a \ndocker-compose file, how to configure DNS for your project's containers and how to configure \npersistent storage if your project needs it.",
            "title": "New Projects"
        },
        {
            "location": "/project-setup/new-projects/#manual-setup",
            "text": "DevTools is intended to work with either raw Docker commands or Docker Compose files. Docker\nCompose is the preferred tool to use when setting up projects and in this section we will go\nover some basics to get a project setup.  Be sure to read the  Docker Compose compose file documentation \nso that you have a handle on how to setup the various configuration.  Please see the  DevTools Examples Repository  for \nhow to setup various technologies within DevTools.  Specifically, the  Drupal 8 example  covers all\nof the high points.",
            "title": "Manual Setup"
        },
        {
            "location": "/project-setup/new-projects/#choosing-images",
            "text": "Any valid Docker Image can work with DevTools. We also supply  a collection of crafted Docker\nimages  that are easily configured and optimized. And example for\nan Apache / PHP image based on PHP7 is  phase2/apache-php:php70  or  php:7.1.1-apache      Use Image Tags  When selecting and image to use, be sure to also specify a tag for that image. When you do not\nspecify a tag, the default tag of  latest  is used and it is easy to get our of sync with other\nteam members or simply get unwanted changes if you do not explicitly specify an image tag.",
            "title": "Choosing Images"
        },
        {
            "location": "/project-setup/new-projects/#environment-variables",
            "text": "Images can take configuration through  environment variables specified in the Docker Compose file . \nFor example, the  phase2/apache-php  image allows you to configure settings such as  max_execution_time  with \nthe  PHP_MAX_EXECUTION_TIME  environment variable and  memory_limit  with the  PHP_MEMORY_LIMIT  envirionment variables. \nYou can also turn on settings like Xdebug with the  PHP_XDEBUG  environment variable.",
            "title": "Environment Variables"
        },
        {
            "location": "/project-setup/new-projects/#dns",
            "text": "DNS Names for containers are managed with a service called dnsdock.  Dnsdock listens for containers started with certain label metadata\nspecified and creates DNS entries for those containers. Read the linked docs to learn about  configuring label metadata in Compose \nand the key/values for  dnsdock label configuration",
            "title": "DNS"
        },
        {
            "location": "/project-setup/new-projects/#volumes",
            "text": "Volume mounting directories and files into containers are use for a variety of reasons.   Getting your code base into a container  Specifying certain configuration files  Overriding existing configuration files  Making SSH keys available within a container  Providing directories that will hold data that lives longer than the container (e.g. database files, or website uploads)   See the  Compose documentation for volumes  to learn\nabout the various options. Also check out the DevTools examples linked above to see volume mounts in action.",
            "title": "Volumes"
        },
        {
            "location": "/project-setup/new-projects/#using-generators",
            "text": "Coming Soon with details on Yo P2 and Generator Gadget as tools that prompt for a few details and then generate the \nscaffolding of an entire project configuration.",
            "title": "Using Generators"
        },
        {
            "location": "/project-setup/existing-projects/",
            "text": "Existing Projects\n\n\nTo Be Done",
            "title": "Existing Projects"
        },
        {
            "location": "/project-setup/existing-projects/#existing-projects",
            "text": "To Be Done",
            "title": "Existing Projects"
        },
        {
            "location": "/project-setup/docker-images/",
            "text": "Docker Images\n\n\nKey components\n\n\nThe following Docker Images have been built to work with DevTools. They all have a similar and consistent \nsetup, so when using these images it is important to know the technology in place and how to customize it for you purposes.\n\nWe have provided environmental configuration for the most frequently customized options, and any extended customization \ncan be made by following the recommendations in \nCustomizing container configuration\n\n\nThese images are built with the following software\n\n\n\n\nS6-overlay\n Init System\n\n\nconfd\n config file templating\n\n\n\n\n\n\nNote\n\n\nBelow are a collection of tuned images for working with DevTools, but \nany\n Docker Image can be used within DevTools.\nAdditionally these Docker Images do not need to be used with DevTools, they can be used in any Docker environment.\n\n\n\n\nImages\n\n\nphase2/servicebase\n\n\n(\nDocker Hub\n) (\nRepo\n) \n\n\nA CentOS 7 base image that has s6-overlay and confd. This is a useful image for extending to build non-trivial services.\n\n\nphase2/servicebaselight\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nThis is an Alpine-based image that has had the S6-overlay init system and confd added to it.\n\n\nIn addition to the lightweight Alpine base it also includes bash and glibc so that Go-based Linux binaries will run. This \nimage is only ~8MB when compared to the 100+MB of servicebase.\n\n\nphase2/apache-php\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nApache \n PHP runtime images. It currently support PHP 5.5, 5.6, and 7.0\n\n\nphase2/apache-php-base\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nA base image for phase2/apache-php. Includes Apache and a default VirtualHost configured with php-fpm proxy. It does not \ninclude the php runtime, that is handed in the extension image(s).\n\n\nphase2/devtools-build\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nThis image provides the collection of development tools necessary to build applications, bundled with a wide array of \ntools useful for development and troubleshooting via the command-line interface. While it is possible to directly\nconnect via the \"web\" containers (apache-php), this is the preferred way to perform \"server work\".\n\n\nIt also contains some extras you may need to work with Drupal, including use of tools such as \nDrupal Console\n, \n\nGrunt Drupal Tasks\n and \nPattern Lab Starter\n.\n\n\nphase2/mariadb\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nMariaDB image for MySQL based builds with confd templates for config\n\n\nphase2/memcache\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nMemcache image with configurable settings\n\n\nphase2/redis\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nRedis image with a confd template for redis.conf\n\n\nphase2/node\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nNode image \n\n\nphase2/varnish\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nVarnish container with fancy environment variables for easy configuration\n\n\nphase2/jenkins-docker\n\n\n(\nDocker Hub\n) (\nRepo\n)\n\n\nJenkins image that is built to be able to run Docker commands and launch containers. Docker-inception.",
            "title": "Docker Images"
        },
        {
            "location": "/project-setup/docker-images/#docker-images",
            "text": "",
            "title": "Docker Images"
        },
        {
            "location": "/project-setup/docker-images/#key-components",
            "text": "The following Docker Images have been built to work with DevTools. They all have a similar and consistent \nsetup, so when using these images it is important to know the technology in place and how to customize it for you purposes. \nWe have provided environmental configuration for the most frequently customized options, and any extended customization \ncan be made by following the recommendations in  Customizing container configuration  These images are built with the following software   S6-overlay  Init System  confd  config file templating    Note  Below are a collection of tuned images for working with DevTools, but  any  Docker Image can be used within DevTools.\nAdditionally these Docker Images do not need to be used with DevTools, they can be used in any Docker environment.",
            "title": "Key components"
        },
        {
            "location": "/project-setup/docker-images/#images",
            "text": "",
            "title": "Images"
        },
        {
            "location": "/project-setup/docker-images/#phase2servicebase",
            "text": "( Docker Hub ) ( Repo )   A CentOS 7 base image that has s6-overlay and confd. This is a useful image for extending to build non-trivial services.",
            "title": "phase2/servicebase"
        },
        {
            "location": "/project-setup/docker-images/#phase2servicebaselight",
            "text": "( Docker Hub ) ( Repo )  This is an Alpine-based image that has had the S6-overlay init system and confd added to it.  In addition to the lightweight Alpine base it also includes bash and glibc so that Go-based Linux binaries will run. This \nimage is only ~8MB when compared to the 100+MB of servicebase.",
            "title": "phase2/servicebaselight"
        },
        {
            "location": "/project-setup/docker-images/#phase2apache-php",
            "text": "( Docker Hub ) ( Repo )  Apache   PHP runtime images. It currently support PHP 5.5, 5.6, and 7.0",
            "title": "phase2/apache-php"
        },
        {
            "location": "/project-setup/docker-images/#phase2apache-php-base",
            "text": "( Docker Hub ) ( Repo )  A base image for phase2/apache-php. Includes Apache and a default VirtualHost configured with php-fpm proxy. It does not \ninclude the php runtime, that is handed in the extension image(s).",
            "title": "phase2/apache-php-base"
        },
        {
            "location": "/project-setup/docker-images/#phase2devtools-build",
            "text": "( Docker Hub ) ( Repo )  This image provides the collection of development tools necessary to build applications, bundled with a wide array of \ntools useful for development and troubleshooting via the command-line interface. While it is possible to directly\nconnect via the \"web\" containers (apache-php), this is the preferred way to perform \"server work\".  It also contains some extras you may need to work with Drupal, including use of tools such as  Drupal Console ,  Grunt Drupal Tasks  and  Pattern Lab Starter .",
            "title": "phase2/devtools-build"
        },
        {
            "location": "/project-setup/docker-images/#phase2mariadb",
            "text": "( Docker Hub ) ( Repo )  MariaDB image for MySQL based builds with confd templates for config",
            "title": "phase2/mariadb"
        },
        {
            "location": "/project-setup/docker-images/#phase2memcache",
            "text": "( Docker Hub ) ( Repo )  Memcache image with configurable settings",
            "title": "phase2/memcache"
        },
        {
            "location": "/project-setup/docker-images/#phase2redis",
            "text": "( Docker Hub ) ( Repo )  Redis image with a confd template for redis.conf",
            "title": "phase2/redis"
        },
        {
            "location": "/project-setup/docker-images/#phase2node",
            "text": "( Docker Hub ) ( Repo )  Node image",
            "title": "phase2/node"
        },
        {
            "location": "/project-setup/docker-images/#phase2varnish",
            "text": "( Docker Hub ) ( Repo )  Varnish container with fancy environment variables for easy configuration",
            "title": "phase2/varnish"
        },
        {
            "location": "/project-setup/docker-images/#phase2jenkins-docker",
            "text": "( Docker Hub ) ( Repo )  Jenkins image that is built to be able to run Docker commands and launch containers. Docker-inception.",
            "title": "phase2/jenkins-docker"
        },
        {
            "location": "/common-tasks/starting-your-project-containers/",
            "text": "Starting your project containers\n\n\nConfigure your environment\n\n\nEnsure all terminals you intend to use can communicate with the Docker Host.  Generally a simple \ndocker ps\n will either\nlist out running containers or give you an error like \nCannot connect to the Docker daemon. Is the docker daemon running on this host?\n\n\nIf you get the error make sure you have run \neval \"$(devtools config)\"\n. See \nInstallation\n \nfor the proper way to configure your environments.\n\n\nStart your containers\n\n\nIn the project directory, start the containers with: \ndocker-compose up\n\n\n\n\nNote\n\n\nThe docker-compose command runs in the foreground as long as the Docker containers are running. \n(It is not hung if there is no output after \"Attaching [container name]...)\n\n\n\n\nLogs from the running containers will stream to the console and be prefixed by their compose names plus an integer (i.e. web_1, db_1, etc)\n\n\nYou can start another terminal tab if you need to run other commands (such as the build container operations, etc.)",
            "title": "Starting your project containers"
        },
        {
            "location": "/common-tasks/starting-your-project-containers/#starting-your-project-containers",
            "text": "",
            "title": "Starting your project containers"
        },
        {
            "location": "/common-tasks/starting-your-project-containers/#configure-your-environment",
            "text": "Ensure all terminals you intend to use can communicate with the Docker Host.  Generally a simple  docker ps  will either\nlist out running containers or give you an error like  Cannot connect to the Docker daemon. Is the docker daemon running on this host?  If you get the error make sure you have run  eval \"$(devtools config)\" . See  Installation  \nfor the proper way to configure your environments.",
            "title": "Configure your environment"
        },
        {
            "location": "/common-tasks/starting-your-project-containers/#start-your-containers",
            "text": "In the project directory, start the containers with:  docker-compose up   Note  The docker-compose command runs in the foreground as long as the Docker containers are running.  (It is not hung if there is no output after \"Attaching [container name]...)   Logs from the running containers will stream to the console and be prefixed by their compose names plus an integer (i.e. web_1, db_1, etc)  You can start another terminal tab if you need to run other commands (such as the build container operations, etc.)",
            "title": "Start your containers"
        },
        {
            "location": "/common-tasks/stopping-containers-and-cleanup/",
            "text": "Stopping containers and cleanup\n\n\nStopping the containers for your project\n\n\nYou may want to recoup the resources used by your projects containers and the docker host for other things if you are \ndone with development for a while.  You can stop the containers for a single project only or all containers and the docker \nhost depending on what you are finished using.\n\n\n\n\n\n\nIf you only want to stop the containers for your project, in the project directory, run \ndocker-compose stop\n or \npress Ctrl-C to stop a docker-compose process running in the foreground and then run \ndocker-compose stop\n to ensure \nthe project containers have stopped.\n\n\n\n\n\n\nIf you want to shut down the docker host as well as any containers, run \ndevtools stop\n\n\n\n\n\n\nCleaning Up\n\n\nFrom time to time you'll want to clean up stopped containers. You'll also want to take special care when finishing a \nproject to release all the resources used by it.\n\n\nFor periodic cleanup of all stopped containers, run the following script while your docker host is running: \ndevtools prune\n\n\nIf you only want to clean up project specific stopped containers, you can run: \ndocker-compose rm\n from your project directory.\n\n\nWhen you are finished with a project, if you used any persistent data storage you'll want to run a command to clean it \nup. The exact directory to request removal from will depend on your project (see suggested directory naming guidelines in \n\nCommon Setup\n): \ndocker ssh dev sudo rm -rf /data/[project]/",
            "title": "Stopping containers and cleanup"
        },
        {
            "location": "/common-tasks/stopping-containers-and-cleanup/#stopping-containers-and-cleanup",
            "text": "",
            "title": "Stopping containers and cleanup"
        },
        {
            "location": "/common-tasks/stopping-containers-and-cleanup/#stopping-the-containers-for-your-project",
            "text": "You may want to recoup the resources used by your projects containers and the docker host for other things if you are \ndone with development for a while.  You can stop the containers for a single project only or all containers and the docker \nhost depending on what you are finished using.    If you only want to stop the containers for your project, in the project directory, run  docker-compose stop  or \npress Ctrl-C to stop a docker-compose process running in the foreground and then run  docker-compose stop  to ensure \nthe project containers have stopped.    If you want to shut down the docker host as well as any containers, run  devtools stop",
            "title": "Stopping the containers for your project"
        },
        {
            "location": "/common-tasks/stopping-containers-and-cleanup/#cleaning-up",
            "text": "From time to time you'll want to clean up stopped containers. You'll also want to take special care when finishing a \nproject to release all the resources used by it.  For periodic cleanup of all stopped containers, run the following script while your docker host is running:  devtools prune  If you only want to clean up project specific stopped containers, you can run:  docker-compose rm  from your project directory.  When you are finished with a project, if you used any persistent data storage you'll want to run a command to clean it \nup. The exact directory to request removal from will depend on your project (see suggested directory naming guidelines in  Common Setup ):  docker ssh dev sudo rm -rf /data/[project]/",
            "title": "Cleaning Up"
        },
        {
            "location": "/common-tasks/using-the-build-container/",
            "text": "Using the Build Container\n\n\nPart of DevTools is a \ndevtools-build\n image.  The idea of the build \ncontainer is that it will have installed many of the tools you'd need to work on a project and the proper versions \nso that they work well together.  Everything from drush to gem to npm to composer as well as grunt, bower, yeoman, etc. \nProviding these tools in a container means that you'll never have to worry about having the right tools installed on \nyour laptop or integration environment to get your job done.\n\n\nThe example Drupal project contains a \nbuild.yml\n \nDocker Compose file that shows a variety of ways to use the container.  \n\n\nGetting a build container command line.\n\n\nOne of the most common ways to use the build container is to launch a shell into the container and run commands from the \ncommand line interface (cli). The following command get you to the cli\n\n\ndocker-compose -f build.yml run cli\n\n\n\n\nMaking a command alias\n\n\nUsing a shell alias you can make a really quick CLI command that is reusable across projects if you name your build.yml\nfile the same everywhere. \nalias cli='docker-compose -f build.yml run cli\n then you only need to \ncli\n to get into\nyour build containers shell.  This \ntrick\n can be used with all of the command below as well.\n\n\n\n\nRunning a command container\n\n\nA \"command container\" is a term we have coined for a specific approach we use, where containers are spun up to run a single \ncommand in a consistent environment and then shut down.  Here are some example of command containers that we have configured \ninto the \nbuild.yml\n file from our example repository above.\n\n\nDrush Command Container\n\n\nThis is a general purpose Drush command container that allows you to run any drush command in a consistent environment\n\n\ndocker-compose -f build.yml run drush [command here]\n\n\nGrunt Command Container\n\n\nThis is a general purpose Grunt command container that allows you to run any grunt command in a consistent environment\n\n\ndocker-compose -f build.yml run grunt [command here]\n\n\nComposer Command Container\n\n\nThis is a general purpose Composer command container that allows you to run any composer command in a consistent environment\n\n\ndocker-compose -f build.yml run composer [command here]\n\n\nComposer Install Command Container\n\n\nThis one goes a step further when there is a specific command you want to run and control all the arguments used to run it.\n\n\ndocker-compose -f build.yml run composer-install\n\n\nShare output from the build container\n\n\nUsing the example project from above, we have a volume mount of your project code into the build container. Now, when you perform a \nbuild and it writes the output to the local project directory (e.g in ./build/html or something else in the working directory), \nthose changes to the filesystem are effectively outside of the container. The web container shoudl also define a volume mount \nfor the build output into the docroot, or mount your project directory in the container and configure the docroot to be the\n absolute path to your build output and you will have seamless integration of build output to a web container running your project.",
            "title": "Using the build container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#using-the-build-container",
            "text": "Part of DevTools is a  devtools-build  image.  The idea of the build \ncontainer is that it will have installed many of the tools you'd need to work on a project and the proper versions \nso that they work well together.  Everything from drush to gem to npm to composer as well as grunt, bower, yeoman, etc. \nProviding these tools in a container means that you'll never have to worry about having the right tools installed on \nyour laptop or integration environment to get your job done.  The example Drupal project contains a  build.yml  \nDocker Compose file that shows a variety of ways to use the container.",
            "title": "Using the Build Container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#getting-a-build-container-command-line",
            "text": "One of the most common ways to use the build container is to launch a shell into the container and run commands from the \ncommand line interface (cli). The following command get you to the cli  docker-compose -f build.yml run cli   Making a command alias  Using a shell alias you can make a really quick CLI command that is reusable across projects if you name your build.yml\nfile the same everywhere.  alias cli='docker-compose -f build.yml run cli  then you only need to  cli  to get into\nyour build containers shell.  This  trick  can be used with all of the command below as well.",
            "title": "Getting a build container command line."
        },
        {
            "location": "/common-tasks/using-the-build-container/#running-a-command-container",
            "text": "A \"command container\" is a term we have coined for a specific approach we use, where containers are spun up to run a single \ncommand in a consistent environment and then shut down.  Here are some example of command containers that we have configured \ninto the  build.yml  file from our example repository above.",
            "title": "Running a command container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#drush-command-container",
            "text": "This is a general purpose Drush command container that allows you to run any drush command in a consistent environment  docker-compose -f build.yml run drush [command here]",
            "title": "Drush Command Container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#grunt-command-container",
            "text": "This is a general purpose Grunt command container that allows you to run any grunt command in a consistent environment  docker-compose -f build.yml run grunt [command here]",
            "title": "Grunt Command Container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#composer-command-container",
            "text": "This is a general purpose Composer command container that allows you to run any composer command in a consistent environment  docker-compose -f build.yml run composer [command here]",
            "title": "Composer Command Container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#composer-install-command-container",
            "text": "This one goes a step further when there is a specific command you want to run and control all the arguments used to run it.  docker-compose -f build.yml run composer-install",
            "title": "Composer Install Command Container"
        },
        {
            "location": "/common-tasks/using-the-build-container/#share-output-from-the-build-container",
            "text": "Using the example project from above, we have a volume mount of your project code into the build container. Now, when you perform a \nbuild and it writes the output to the local project directory (e.g in ./build/html or something else in the working directory), \nthose changes to the filesystem are effectively outside of the container. The web container shoudl also define a volume mount \nfor the build output into the docroot, or mount your project directory in the container and configure the docroot to be the\n absolute path to your build output and you will have seamless integration of build output to a web container running your project.",
            "title": "Share output from the build container"
        },
        {
            "location": "/common-tasks/working-with-volumes/",
            "text": "Working with Volumes\n\n\nVolumes are a way that you can map directories or individual files into a running container.  This is useful to provide \ncode to run for a generic container, or directories to store data that persist longer than the life of the container, or \nto even override directories and/or files that exist in an image.  Lets look at a few of those examples.\n\n\nProvide code for a generic container to run*\n\n\nThe default phase2/apache-php:php70 is a Web/PHP container that provides only an index file in \n/var/www/html\n that \nprints out phpinfo().  This is obviously not very useful for an application, so we can provide an entire Drupal site to \nrun and we do that by mapping our site into the default docroot like this:\n\n\n./build/html:/var/www/html\n\n\nThis takes the Drupal site we have in our local project directory of \nbuild/html\n and it overrides the default content \nof the images \n/var/www/html\n directory.\n\n\nPersist data longer than the life of the container\n\n\nWhen using a database like mysql the container will store the database files in \n/var/lib/mysql\n and by default that \ndirectory will be reset every time the container restarts. This means each time you restart your container you'd need \nto reinstall your application and database, which can make life difficult. So in order to persist mysql data for longer \nthan the current run of the container we will map a directory from the Docker Host into the container and override the \ndefault \n/var/lib/mysql\n directory. The configuration will look something like this.\n\n\n/data/drupal/mysql:/var/lib/mysql\n\n\nNow when your database container creates files in \n/var/lib/mysql\n they are actually saved in the \n/data/drupal/mysql\n \ndirectory on the Docker Host. Be sure to namespace your directories inside /data so that separate projects don't conflict \nwith each other. You'll also want to ensure you clean up when you are done with your project to keep from using up all \nof your disk space. See the cleaning up section for more info.\n\n\nOverride directories and files that exist in an image\n\n\nGenerally the configuration shipped with a Docker Image is meant to be the production configuration. Often, that \nconfiguration is not suitable for development and we need to override configurations.  With volumes we have shown \nearlier how you can override directories, but you can also override individual files too.\n\n\n./config/dev/httpd/httpd.conf:/etc/httpd/httpd.conf\n\n\nThis takes a local \nhttpd.conf\n file from our project and overrides the \n/etc/httpd/httpd.conf\n files that ships with \nthe container. \n\n\nChanging Volume Definitions in Compose File\n\n\nIf you wind up changing volume definitions in your docker-compose file you will need to remove your container before it \nwill recognize those changes on a restart.\n\n\nIn the project directory, run: \ndocker-compose rm\n\n\nThis command will remove all stopped containers defined in the docker-compose.yml.  You could also remove an individual \ncontainer by running: \ndocker-compose rm \nname in yml\n\n\nAfter removing the container, it will revert to the original state from the Docker image, removing any packages \ninstalled or files modified that are not included in a volume mount. Start your containers again with \ndocker-compose up\n \nand you should have your new volume mounts.",
            "title": "Working with Volumes"
        },
        {
            "location": "/common-tasks/working-with-volumes/#working-with-volumes",
            "text": "Volumes are a way that you can map directories or individual files into a running container.  This is useful to provide \ncode to run for a generic container, or directories to store data that persist longer than the life of the container, or \nto even override directories and/or files that exist in an image.  Lets look at a few of those examples.",
            "title": "Working with Volumes"
        },
        {
            "location": "/common-tasks/working-with-volumes/#provide-code-for-a-generic-container-to-run",
            "text": "The default phase2/apache-php:php70 is a Web/PHP container that provides only an index file in  /var/www/html  that \nprints out phpinfo().  This is obviously not very useful for an application, so we can provide an entire Drupal site to \nrun and we do that by mapping our site into the default docroot like this:  ./build/html:/var/www/html  This takes the Drupal site we have in our local project directory of  build/html  and it overrides the default content \nof the images  /var/www/html  directory.",
            "title": "Provide code for a generic container to run*"
        },
        {
            "location": "/common-tasks/working-with-volumes/#persist-data-longer-than-the-life-of-the-container",
            "text": "When using a database like mysql the container will store the database files in  /var/lib/mysql  and by default that \ndirectory will be reset every time the container restarts. This means each time you restart your container you'd need \nto reinstall your application and database, which can make life difficult. So in order to persist mysql data for longer \nthan the current run of the container we will map a directory from the Docker Host into the container and override the \ndefault  /var/lib/mysql  directory. The configuration will look something like this.  /data/drupal/mysql:/var/lib/mysql  Now when your database container creates files in  /var/lib/mysql  they are actually saved in the  /data/drupal/mysql  \ndirectory on the Docker Host. Be sure to namespace your directories inside /data so that separate projects don't conflict \nwith each other. You'll also want to ensure you clean up when you are done with your project to keep from using up all \nof your disk space. See the cleaning up section for more info.",
            "title": "Persist data longer than the life of the container"
        },
        {
            "location": "/common-tasks/working-with-volumes/#override-directories-and-files-that-exist-in-an-image",
            "text": "Generally the configuration shipped with a Docker Image is meant to be the production configuration. Often, that \nconfiguration is not suitable for development and we need to override configurations.  With volumes we have shown \nearlier how you can override directories, but you can also override individual files too.  ./config/dev/httpd/httpd.conf:/etc/httpd/httpd.conf  This takes a local  httpd.conf  file from our project and overrides the  /etc/httpd/httpd.conf  files that ships with \nthe container.",
            "title": "Override directories and files that exist in an image"
        },
        {
            "location": "/common-tasks/working-with-volumes/#changing-volume-definitions-in-compose-file",
            "text": "If you wind up changing volume definitions in your docker-compose file you will need to remove your container before it \nwill recognize those changes on a restart.  In the project directory, run:  docker-compose rm  This command will remove all stopped containers defined in the docker-compose.yml.  You could also remove an individual \ncontainer by running:  docker-compose rm  name in yml  After removing the container, it will revert to the original state from the Docker image, removing any packages \ninstalled or files modified that are not included in a volume mount. Start your containers again with  docker-compose up  \nand you should have your new volume mounts.",
            "title": "Changing Volume Definitions in Compose File"
        },
        {
            "location": "/common-tasks/working-offline/",
            "text": "Working Offline\n\n\nA common desire is the ability to leverage the full development environment provided to work\noffline. When attempting this users are often thwarted trying to access containers which\nappear to be successfully running.\n\n\nThis issue is due to a failure to resolve domain names to the appropriate IP address for the\ncontainer. This affects those using OS X and appears to be the result of a failure of the name\nresolution system to operate when no network interface appears connected. Typical error messages\nin browsers warn of being disconnected from the internet. Specifically, Chrome will include the \nerror code ERR_INTERNET_DISCONNECTED. In these instances, a test command like \n\ncurl -v http://www.project.vm/\n succeeds as does attempting to use the IP address of a container\nwithin a browser. The command \ndevtools dns-records\n will display a mapping between all known\ncontainers and IP addresses. The \ndocker inspect CONTAINER_NAME\n command can be used to view more\ndetailed information about a specific container including its IP address and should be used on\nsystems not supporting the \ndevtools\n application.\n\n\nOffline DNS Workaround\n\n\nThe work around for this issue is to use the \ndevtools dns-records\n command and copy the output\nto your \n/etc/hosts\n file. You'll need to update this file any time you start or stop project\ncontainers and you should clean entries from it when you reconnect to a network. On systems\nwhich do not support the \ndevtools\n application the \ndocker inspect\n command can be used to\nbuild a mapping of IP addresses to domain names.\n\n\n\n\nNetwork Changes Can Require Restart\n\n\nNetwork changes such as connecting or disconnecting an interface or VPN can require a restart\nof your devtools environment via \ndevtools restart\n or a re-execution of the \ndevtools dns\n\ncommand to ensure routing of traffic to containers and DNS resolution is properly configured.\n\n\n\n\nAdditional Information\n\n\nThose seeking additional information about the root cause of this issue and wishing to explore\npotential solutions can read further information at the following URLs. Note that none of the\npurported solutions other than that described above has proven successful in testing. Note that\nsome of these links refer to DNS utilities used in older OS X versions.\n\n\n\n\nhttp://serverfault.com/questions/22419/set-dns-server-on-os-x-even-when-without-internet-connection\n\n\nhttp://apple.stackexchange.com/questions/202887/mac-doesnt-use-local-dns-for-local\n\n\nhttp://superuser.com/questions/418833/using-dnsmasq-on-os-x-when-not-connected-to-the-internet\n\n\nhttp://apple.stackexchange.com/questions/26616/dns-not-resolving-on-mac-os-x\n\n\n\n\nThis same issue affects other projects as well.\n\n\n\n\nhttps://github.com/basecamp/pow/issues/471\n\n\nhttps://github.com/basecamp/pow/issues/104\n\n\n\n\nA theoretical solution to this issue would be to have a network interface that always appeared\nactive triggering the attempt to resolve the domain name. The following post discusses creation\nof a virtual interface to satisfy this requirement. The mechanism mentioned by bmasterswizzle and\nAlex Gray did not prove effective in testing. The interface could be created successfully but\nnever brought up to a state where OS X considered it active.\n\n\n\n\nhttp://stackoverflow.com/questions/87442/virtual-network-interface-in-mac-os-x\n\n\n\n\nSome additional information and demonstrations of utilities for diagnostics can be found at\n\n\n\n\nhttp://apple.stackexchange.com/questions/26616/dns-not-resolving-on-mac-os-x\n\n\nhttp://serverfault.com/questions/478534/how-is-dns-lookup-configured-for-osx-mountain-lion",
            "title": "Working Offline"
        },
        {
            "location": "/common-tasks/working-offline/#working-offline",
            "text": "A common desire is the ability to leverage the full development environment provided to work\noffline. When attempting this users are often thwarted trying to access containers which\nappear to be successfully running.  This issue is due to a failure to resolve domain names to the appropriate IP address for the\ncontainer. This affects those using OS X and appears to be the result of a failure of the name\nresolution system to operate when no network interface appears connected. Typical error messages\nin browsers warn of being disconnected from the internet. Specifically, Chrome will include the \nerror code ERR_INTERNET_DISCONNECTED. In these instances, a test command like  curl -v http://www.project.vm/  succeeds as does attempting to use the IP address of a container\nwithin a browser. The command  devtools dns-records  will display a mapping between all known\ncontainers and IP addresses. The  docker inspect CONTAINER_NAME  command can be used to view more\ndetailed information about a specific container including its IP address and should be used on\nsystems not supporting the  devtools  application.",
            "title": "Working Offline"
        },
        {
            "location": "/common-tasks/working-offline/#offline-dns-workaround",
            "text": "The work around for this issue is to use the  devtools dns-records  command and copy the output\nto your  /etc/hosts  file. You'll need to update this file any time you start or stop project\ncontainers and you should clean entries from it when you reconnect to a network. On systems\nwhich do not support the  devtools  application the  docker inspect  command can be used to\nbuild a mapping of IP addresses to domain names.   Network Changes Can Require Restart  Network changes such as connecting or disconnecting an interface or VPN can require a restart\nof your devtools environment via  devtools restart  or a re-execution of the  devtools dns \ncommand to ensure routing of traffic to containers and DNS resolution is properly configured.",
            "title": "Offline DNS Workaround"
        },
        {
            "location": "/common-tasks/working-offline/#additional-information",
            "text": "Those seeking additional information about the root cause of this issue and wishing to explore\npotential solutions can read further information at the following URLs. Note that none of the\npurported solutions other than that described above has proven successful in testing. Note that\nsome of these links refer to DNS utilities used in older OS X versions.   http://serverfault.com/questions/22419/set-dns-server-on-os-x-even-when-without-internet-connection  http://apple.stackexchange.com/questions/202887/mac-doesnt-use-local-dns-for-local  http://superuser.com/questions/418833/using-dnsmasq-on-os-x-when-not-connected-to-the-internet  http://apple.stackexchange.com/questions/26616/dns-not-resolving-on-mac-os-x   This same issue affects other projects as well.   https://github.com/basecamp/pow/issues/471  https://github.com/basecamp/pow/issues/104   A theoretical solution to this issue would be to have a network interface that always appeared\nactive triggering the attempt to resolve the domain name. The following post discusses creation\nof a virtual interface to satisfy this requirement. The mechanism mentioned by bmasterswizzle and\nAlex Gray did not prove effective in testing. The interface could be created successfully but\nnever brought up to a state where OS X considered it active.   http://stackoverflow.com/questions/87442/virtual-network-interface-in-mac-os-x   Some additional information and demonstrations of utilities for diagnostics can be found at   http://apple.stackexchange.com/questions/26616/dns-not-resolving-on-mac-os-x  http://serverfault.com/questions/478534/how-is-dns-lookup-configured-for-osx-mountain-lion",
            "title": "Additional Information"
        },
        {
            "location": "/common-tasks/ssh-into-a-container/",
            "text": "SSH into a Container\n\n\nHow do I SSH into a running container\n\n\nThere is a docker exec command that can be used to connect to a container that is already running.  \n\n\n\n\nUse \ndocker ps\n to get the name of the existing container\n\n\nUse the command \ndocker exec -it \ncontainer name\n /bin/bash\n to get a bash shell in the container\n\n\nGenerically, use \ndocker exec -it \ncontainer name\n \ncommand\n to execute whatever command you specify in the container.\n\n\n\n\nHow do I run a command in my container?\n\n\nThe proper way to run a command in a container is: \ndocker-compose run \ncontainer name\n \ncommand\n. For example, to get a shell \ninto your web container you might run \ndocker-compose run web /bin/bash\n\n\nTo run a series of commands, you must wrap them in a single command using a shell. For example: \ndocker-compose run \n\nname in yml\n sh -c '\ncommand 1\n \n \ncommand 2\n \n \ncommand 3\n'\n\n\nIn some cases you may want to run a container that is not defined by a docker-compose.yml file, for example to test a new \ncontainer configuration. Use docker run to start a new container with a given image: \ndocker run -it \nimage name\n \ncommand\n\n\nThe docker run command accepts command line options to specify volume mounts, environment variables, the working directory, and more.\n\n\nGetting a shell for build/tooling operations\n\n\nGetting a shell into a build container to execute any operations is the simplest approach. You simply want to get access \nto the \ncli\n container we defined in the compose file.  The command \ndocker-compose -f build.yml run cli\n will start an \ninstance of the \nphase2/devtools-build\n image and run a bash shell for you.  From there you are free to use \ndrush\n, \n\ngrunt\n or whatever your little heart desires.\n\n\nRunning commands, but not from a dedicated shell\n\n\nAnother concept in the Docker world is starting a container to run a single command and allowing the container stop when \nthe command is completed.  This is great if you run commands infrequently, or don't want to have another container \nconstantly running.  Running your commands on containers in this fashion is also well suited for commands that don't \ngenerate any files on the filesystem or if they do, they write those files on to volumes mounted into the container.\n\n\nThe \ndrush\n container defined in the example \nbuild.yml\n file is a container designed specifically to run drush in a \nsingle working directory taking only the commands as arguments.  This approach allows us to provide a quick and easy \nmechanism for running any drush command, such as \nsqlc\n, \ncache-rebuild\n, and others, in your Drupal site quick and easily.\n\n\nThere are also other examples of a \ngrunt\n command container similar to \ndrush\n and an even more specific command \ncontainer around running a single command, \ndrush make\n to build the site from a make/dependency file.",
            "title": "SSH into a container"
        },
        {
            "location": "/common-tasks/ssh-into-a-container/#ssh-into-a-container",
            "text": "",
            "title": "SSH into a Container"
        },
        {
            "location": "/common-tasks/ssh-into-a-container/#how-do-i-ssh-into-a-running-container",
            "text": "There is a docker exec command that can be used to connect to a container that is already running.     Use  docker ps  to get the name of the existing container  Use the command  docker exec -it  container name  /bin/bash  to get a bash shell in the container  Generically, use  docker exec -it  container name   command  to execute whatever command you specify in the container.",
            "title": "How do I SSH into a running container"
        },
        {
            "location": "/common-tasks/ssh-into-a-container/#how-do-i-run-a-command-in-my-container",
            "text": "The proper way to run a command in a container is:  docker-compose run  container name   command . For example, to get a shell \ninto your web container you might run  docker-compose run web /bin/bash  To run a series of commands, you must wrap them in a single command using a shell. For example:  docker-compose run  name in yml  sh -c ' command 1     command 2     command 3 '  In some cases you may want to run a container that is not defined by a docker-compose.yml file, for example to test a new \ncontainer configuration. Use docker run to start a new container with a given image:  docker run -it  image name   command  The docker run command accepts command line options to specify volume mounts, environment variables, the working directory, and more.",
            "title": "How do I run a command in my container?"
        },
        {
            "location": "/common-tasks/ssh-into-a-container/#getting-a-shell-for-buildtooling-operations",
            "text": "Getting a shell into a build container to execute any operations is the simplest approach. You simply want to get access \nto the  cli  container we defined in the compose file.  The command  docker-compose -f build.yml run cli  will start an \ninstance of the  phase2/devtools-build  image and run a bash shell for you.  From there you are free to use  drush ,  grunt  or whatever your little heart desires.",
            "title": "Getting a shell for build/tooling operations"
        },
        {
            "location": "/common-tasks/ssh-into-a-container/#running-commands-but-not-from-a-dedicated-shell",
            "text": "Another concept in the Docker world is starting a container to run a single command and allowing the container stop when \nthe command is completed.  This is great if you run commands infrequently, or don't want to have another container \nconstantly running.  Running your commands on containers in this fashion is also well suited for commands that don't \ngenerate any files on the filesystem or if they do, they write those files on to volumes mounted into the container.  The  drush  container defined in the example  build.yml  file is a container designed specifically to run drush in a \nsingle working directory taking only the commands as arguments.  This approach allows us to provide a quick and easy \nmechanism for running any drush command, such as  sqlc ,  cache-rebuild , and others, in your Drupal site quick and easily.  There are also other examples of a  grunt  command container similar to  drush  and an even more specific command \ncontainer around running a single command,  drush make  to build the site from a make/dependency file.",
            "title": "Running commands, but not from a dedicated shell"
        },
        {
            "location": "/common-tasks/customizing-container-configuration/",
            "text": "Customizing Configuration\n\n\nThere are a few primary mechanisms for customizing the configuration of a container.\n\n\nEnvironment Variables\n\n\nMany images will react to environmental variables to alter their behavior. Images which offer\nthis functionality should document it in the README for the image. For an example see the\n\nDevTools Build\n image. When environmental\nconfiguration is available it can be triggered by specifying the appropriate value in the\nenvironments section of your docker compose file.\n\n\nwww:\n  image: phase2/apache-php:php56\n  environment:\n    # Change some core container settings\n    PHP_MAX_EXECUTION_TIME: 45\n    # These enable debug/profiling support\n    PHP_XDEBUG: \ntrue\n\n    PHP_XHPROF: \nfalse\n\n\n\n\n\nVolume Mounts\n\n\nIf the container image you are using doesn't allow for change via environmental variables, your \nnext option is to override the configuration file using volume mounting. In this setup, you\nreplace the configuration file inside a container with a file from your host machine.\n\n\nwww:\n  image: phase2/apache-php:php56\n  volumes:\n    # substitute in a special mime magic file because our project handles files\n    # of special types\n    - ./env/www/etc/httpd/conf/magic:/etc/httpd/conf/magic\n\n\n\n\nVolume Mounts for confd\n\n\nPhase2 images often use \nconfd\n to template configuration from environment variable and other sources.\nThe configuration file you may be trying to override might be generated on container initiation via confd. If this is the \ncase, you'll need to override the template file from which the configuration file is created. If you find that your copy \nof the configuration file on your host machine is updated when you start a container this is likely the cause. \n\n\nFor exmaple, the xdebug configuration provided in our \nphase2/apache-php:php70\n container is proivided by confd, so this\nis how you would override that configuration\n\n\nwww:\n  image: phase2/apache-php:php70\n  volumes:\n    # substitute a different confd template file into the image so confd will use the override on container boot\n    - ./env/www/etc/confd/templates/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl",
            "title": "Changing container configuration"
        },
        {
            "location": "/common-tasks/customizing-container-configuration/#customizing-configuration",
            "text": "There are a few primary mechanisms for customizing the configuration of a container.",
            "title": "Customizing Configuration"
        },
        {
            "location": "/common-tasks/customizing-container-configuration/#environment-variables",
            "text": "Many images will react to environmental variables to alter their behavior. Images which offer\nthis functionality should document it in the README for the image. For an example see the DevTools Build  image. When environmental\nconfiguration is available it can be triggered by specifying the appropriate value in the\nenvironments section of your docker compose file.  www:\n  image: phase2/apache-php:php56\n  environment:\n    # Change some core container settings\n    PHP_MAX_EXECUTION_TIME: 45\n    # These enable debug/profiling support\n    PHP_XDEBUG:  true \n    PHP_XHPROF:  false",
            "title": "Environment Variables"
        },
        {
            "location": "/common-tasks/customizing-container-configuration/#volume-mounts",
            "text": "If the container image you are using doesn't allow for change via environmental variables, your \nnext option is to override the configuration file using volume mounting. In this setup, you\nreplace the configuration file inside a container with a file from your host machine.  www:\n  image: phase2/apache-php:php56\n  volumes:\n    # substitute in a special mime magic file because our project handles files\n    # of special types\n    - ./env/www/etc/httpd/conf/magic:/etc/httpd/conf/magic",
            "title": "Volume Mounts"
        },
        {
            "location": "/common-tasks/customizing-container-configuration/#volume-mounts-for-confd",
            "text": "Phase2 images often use  confd  to template configuration from environment variable and other sources.\nThe configuration file you may be trying to override might be generated on container initiation via confd. If this is the \ncase, you'll need to override the template file from which the configuration file is created. If you find that your copy \nof the configuration file on your host machine is updated when you start a container this is likely the cause.   For exmaple, the xdebug configuration provided in our  phase2/apache-php:php70  container is proivided by confd, so this\nis how you would override that configuration  www:\n  image: phase2/apache-php:php70\n  volumes:\n    # substitute a different confd template file into the image so confd will use the override on container boot\n    - ./env/www/etc/confd/templates/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl",
            "title": "Volume Mounts for confd"
        },
        {
            "location": "/common-tasks/using-watches/",
            "text": "Using Watches\n\n\nOften we need \nwatches\n running inside of our containers. This could be for webpack, grunt, nodemon, etc.  One of the \nmain challenges with the NFS mounts used in DevTools is that they do not forward filesystem notifications across the \nNFS mount and into containers, so we need to facilitate that.\n\n\nThere is a command \ndevtools watch [options] \npath\n. Running this on your host will watch for changes and rsync \nnotifications to files and directories under \npath\n into the Docker Machine VM (which will then provide filesystem \nnotifications into the container). These are the options for \ndevtools watch\n\n\n\n\n--machine \nname\n Optional: Specify a machine to send events. It will default to our \ndev\n machine\n\n\n--ignorefile \nfile\n Optional: Specify a file that contains patterns for directories/files to ignore.  Put one \n entry per line (blank lines and comments are allowed). If not specified it will look for a file named \n \n.devtools-watch-ignore\n in the working directory and all parent directories.",
            "title": "Using watches"
        },
        {
            "location": "/common-tasks/using-watches/#using-watches",
            "text": "Often we need  watches  running inside of our containers. This could be for webpack, grunt, nodemon, etc.  One of the \nmain challenges with the NFS mounts used in DevTools is that they do not forward filesystem notifications across the \nNFS mount and into containers, so we need to facilitate that.  There is a command  devtools watch [options]  path . Running this on your host will watch for changes and rsync \nnotifications to files and directories under  path  into the Docker Machine VM (which will then provide filesystem \nnotifications into the container). These are the options for  devtools watch   --machine  name  Optional: Specify a machine to send events. It will default to our  dev  machine  --ignorefile  file  Optional: Specify a file that contains patterns for directories/files to ignore.  Put one \n entry per line (blank lines and comments are allowed). If not specified it will look for a file named \n  .devtools-watch-ignore  in the working directory and all parent directories.",
            "title": "Using Watches"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/",
            "text": "Local Xdebug with DevTools \n PHPStorm\n\n\nGetting \nXdebug\n set up can be a bit challenging but while there are many discrete steps, they are \nindividually straightforward. This guide will walk you through getting setup quickly with PHPStorm.\n\n\n\n\nApplies to use of the Phase2 Docker Images\n\n\nThis documentation specifically pertains to using Phase2's \nApache-PHP Docker Images\n \nor the Phase2 \nDrupal Build Image\n.\n\n\ndevtools-cli\n itself is only relevant in that it brokers standardized DNS practices.\n\n\n\n\n\n\nMake sure your environment is up-to-date\n\n\nIn case there might be fixes for any problems you might encounter, consider \nupdating devtools\n before \nproceeding.\n\n\nOnce done, run \ndevtools doctor\n to confirm devtools is in a healthy. Check out \nTroubleshooting\n \nor the \nF.A.Q.\n if anything comes up.\n\n\nIf you haven't updated your Docker Images in awhile, doing so now is a good precautionary step that you have everything \nyou need. Check out the \nRoutine Image Maintenance\n\n\n\n\nSetup Steps\n\n\n1. Activate Xdebug for your running Drupal site\n\n\nIn your docker command or your docker-compose.yml manifest, ensure the environment variable \nPHP_XDEBUG=\"true\"\n. This \nwill load the PHP Xdebug extension with the default configuration.\n\n\nFor details of the Xdebug configuration of Phase2's Apache PHP containers, check out the \napache-php-base DockerHub page\n.\n\n\n2. Configure PHPStorm for Xdebug\n\n\nTo get started configuring your PHPStorm IDE open the application settings.\n\n\nClick on the wrench icon in the toolbar:\n\n\n\n\nYou can also get to the project settings by going to: PHPStorm \n Preferences (OSX) or File \n Settings (Windows, Linux).\n\n\n3. Adjust the PHP Project settings.\n\n\nMake sure you have the correct version of PHP selected:\n\n\n\n\n4. Adjust the Debug Project settings.\n\n\n\n\nXdebug is using Port 9000.\n\n\nAccept external connections.\n\n\n\n\n\n\n\n\nEyes on Your Xdebug Configuration\n\n\nYou can view your Xdebug configuration by looking inside the Apache container.\nWith the container name (found via \ndocker ps\n), try running:\n\n\ndocker exec [container_name] /usr/bin/env cat /etc/opt/remi/php70/php.d/15-xdebug.ini\n\n\nif using docker-compose with your Apache container named *\nwww\n, you can more simply run:\n\n\ndocker-compose exec www /usr/bin/env cat /etc/opt/remi/php70/php.d/15-xdebug.ini\n\n\nThis path varies by PHP version. For PHP 5.6 check \n/etc/opt/rh/rh-php56/php.d/15-xdebug.ini\n.\n\n\n\n\n5. For the DBGp Proxy, just ensure that the port is the same.\n\n\nYou can leave the other settings blank.\n\n\n\n\n6. Adjust the Server Project settings.\n\n\nCreate a new Server by clicking on the \"+\" button. Give your server a name and input the host.\n\n\nBe sure to add the docroot mappings. The example shown here is using the \nGrunt Drupal Tasks\n \nproject structure. There are two mappings in this case. One for the docroot (\nbuild/html\n) and the other for the \nsrc\n \ndirectory so that breakpoints can be set in the custom modules in the \nsrc\n directory as well.\n\n\nThese mappings are used to match paths from inside the Docker container to the paths\nused in the local filesystem where PHPStorm is run.\n\n\n\n\n7. Validate your debug settings.\n\n\n\n\nProxies Interfere with Xdebug\n\n\nWhen setting your server URL, be sure to use the URL associated with your web container. If you are using a proxy \n(such as Varnish) that URL may validate but will not work in practice.\n\n\n\n\nSelect the \"Web Server Debug Validation\" option from the \"Run\" menu option. (Confirm your Apache container is running \nor this validation will fail.)\n\n\n\n\nThis will display a dialog window that allows you to validate your settings. Make sure that your \"Path to create \nvalidation script\" points to your project docroot and the URL is your project URL.\n\n\nIf all goes well, clicking the \"Validate\" button should give you something like this:\n\n\n\n\nClick the dialog 'x' (close) button to close this dialog window.\n\n\n8. Restart PHPStorm.\n\n\nIn order to ensure that all your settings are applying, you will need to restart PHPStorm.\n\n\n9. Make sure that you listen for connections!\n\n\n\n\n10. Configure a Debugger\n\n\n\n\nSelect Run -\n Edit Configurations from the main PHPStorm menu\n\n\nClick + and add a \"PHP Web Application\"\n\n\nGive it a name, then select the Server defined in the previous section from the drop-down menu.\n\n\nEnter a Start URL of \n/\n.\n\n\nSelect your Browser (e.g. Chrome)\n\n\nClick \nOK\n.\n\n\n\n\n\n\nOverriding the Default Xdebug Configuration\n\n\nIf your project or workflow has special needs, you can override the Xdebug configuration\nusing Volume Mounts to substitute your own template file. Copy \nthe original template\n \ninto your project and make the necessary changes. (You can also pull your current version of this file from the locally \nrunning docker image.)\n\n\nCommit your version of the file and add a volume mount to your docker-compose manifest with an entry such as:\n\n\n./env/local/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl\n\n\n\n\nOnce that's in place, you will have to restart the container to pick up the new volume mount:\n\n\ndocker-compose restart www",
            "title": "Using Xdebug with PHPStorm"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#local-xdebug-with-devtools-phpstorm",
            "text": "Getting  Xdebug  set up can be a bit challenging but while there are many discrete steps, they are \nindividually straightforward. This guide will walk you through getting setup quickly with PHPStorm.   Applies to use of the Phase2 Docker Images  This documentation specifically pertains to using Phase2's  Apache-PHP Docker Images  \nor the Phase2  Drupal Build Image .  devtools-cli  itself is only relevant in that it brokers standardized DNS practices.    Make sure your environment is up-to-date  In case there might be fixes for any problems you might encounter, consider  updating devtools  before \nproceeding.  Once done, run  devtools doctor  to confirm devtools is in a healthy. Check out  Troubleshooting  \nor the  F.A.Q.  if anything comes up.  If you haven't updated your Docker Images in awhile, doing so now is a good precautionary step that you have everything \nyou need. Check out the  Routine Image Maintenance",
            "title": "Local Xdebug with DevTools &amp; PHPStorm"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#setup-steps",
            "text": "",
            "title": "Setup Steps"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#1-activate-xdebug-for-your-running-drupal-site",
            "text": "In your docker command or your docker-compose.yml manifest, ensure the environment variable  PHP_XDEBUG=\"true\" . This \nwill load the PHP Xdebug extension with the default configuration.  For details of the Xdebug configuration of Phase2's Apache PHP containers, check out the  apache-php-base DockerHub page .",
            "title": "1. Activate Xdebug for your running Drupal site"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#2-configure-phpstorm-for-xdebug",
            "text": "To get started configuring your PHPStorm IDE open the application settings.  Click on the wrench icon in the toolbar:   You can also get to the project settings by going to: PHPStorm   Preferences (OSX) or File   Settings (Windows, Linux).",
            "title": "2. Configure PHPStorm for Xdebug"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#3-adjust-the-php-project-settings",
            "text": "Make sure you have the correct version of PHP selected:",
            "title": "3. Adjust the PHP Project settings."
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#4-adjust-the-debug-project-settings",
            "text": "Xdebug is using Port 9000.  Accept external connections.     Eyes on Your Xdebug Configuration  You can view your Xdebug configuration by looking inside the Apache container.\nWith the container name (found via  docker ps ), try running:  docker exec [container_name] /usr/bin/env cat /etc/opt/remi/php70/php.d/15-xdebug.ini  if using docker-compose with your Apache container named * www , you can more simply run:  docker-compose exec www /usr/bin/env cat /etc/opt/remi/php70/php.d/15-xdebug.ini  This path varies by PHP version. For PHP 5.6 check  /etc/opt/rh/rh-php56/php.d/15-xdebug.ini .",
            "title": "4. Adjust the Debug Project settings."
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#5-for-the-dbgp-proxy-just-ensure-that-the-port-is-the-same",
            "text": "You can leave the other settings blank.",
            "title": "5. For the DBGp Proxy, just ensure that the port is the same."
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#6-adjust-the-server-project-settings",
            "text": "Create a new Server by clicking on the \"+\" button. Give your server a name and input the host.  Be sure to add the docroot mappings. The example shown here is using the  Grunt Drupal Tasks  \nproject structure. There are two mappings in this case. One for the docroot ( build/html ) and the other for the  src  \ndirectory so that breakpoints can be set in the custom modules in the  src  directory as well.  These mappings are used to match paths from inside the Docker container to the paths\nused in the local filesystem where PHPStorm is run.",
            "title": "6. Adjust the Server Project settings."
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#7-validate-your-debug-settings",
            "text": "Proxies Interfere with Xdebug  When setting your server URL, be sure to use the URL associated with your web container. If you are using a proxy \n(such as Varnish) that URL may validate but will not work in practice.   Select the \"Web Server Debug Validation\" option from the \"Run\" menu option. (Confirm your Apache container is running \nor this validation will fail.)   This will display a dialog window that allows you to validate your settings. Make sure that your \"Path to create \nvalidation script\" points to your project docroot and the URL is your project URL.  If all goes well, clicking the \"Validate\" button should give you something like this:   Click the dialog 'x' (close) button to close this dialog window.",
            "title": "7. Validate your debug settings."
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#8-restart-phpstorm",
            "text": "In order to ensure that all your settings are applying, you will need to restart PHPStorm.",
            "title": "8. Restart PHPStorm."
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#9-make-sure-that-you-listen-for-connections",
            "text": "",
            "title": "9. Make sure that you listen for connections!"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#10-configure-a-debugger",
            "text": "Select Run -  Edit Configurations from the main PHPStorm menu  Click + and add a \"PHP Web Application\"  Give it a name, then select the Server defined in the previous section from the drop-down menu.  Enter a Start URL of  / .  Select your Browser (e.g. Chrome)  Click  OK .",
            "title": "10. Configure a Debugger"
        },
        {
            "location": "/common-tasks/using-xdebug-with-phpstorm/#overriding-the-default-xdebug-configuration",
            "text": "If your project or workflow has special needs, you can override the Xdebug configuration\nusing Volume Mounts to substitute your own template file. Copy  the original template  \ninto your project and make the necessary changes. (You can also pull your current version of this file from the locally \nrunning docker image.)  Commit your version of the file and add a volume mount to your docker-compose manifest with an entry such as:  ./env/local/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl  Once that's in place, you will have to restart the container to pick up the new volume mount:  docker-compose restart www",
            "title": "Overriding the Default Xdebug Configuration"
        },
        {
            "location": "/common-tasks/accessing-logs/",
            "text": "Accessing Logs\n\n\nViewing logs from my container service(s)?\n\n\nWhen you start a your containers via \ndocker-compose up\n all of the defined services will start in the foreground. All \nlog output to stdout/stderr within each container will be output the console.  Each entry will be prefixed with the name \nof the running container to identify the source of the log message.\n\n\nIf log output is not coming directly to the console you can \nSSH into the container\n \nand browse the file system for logs. Most common services will provide some log output in \n/var/log\n.",
            "title": "Accessing logs"
        },
        {
            "location": "/common-tasks/accessing-logs/#accessing-logs",
            "text": "",
            "title": "Accessing Logs"
        },
        {
            "location": "/common-tasks/accessing-logs/#viewing-logs-from-my-container-services",
            "text": "When you start a your containers via  docker-compose up  all of the defined services will start in the foreground. All \nlog output to stdout/stderr within each container will be output the console.  Each entry will be prefixed with the name \nof the running container to identify the source of the log message.  If log output is not coming directly to the console you can  SSH into the container  \nand browse the file system for logs. Most common services will provide some log output in  /var/log .",
            "title": "Viewing logs from my container service(s)?"
        },
        {
            "location": "/common-tasks/ssh-keys-for-private-repos/",
            "text": "SSH Keys for Private Repos\n\n\nForward/Import your SSH Key into the build container to clone private repos\n\n\nCertain containers like jenkins and devtools-build may need your private key. This is supported by importing your \nprivate key into the container via a volume mount.  \n\n\nTo get your private key into the build container, volume mount your key into the container at \n/root/.ssh/devtools.key\n \nand it will be processed accordingly.\n\n\n~/.ssh/id_rsa:/root/.ssh/devtools.key",
            "title": "SSH Keys for private repos"
        },
        {
            "location": "/common-tasks/ssh-keys-for-private-repos/#ssh-keys-for-private-repos",
            "text": "",
            "title": "SSH Keys for Private Repos"
        },
        {
            "location": "/common-tasks/ssh-keys-for-private-repos/#forwardimport-your-ssh-key-into-the-build-container-to-clone-private-repos",
            "text": "Certain containers like jenkins and devtools-build may need your private key. This is supported by importing your \nprivate key into the container via a volume mount.    To get your private key into the build container, volume mount your key into the container at  /root/.ssh/devtools.key  \nand it will be processed accordingly.  ~/.ssh/id_rsa:/root/.ssh/devtools.key",
            "title": "Forward/Import your SSH Key into the build container to clone private repos"
        },
        {
            "location": "/common-tasks/setting-up-mail/",
            "text": "Setting Up Mail\n\n\nEmail is something that many projects need, but during development you likely do \nnot want to actually send email, but you'd rather have sent mail captured for examination\nand released to a real mail server only in certain situations.\n\n\nTo handle these and other situations we recommend \nMailhog\n\n\nUsing Mailhog\n\n\nMailhog can be added as another service with your projects Docker Compose file.\n\n\nSee the mail service defined in the \nDevTools Example Mail Project\n\nthat service can be copied into your projects \ndocker-compose.yml\n file, or kept \nseparate and started as needed.\n\n\nUsing the configuration from the example you would configure your application \nto use \nmail.devtools.vm:1025\n as your SMTP server and you could view captured \nmail (and choose to release it) via the web interface accessible at http://mail.devtools.vm:8025",
            "title": "Seting up mail"
        },
        {
            "location": "/common-tasks/setting-up-mail/#setting-up-mail",
            "text": "Email is something that many projects need, but during development you likely do \nnot want to actually send email, but you'd rather have sent mail captured for examination\nand released to a real mail server only in certain situations.  To handle these and other situations we recommend  Mailhog",
            "title": "Setting Up Mail"
        },
        {
            "location": "/common-tasks/setting-up-mail/#using-mailhog",
            "text": "Mailhog can be added as another service with your projects Docker Compose file.  See the mail service defined in the  DevTools Example Mail Project \nthat service can be copied into your projects  docker-compose.yml  file, or kept \nseparate and started as needed.  Using the configuration from the example you would configure your application \nto use  mail.devtools.vm:1025  as your SMTP server and you could view captured \nmail (and choose to release it) via the web interface accessible at http://mail.devtools.vm:8025",
            "title": "Using Mailhog"
        },
        {
            "location": "/common-tasks/dns-resolution/",
            "text": "DNS Resolution\n\n\nDNS Names for your containers\n\n\nWithin the \nlabels\n section of the docker-compose file you can specify labels that will control the DNS name of your \ncontainers.  DNS names are in the format of \n[name].[image].vm\n (e.g web.devtools.vm)  \n\n\n\n\n\n\ncom.dnsdock.name\n - This is the type of container. Usually something like web, db, cache, etc.\n\n\n\n\n\n\ncom.dnsdock.image\n - This is generally your project name (e.g devtools, drupal, etc.)\n\n\n\n\n\n\n\n\nNote\n\n\nAll DNS names of devtools containers will end in \n.vm\n\n\n\n\nIf you need multiple domains mapped to a container you can use the \ncom.dnsdock.alias\n setting. It takes a full domain \nname and can take a comma separated list (e.g. otherhost.devtools.vm or alexandria.phase2.vm). Additionally, dnsdock \nsupports longer domain queries meaning if you have a service named web.devtools.vm, you can also use \nsomething.web.devtools.vm and it will resolve to the same IP address.\n\n\nFor all other DNS configuration options, please see the \ndnsdock label documentation\n\n\nDNS Forwarders\n\n\nDevTools can be configured to use additional name servers to forward DNS requests if the record cannot be resolved by dnsdock.\n\n\nAn example is if you connect to a VPN and need to resolve addresses to private servers within a VPN.  To enable this you \nneed to configure the \nDEVTOOLS_NAMESERVERS\n environment variable to a comma separated list of \nip:port\n \n(example: \n10.10.7.2:53,8.8.8.8:53\n) before running either \ndevtools start\n or \ndevtools dns\n. We suggest putting this \nenv var configuration in your \n~/.bashrc\n or \n~/.zshrc\n so that it is always present when needed.  If you just need this \ntemporarily, you can pass the configuration in with the \n--nameservers\n command line option to \ndevtools start\n or \ndevtools dns\n. \n\n\nThis configuration will try each forwarder name server, in order, to resolve names until success or all name servers \nhave been exhausted.\n\n\nDNS Command\n\n\nThere is also a \ndevtools dns\n command that will launch and configure our DNS services on any Docker Host. If you want to \nconfigure DNS on a Docker Host other than \ndev\n be sure to specify the \n--name\n parameter.\n\n\nDNS Debugging\n\n\nIf you want to see what containers have registered names, use the \ndevtools dns-records\n command. This command will list \nall registered container names and aliases along with the container's IP address.",
            "title": "DNS Resolution"
        },
        {
            "location": "/common-tasks/dns-resolution/#dns-resolution",
            "text": "",
            "title": "DNS Resolution"
        },
        {
            "location": "/common-tasks/dns-resolution/#dns-names-for-your-containers",
            "text": "Within the  labels  section of the docker-compose file you can specify labels that will control the DNS name of your \ncontainers.  DNS names are in the format of  [name].[image].vm  (e.g web.devtools.vm)      com.dnsdock.name  - This is the type of container. Usually something like web, db, cache, etc.    com.dnsdock.image  - This is generally your project name (e.g devtools, drupal, etc.)     Note  All DNS names of devtools containers will end in  .vm   If you need multiple domains mapped to a container you can use the  com.dnsdock.alias  setting. It takes a full domain \nname and can take a comma separated list (e.g. otherhost.devtools.vm or alexandria.phase2.vm). Additionally, dnsdock \nsupports longer domain queries meaning if you have a service named web.devtools.vm, you can also use \nsomething.web.devtools.vm and it will resolve to the same IP address.  For all other DNS configuration options, please see the  dnsdock label documentation",
            "title": "DNS Names for your containers"
        },
        {
            "location": "/common-tasks/dns-resolution/#dns-forwarders",
            "text": "DevTools can be configured to use additional name servers to forward DNS requests if the record cannot be resolved by dnsdock.  An example is if you connect to a VPN and need to resolve addresses to private servers within a VPN.  To enable this you \nneed to configure the  DEVTOOLS_NAMESERVERS  environment variable to a comma separated list of  ip:port  \n(example:  10.10.7.2:53,8.8.8.8:53 ) before running either  devtools start  or  devtools dns . We suggest putting this \nenv var configuration in your  ~/.bashrc  or  ~/.zshrc  so that it is always present when needed.  If you just need this \ntemporarily, you can pass the configuration in with the  --nameservers  command line option to  devtools start  or  devtools dns .   This configuration will try each forwarder name server, in order, to resolve names until success or all name servers \nhave been exhausted.",
            "title": "DNS Forwarders"
        },
        {
            "location": "/common-tasks/dns-resolution/#dns-command",
            "text": "There is also a  devtools dns  command that will launch and configure our DNS services on any Docker Host. If you want to \nconfigure DNS on a Docker Host other than  dev  be sure to specify the  --name  parameter.",
            "title": "DNS Command"
        },
        {
            "location": "/common-tasks/dns-resolution/#dns-debugging",
            "text": "If you want to see what containers have registered names, use the  devtools dns-records  command. This command will list \nall registered container names and aliases along with the container's IP address.",
            "title": "DNS Debugging"
        },
        {
            "location": "/common-tasks/upgrading-devtools/",
            "text": "Upgrading DevTools\n\n\nUpgrade devtools CLI\n\n\nHomebrew\n\n\nIf you installed devtools via Homebrew, you can check for updates by running\n\n\nbrew update\nbrew upgrade devtools\n\n\n\n\nTesting your installation.\n\n\nRun \ndevtools doctor\n to confirm the system is in good working order.\n\n\nUpgrading your Docker Host\n\n\nIf your \nbrew upgrade\n happens to also update docker, when running \ndevtools doctor\n you \nmay get a warning about an incompatible Docker version in your Docker Host VM. In that case use the\n\ndevtools upgrade\n command to upgrade your Docker Host VM to a compatible version.",
            "title": "Upgrading DevTools"
        },
        {
            "location": "/common-tasks/upgrading-devtools/#upgrading-devtools",
            "text": "",
            "title": "Upgrading DevTools"
        },
        {
            "location": "/common-tasks/upgrading-devtools/#upgrade-devtools-cli",
            "text": "",
            "title": "Upgrade devtools CLI"
        },
        {
            "location": "/common-tasks/upgrading-devtools/#homebrew",
            "text": "If you installed devtools via Homebrew, you can check for updates by running  brew update\nbrew upgrade devtools",
            "title": "Homebrew"
        },
        {
            "location": "/common-tasks/upgrading-devtools/#testing-your-installation",
            "text": "Run  devtools doctor  to confirm the system is in good working order.",
            "title": "Testing your installation."
        },
        {
            "location": "/common-tasks/upgrading-devtools/#upgrading-your-docker-host",
            "text": "If your  brew upgrade  happens to also update docker, when running  devtools doctor  you \nmay get a warning about an incompatible Docker version in your Docker Host VM. In that case use the devtools upgrade  command to upgrade your Docker Host VM to a compatible version.",
            "title": "Upgrading your Docker Host"
        },
        {
            "location": "/common-tasks/multiple-docker-machines/",
            "text": "Multiple Docker Machines\n\n\nThere are special cases in which you may want to have multiple Docker Hosts running, or use a Docker Machine from \nanother client/project. One example of this might be to test the performance differences between VirtualBox and xhyve.  \n\n\nFor these cases, all \ndevtools\n commands that interact with a Docker Host take a \n--name\n flag that will allow you to \nspecify name of the Docker Host. For all commands this name defaults to \ndev\n but you can configure this name if needed.\n\nAlso, if you don't want to specify the Docker Host name on every command you can specify the \nDEVTOOLS_ACTIVE_MACHINE\n \nenvironment variable to be Docker Machine name of the VM you care to interact with.  This way you can set it once and \nforget about it.  Unless otherwise specified, the name defaults to \ndev\n for all commands.",
            "title": "Multiple Docker Machines"
        },
        {
            "location": "/common-tasks/multiple-docker-machines/#multiple-docker-machines",
            "text": "There are special cases in which you may want to have multiple Docker Hosts running, or use a Docker Machine from \nanother client/project. One example of this might be to test the performance differences between VirtualBox and xhyve.    For these cases, all  devtools  commands that interact with a Docker Host take a  --name  flag that will allow you to \nspecify name of the Docker Host. For all commands this name defaults to  dev  but you can configure this name if needed. \nAlso, if you don't want to specify the Docker Host name on every command you can specify the  DEVTOOLS_ACTIVE_MACHINE  \nenvironment variable to be Docker Machine name of the VM you care to interact with.  This way you can set it once and \nforget about it.  Unless otherwise specified, the name defaults to  dev  for all commands.",
            "title": "Multiple Docker Machines"
        },
        {
            "location": "/common-tasks/routine-image-maintenance/",
            "text": "Routine Image Maintenance\n\n\nRestart devtools on a regular basis to minimize the risk of filesystem or other performance problems with your containers.\n\n\nDocker Image Updates\n\n\nPeriodically update your Docker Images to ensure you have the correct configuration. This should be done in coordination\nwith members of your project team so you are all working from the same version of image. Ideally all images in compose \nfiles are working off of tags to ensure consistency.  Images shoudl be pulled frequently though especially for images \nthat are tagged with a language version, like \nphp70\n. Updates may go into those images and keep the same tag, so pulling\nregularly (and coordinating) will ensure you are getting state of the art.\n\n\nIf your project uses \"loosely versioned\" Docker images (such as specifying \nlatest\n as an image version tag or no tag\nat all which will default to \nlatest\n) your local update schedule should be coordinated with updates to other environments\nand team members.\n\n\nHere is how to update your images\n\n\n// Stop your containers in case they are running.\ndocker-compose stop\n\n// Pull the latest changes for all images referenced in docker-compose.yml\ndocker-compose pull\n// Pull the latest changes for all images referenced in build.yml.\ndocker-compose -f build.yml pull\n\n// Remove your old containers to make sure you're using the latest images.\ndocker-compose rm\n\n// Re-create your containers based on the freshly updated images.\ndocker-compose up -d\n\n\n\n\nUpdates for a Specified Image\n\n\ndocker pull phase2/devtools-build:php70\n\n\n\n\nIf either form of \npull\n command fails, try re-running with the \n--no-cache\n option.",
            "title": "Routine Image Maintenance"
        },
        {
            "location": "/common-tasks/routine-image-maintenance/#routine-image-maintenance",
            "text": "Restart devtools on a regular basis to minimize the risk of filesystem or other performance problems with your containers.",
            "title": "Routine Image Maintenance"
        },
        {
            "location": "/common-tasks/routine-image-maintenance/#docker-image-updates",
            "text": "Periodically update your Docker Images to ensure you have the correct configuration. This should be done in coordination\nwith members of your project team so you are all working from the same version of image. Ideally all images in compose \nfiles are working off of tags to ensure consistency.  Images shoudl be pulled frequently though especially for images \nthat are tagged with a language version, like  php70 . Updates may go into those images and keep the same tag, so pulling\nregularly (and coordinating) will ensure you are getting state of the art.  If your project uses \"loosely versioned\" Docker images (such as specifying  latest  as an image version tag or no tag\nat all which will default to  latest ) your local update schedule should be coordinated with updates to other environments\nand team members.  Here is how to update your images  // Stop your containers in case they are running.\ndocker-compose stop\n\n// Pull the latest changes for all images referenced in docker-compose.yml\ndocker-compose pull\n// Pull the latest changes for all images referenced in build.yml.\ndocker-compose -f build.yml pull\n\n// Remove your old containers to make sure you're using the latest images.\ndocker-compose rm\n\n// Re-create your containers based on the freshly updated images.\ndocker-compose up -d",
            "title": "Docker Image Updates"
        },
        {
            "location": "/common-tasks/routine-image-maintenance/#updates-for-a-specified-image",
            "text": "docker pull phase2/devtools-build:php70  If either form of  pull  command fails, try re-running with the  --no-cache  option.",
            "title": "Updates for a Specified Image"
        },
        {
            "location": "/common-tasks/creating-your-own-images/",
            "text": "Creating your own images\n\n\nCreating a Dockerfile\n\n\nThe Dockerfile you create for your project should represent the application as it will need to run in production. There \nare many reasons to have a Dockerfile to create an image, but if you don't intend on running containers in production \nyou can likely skip this part. \n\n\nThe most minimal project container will need to have your code in it.\n\n\n\n\n\n\nStart by determining which Docker image you will need to extend. \n\n\n\n\n\n\nFor the general Drupal use cases you will base your project Dockerfile on apache-php:php70.\n\n\n\n\nFROM phase2/apache-php:php70\n\n\n\n\n\n\n\n\nThen copy your code into the correct place for the container. For a PHP/Drupal project, copy the materialized site code into the container docroot\n\n\n\n\nCOPY ./html /var/www/html/\n\n\n\n\n\n\n\n\nBuild the Dockerfile into an image\n\n\n\n\ndocker build -t \nsome-name\n .\n\n\n\n\n\n\n\n\nOn successful build, test the image by running\n\n\n\n\ndocker run -t \nsome-name\n\n\n\n\n\n\n\n\nHere is the full (simple) Dockerfile\n\n\nFROM phase2/apache-php:php70\n\n# Copy in the site\nCOPY ./html /var/www/html/",
            "title": "Creating your own images"
        },
        {
            "location": "/common-tasks/creating-your-own-images/#creating-your-own-images",
            "text": "",
            "title": "Creating your own images"
        },
        {
            "location": "/common-tasks/creating-your-own-images/#creating-a-dockerfile",
            "text": "The Dockerfile you create for your project should represent the application as it will need to run in production. There \nare many reasons to have a Dockerfile to create an image, but if you don't intend on running containers in production \nyou can likely skip this part.   The most minimal project container will need to have your code in it.    Start by determining which Docker image you will need to extend.     For the general Drupal use cases you will base your project Dockerfile on apache-php:php70.   FROM phase2/apache-php:php70     Then copy your code into the correct place for the container. For a PHP/Drupal project, copy the materialized site code into the container docroot   COPY ./html /var/www/html/     Build the Dockerfile into an image   docker build -t  some-name  .     On successful build, test the image by running   docker run -t  some-name     Here is the full (simple) Dockerfile  FROM phase2/apache-php:php70\n\n# Copy in the site\nCOPY ./html /var/www/html/",
            "title": "Creating a Dockerfile"
        },
        {
            "location": "/faq/general/",
            "text": "General FAQ\n\n\nHow do I configure my web container / vhosts so I can run multiple projects at once from the same web container?\n\n\nYou don\u2019t. Seriously. This is a place where you must change your thinking from that of treating a \nserver\n as a unit to \ntreating the \nservice\n as a unit. If you have multiple projects active at once, you\u2019ll have a web serving container \nactive for each of them. This is ok because containers are much lighter weight than full virtual machines, though you do \nwant to be careful about starting too many at once.  Consider that you will have a docker-compose file for each project \nyou are working on, and each docker-compose file represents your application and all the services required to run it.\n\nYou could be running multiple docker-compose applications on a single Docker Host.  Realistically, for the performance \nof your computer you would stop one docker-compose environment before you would run another.\n\n\nHow do I see what containers are running on my Docker Host?\n\n\nIf you want to see how many containers are present within your Docker Host VM and check on the status of them just \nrun \ndocker ps\n This will show you the containers running, the image they are based on, the ports they expose and the \nname of the container.\n\n\nTo see all the containers on the Docker Host both running and stopped use the command  \ndocker ps -a\n\n\nWhy do I have so many containers / cleanup?\n\n\nAny time you finish a project or you need to \nreset\n things, you should clean up your containers for a project by running \n\ndocker-compose rm\n. That will remove the instances for the containers specified in your docker compose file.\n\n\nAdditionally you can run \ndevtools prune\n to clear out all stopped containers and any dangling images.\n\n\nIs there any regular maintenance needed?\n\n\nYes, to keep your environment working smoothly and with current infrastructure configurations, implement a personal \nregimen of \nRoutine Image Maintenance\n.\n\n\nWorking with multiple Docker versions [Homebrew]\n\n\nIf you have multiple versions installed, doing \nbrew info docker-compose\n will list the versions you have installed. The \none with the \n\"*\"\n will be the version that is active.\n\n\nIf you need to switch versions, use the \nbrew switch\n command and run any additional commands like \nbrew unlink ...\n. \n(The \nswitch\n command will provide next command steps if you need to link or unlink any formulae).\n\n\nExample:\n\n\nbrew switch docker 1.9.1\n\n\n\n\nCan I get .vm container names a Docker Host not created with DevTools?\n\n\nYes, with an important caveat that containers will not be able to resolve .vm addresses without reconfiguring the daemon.\n\n\nThe \ndevtools dns\n command can accept a \n--name\n parameter to run the DNS services on an existing Docker Host\n\n\nWhen we start a machine with \ndevtools start\n, we do the following things:\n\n\n\n\nStart a machine with the \n-dns=172.17.0.1\n Docker daemon option set so that all containers will try dnsdock for DNS\n\n\nRun dnsdock bound to \n172.17.0.1:53\n to provide .vm addresses for all containers\n\n\nSet up Mac OS X to route 172.17.0.1/16 to the Docker virtual machine's IP so the host machine can access containers direct\n\n\nSet up \n/etc/resolver/vm\n so that OS X will look up .vm addresses through DNS queries to \n172.17.0.1\n\n\n\n\nIf you run \ndevtools dns --name=$DOCKER_MACHINE_NAME\n, every step except the first will run, so your OS X host will be \nable to reach containers by their .vm addresses but other containers will not. This is the major difference between \ncreating a machine with \ndevtools start\n and applying the DNS configuration to an existing machine with \ndevtools dns\n.\n\n\nMonitoring of containers\n\n\nIf you need some insight into how many resources a given Docker container may be using, take advantage of the command \n\ndocker stats \ncontainer name\n.  This handy command will show you CPU%, Memory%, Memory Usage vs Limit, and Network I/O.\n\nIt is rudimentary but can be very useful in the first line of inspection on a container.",
            "title": "General"
        },
        {
            "location": "/faq/general/#general-faq",
            "text": "",
            "title": "General FAQ"
        },
        {
            "location": "/faq/general/#how-do-i-configure-my-web-container-vhosts-so-i-can-run-multiple-projects-at-once-from-the-same-web-container",
            "text": "You don\u2019t. Seriously. This is a place where you must change your thinking from that of treating a  server  as a unit to \ntreating the  service  as a unit. If you have multiple projects active at once, you\u2019ll have a web serving container \nactive for each of them. This is ok because containers are much lighter weight than full virtual machines, though you do \nwant to be careful about starting too many at once.  Consider that you will have a docker-compose file for each project \nyou are working on, and each docker-compose file represents your application and all the services required to run it. \nYou could be running multiple docker-compose applications on a single Docker Host.  Realistically, for the performance \nof your computer you would stop one docker-compose environment before you would run another.",
            "title": "How do I configure my web container / vhosts so I can run multiple projects at once from the same web container?"
        },
        {
            "location": "/faq/general/#how-do-i-see-what-containers-are-running-on-my-docker-host",
            "text": "If you want to see how many containers are present within your Docker Host VM and check on the status of them just \nrun  docker ps  This will show you the containers running, the image they are based on, the ports they expose and the \nname of the container.  To see all the containers on the Docker Host both running and stopped use the command   docker ps -a",
            "title": "How do I see what containers are running on my Docker Host?"
        },
        {
            "location": "/faq/general/#why-do-i-have-so-many-containers-cleanup",
            "text": "Any time you finish a project or you need to  reset  things, you should clean up your containers for a project by running  docker-compose rm . That will remove the instances for the containers specified in your docker compose file.  Additionally you can run  devtools prune  to clear out all stopped containers and any dangling images.",
            "title": "Why do I have so many containers / cleanup?"
        },
        {
            "location": "/faq/general/#is-there-any-regular-maintenance-needed",
            "text": "Yes, to keep your environment working smoothly and with current infrastructure configurations, implement a personal \nregimen of  Routine Image Maintenance .",
            "title": "Is there any regular maintenance needed?"
        },
        {
            "location": "/faq/general/#working-with-multiple-docker-versions-homebrew",
            "text": "If you have multiple versions installed, doing  brew info docker-compose  will list the versions you have installed. The \none with the  \"*\"  will be the version that is active.  If you need to switch versions, use the  brew switch  command and run any additional commands like  brew unlink ... . \n(The  switch  command will provide next command steps if you need to link or unlink any formulae).  Example:  brew switch docker 1.9.1",
            "title": "Working with multiple Docker versions [Homebrew]"
        },
        {
            "location": "/faq/general/#can-i-get-vm-container-names-a-docker-host-not-created-with-devtools",
            "text": "Yes, with an important caveat that containers will not be able to resolve .vm addresses without reconfiguring the daemon.  The  devtools dns  command can accept a  --name  parameter to run the DNS services on an existing Docker Host  When we start a machine with  devtools start , we do the following things:   Start a machine with the  -dns=172.17.0.1  Docker daemon option set so that all containers will try dnsdock for DNS  Run dnsdock bound to  172.17.0.1:53  to provide .vm addresses for all containers  Set up Mac OS X to route 172.17.0.1/16 to the Docker virtual machine's IP so the host machine can access containers direct  Set up  /etc/resolver/vm  so that OS X will look up .vm addresses through DNS queries to  172.17.0.1   If you run  devtools dns --name=$DOCKER_MACHINE_NAME , every step except the first will run, so your OS X host will be \nable to reach containers by their .vm addresses but other containers will not. This is the major difference between \ncreating a machine with  devtools start  and applying the DNS configuration to an existing machine with  devtools dns .",
            "title": "Can I get .vm container names a Docker Host not created with DevTools?"
        },
        {
            "location": "/faq/general/#monitoring-of-containers",
            "text": "If you need some insight into how many resources a given Docker container may be using, take advantage of the command  docker stats  container name .  This handy command will show you CPU%, Memory%, Memory Usage vs Limit, and Network I/O. \nIt is rudimentary but can be very useful in the first line of inspection on a container.",
            "title": "Monitoring of containers"
        },
        {
            "location": "/faq/troubleshooting/",
            "text": "Troubleshooting\n\n\nSee the following sections for common problems and ways to solve them.\n\n\nRun doctor\n\n\nRun \ndevtools doctor\n to determine if your environment is set to run DevTools.\n\n\nEnsure the environment is setup correctly\n\n\nIt can be useful to ensure everything is in a clean state. The following should ensure that\n\n\n\n\ndevtools stop\n stops the docker machine and cleans up networking\n\n\neval \"$(devtools config)\"\n clears environmental variables docker uses to communicate with the docker host\n\n\ndevtools start\n starts the docker machine\n\n\neval \"$(devtools config)\"\n sets environmental variables docker uses to communicate with the docker host\n\n\n\n\nEnsure your images are up to date\n\n\nFrom time to time images are updated to fix bugs or add functionality. You won't automatically receive these updates but \nyou can fetch them when you hear new ones are available.\n\n\ndocker pull imagename\n can be used if you want to update a specific image. For example, if you wanted to make sure you \nhad the latest dnsdock you'd run \ndocker pull phase2/dnsdock\n.\n\n\ndocker-compose pull\n can be used within a project directory to make sure you've got the latest version of all images \nin the docker-compose.yml file.\n\n\nConfigure Your Shell\n\n\nIf you do not have any containers listed when running \ndocker ps\n or you get an error message like:\n\n\nGet http:///var/run/docker.sock/v1.20/containers/json: dial unix /var/run/docker.sock: no such file or directory.\n\n* Are you trying to connect to a TLS-enabled daemon without TLS?\n\n* Is your docker daemon up and running?\n\n\n\nOr an error message like:\n\n\nCouldn't connect to Docker daemon - you might need to run `boot2docker up`.\n\n\n\nMake sure your shell has the necessary environment variables by running:\n\n\neval \"$(devtools config)\"\n\n\nReset everything\n\n\nIf a problem continue to persists and the Docker Host is non-responsive, you may need to resort to the nuclear option of \nblowing everything away and starting over. Note this is a \nnuclear option\n as even your persistent data area will be \nremoved if you don't back it up. If you have any data that needs to be maintained be sure to get a copy of it off of your \nVM first with the scripts provided.\n\n\nTo wipe everything out and start over\n\n\n\n\nFirst backup your existing data (if desired) by running \ndevtools data-backup\n. This will sync your entire \n/data\n \ndirectory to your host machine.\n\n\nThen you can run \ndevtools remove\n This removes the broken Docker Host and it\u2019s state, making way for a clean start.\n\n\nNext you can rebuild everything by running \ndevtools start\n. This will create you new Docker Host.\n\n\nIf you wish to restore the \n/data\n directory that you previously backed up, then run \ndevtools data-restore\n\n\n\n\nFiles Not Found\n\n\nIf you get messages about files not being found in the container that should be shared from your host computer, check the \nfollowing:\n\n\n\n\nIs the project checked out under the \n/Users\n folder? Only files under the \n/Users\n folder are shared into the \nDocker Host (and thus containers) by default.\n\n\nDoes the \ndocker-compose.yml\n file have a volume mount set up that contains the missing files?\n\n\nGet shell in the Docker container via \ndocker exec -it \ncontainer name\n /bin/bash\n and check if the files are \nshared in the wrong place.\n\n\nGet shell in the Docker Machine with \ndocker-machine ssh dev\n and check if you find the files under /Users.\n\n\n\n\nImage not found\n\n\nIf you encounter the following error about the Docker image not being found when starting a project, it may indicate \nthat the image is private and your Docker client is not logged into a required private Docker Hub repository:\n\n\nPulling repository phase2/privateimage\n\nError: image phase2/privateimage:latest not found\n\n\n\nTo solve this, run \ndocker login\n and provide the relevant credentials.\n\n\nDocker client and server version incompatibilities\n\n\nIf you see an error similar to this:\n\n\nError response from daemon: client is newer than server (client API version: 1.20, server API version: 1.19)\n\n\n\nYou likely need to upgrade your Docker Host to a get Docker client API compatibility. Do that with:\n\n\n`devtools upgrade`\n\n\n\nNetwork timed out and can't pull container image\n\n\nExample:\n\n\nPulling cache (phase2/memcache:latest)...\nPulling repository docker.io/phase2/memcache\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/phase2/memcache/images. You may want to check your internet connection or if you are behind a proxy.\n\n\n\n\nTry restarting docker-machine: \ndevtools restart\n\n\nStarted machines may have a new IP address\n\n\nExample:\n\n\nStarted machines may have new IP addresses. You may need to re-run the `docker-machine env` command.\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 1 of 10.\n...\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 10 of 10.\n[ERROR] Docker daemon failed to start!\n\n\n\n\nThe Docker Host (probably called dev) has it's IP changed. The generated TLS Certs are no longer valid and must be regenerated.\n\n\nPossible causes or relations/patterns:\n\n\n\n\nAnother VM was started in VirtualBox.\n\n\nMachine went to sleep and somehow caused issues with the running VM.\n\n\n\n\nFix:\n\n\nTry running: \ndocker-machine env\n\n\nIf that does not work, you should be able to start the VM directly through docker-machine: \ndocker-machine start dev\n\n\nNext, check the IP / TLS status by running: \ndocker-machine ls\n\n\nThe output will likely report something akin to:\n\n\ndev       -        virtualbox   Running   tcp://192.168.99.100:2376 Unknown\nUnable to query docker version: Get https://192.168.99.100:2376/v1.15/version: x509: certificate is valid for 192.168.99.101, not 192.168.99.100\n\n\n\n\nNow, regenerate the TLS Certs: \ndocker-machine regenerate-certs dev -f\n\nDevtools should now be able to start. Don't forget to run `eval \"$(devtools config)\" after.\n\n\nContainers Started but Service Not Available\n\n\nYour Docker Host is running, the project's containers are up, and command-line operations work fine. Why can't you view \nthe site in your web browser?\n\n\nDNS Services\n\n\nThe DNS services that DevTools spins up may not be working. Run \ndocker ps\n and see that you have a dnsdock and dnsmasq container.\n\n\nIf those services are not running, try \ndevtools dns\n to bring them up, or a full \ndevtools restart\n if that does not work.\n\n\ndevtools dns-records\n is also useful to see what containers have registered names.\n\n\nDNS Configuration\n\n\nIt is also possible that the DNS services are running for your environment, but somehow the configuration is wrong. Run \n\ndevtools dns-records\n and make sure your project has an entry. If not, you may need another restart, or perhaps you are \nmissing \nDNSDOCK_NAME\n and \nDNSDOCK_IMAGE\n environment variable entries in your docker-compose.yml manifest.\n\n\nSlow-starting Services\n\n\nSome services, such as Apache Solr or Varnish, can take longer to start up than Apache and PHP-FPM. As a result you might \nload the browser so fast that not all services are available, which in the case of a proxy may prevent the page from \nloading at all. Wait a short time and try reloading the page.\n\n\nFailed Health Checks\n\n\nSome services such as Varnish depend on others to operate, and have built-in health checks to verify the other service is operating.\n\n\nIf such a health check fails, there could be two problems:\n\n\n\n\nThe internal DNS routing between Docker containers is broken. Make sure the\nconfiguration of your services is correct.\n\n\nThe dependency (e.g., Apache behing Varnish) is not yet up and running when Varnish performs its checks.\n\n\n\n\nIn either case, you can often repair the problem by performing a clean restart of the broken service.\n\n\ndocker-compose stop proxy\ndocker-compose rm -f proxy\ndocker-compose up -d proxy\n\n\n\n\nYour other services should already be up and functional when this is done, so the health check will not fail on account of (2).\n\n\n\n\nChecking on Varnish Health\n\n\nIf you suspect Varnish may be failing, run \ndocker exec -it [VARNISH_CONTAINER] varnishlog\n and scan for VCL compilation errors.\n\n\n\n\nService Became Non-Responsive\n\n\nSometimes a service locks up. Apache stops serving results, Solr stops indexing or responding to search queries. These \nthings happen on servers all the time. It may even happen more often on Docker, especially since we are now using more \n\"infrastructure\" in our local environments.\n\n\nDocker is meant to easily sandbox these problems from the rest of your machine, and to easily resolve these problems by \nallowing you to dump the problem and start over fresh very easily.\n\n\nHard reset on a service (as describe above), is very much like a power cycle:\n\n\ndocker-compose stop [BROKEN_SERVICE]\ndocker-compose rm -f [BROKEN_SERVICE]\ndocker-compose up -d [BROKEN_SERVICE]\n\n\n\n\nSometimes data for a service is volume mounted from outside the container. This persistence is good when the data is \nhealthy, but can be really bad if the data is part of the problem (e.g., broken lockfiles).\n\n\ndocker-machine ssh [MACHINE_NAME]\nrm -Rf /data/[PROJECT]/[DIRECTORY_FOR_SERVICE]\n\n\n\n\nRemember that your service may have configuration or data in another service, you may need to perform this operation against multilpe containers (e.g., Solr)\n\n\nNFS Conflicts with other Environments\n\n\nRunning the Devtools VM in conjunction with other development environments (such as Vagrant) can sometimes cause conflicts \nwith volume mounts. This is due to the fact that the Devtools VM mounts the entirety of \n/Users\n into the VM on OS X. \nAdditional NFS mounts from other environments that target subdirectories of \n/Users\n will fail.\n\n\nThe easiest workaround is to keep projects that use non-Devtools environments like Vagrant in a directory \noutside\n of \n\n/Users\n, such as \n/opt\n. Alternatively, you can run a single VM at a time and manually clear out \n/etc/exports\n prior \nto switching environments/projects.\n\n\nMigrating Vagrant boxes outside of /Users:\n\n\nIf you'd like to move your vagrant boxes outside of your home directory, perform the following steps:\n\n\n\n\nChoose a destination folder.  We'll be using /opt/vms for this example. Insure the destination has enough free space. \nTypically this is not a problem because our Macs are one single partition.\n\n\nMake the new directory, and ensure your userid owns it:  \nsudo mkdir /opt/vms; sudo chown -R userid:userid /opt/vms\n\n\nAdd \nexport VAGRANT_HOME=/opt/vms\n to ~/.bash_profile\n\n\nMove your vagrant folders over to /opt/vms.\n\n\nedit /etc/exports, updating any vagrant mount point to use the new location.  (example: /Users/userid/vagrant/projectx/cms)\n\n\nWhile a reboot isn't neccesary, it'll help to make sure nothing is running and using the old mount points.\n\n\ncd into your new vagrant directory, and do a vagrant up.",
            "title": "Troubleshooting"
        },
        {
            "location": "/faq/troubleshooting/#troubleshooting",
            "text": "See the following sections for common problems and ways to solve them.",
            "title": "Troubleshooting"
        },
        {
            "location": "/faq/troubleshooting/#run-doctor",
            "text": "Run  devtools doctor  to determine if your environment is set to run DevTools.",
            "title": "Run doctor"
        },
        {
            "location": "/faq/troubleshooting/#ensure-the-environment-is-setup-correctly",
            "text": "It can be useful to ensure everything is in a clean state. The following should ensure that   devtools stop  stops the docker machine and cleans up networking  eval \"$(devtools config)\"  clears environmental variables docker uses to communicate with the docker host  devtools start  starts the docker machine  eval \"$(devtools config)\"  sets environmental variables docker uses to communicate with the docker host",
            "title": "Ensure the environment is setup correctly"
        },
        {
            "location": "/faq/troubleshooting/#ensure-your-images-are-up-to-date",
            "text": "From time to time images are updated to fix bugs or add functionality. You won't automatically receive these updates but \nyou can fetch them when you hear new ones are available.  docker pull imagename  can be used if you want to update a specific image. For example, if you wanted to make sure you \nhad the latest dnsdock you'd run  docker pull phase2/dnsdock .  docker-compose pull  can be used within a project directory to make sure you've got the latest version of all images \nin the docker-compose.yml file.",
            "title": "Ensure your images are up to date"
        },
        {
            "location": "/faq/troubleshooting/#configure-your-shell",
            "text": "If you do not have any containers listed when running  docker ps  or you get an error message like:  Get http:///var/run/docker.sock/v1.20/containers/json: dial unix /var/run/docker.sock: no such file or directory.\n\n* Are you trying to connect to a TLS-enabled daemon without TLS?\n\n* Is your docker daemon up and running?  Or an error message like:  Couldn't connect to Docker daemon - you might need to run `boot2docker up`.  Make sure your shell has the necessary environment variables by running:  eval \"$(devtools config)\"",
            "title": "Configure Your Shell"
        },
        {
            "location": "/faq/troubleshooting/#reset-everything",
            "text": "If a problem continue to persists and the Docker Host is non-responsive, you may need to resort to the nuclear option of \nblowing everything away and starting over. Note this is a  nuclear option  as even your persistent data area will be \nremoved if you don't back it up. If you have any data that needs to be maintained be sure to get a copy of it off of your \nVM first with the scripts provided.  To wipe everything out and start over   First backup your existing data (if desired) by running  devtools data-backup . This will sync your entire  /data  \ndirectory to your host machine.  Then you can run  devtools remove  This removes the broken Docker Host and it\u2019s state, making way for a clean start.  Next you can rebuild everything by running  devtools start . This will create you new Docker Host.  If you wish to restore the  /data  directory that you previously backed up, then run  devtools data-restore",
            "title": "Reset everything"
        },
        {
            "location": "/faq/troubleshooting/#files-not-found",
            "text": "If you get messages about files not being found in the container that should be shared from your host computer, check the \nfollowing:   Is the project checked out under the  /Users  folder? Only files under the  /Users  folder are shared into the \nDocker Host (and thus containers) by default.  Does the  docker-compose.yml  file have a volume mount set up that contains the missing files?  Get shell in the Docker container via  docker exec -it  container name  /bin/bash  and check if the files are \nshared in the wrong place.  Get shell in the Docker Machine with  docker-machine ssh dev  and check if you find the files under /Users.",
            "title": "Files Not Found"
        },
        {
            "location": "/faq/troubleshooting/#image-not-found",
            "text": "If you encounter the following error about the Docker image not being found when starting a project, it may indicate \nthat the image is private and your Docker client is not logged into a required private Docker Hub repository:  Pulling repository phase2/privateimage\n\nError: image phase2/privateimage:latest not found  To solve this, run  docker login  and provide the relevant credentials.",
            "title": "Image not found"
        },
        {
            "location": "/faq/troubleshooting/#docker-client-and-server-version-incompatibilities",
            "text": "If you see an error similar to this:  Error response from daemon: client is newer than server (client API version: 1.20, server API version: 1.19)  You likely need to upgrade your Docker Host to a get Docker client API compatibility. Do that with:  `devtools upgrade`",
            "title": "Docker client and server version incompatibilities"
        },
        {
            "location": "/faq/troubleshooting/#network-timed-out-and-cant-pull-container-image",
            "text": "Example:  Pulling cache (phase2/memcache:latest)...\nPulling repository docker.io/phase2/memcache\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/phase2/memcache/images. You may want to check your internet connection or if you are behind a proxy.  Try restarting docker-machine:  devtools restart",
            "title": "Network timed out and can't pull container image"
        },
        {
            "location": "/faq/troubleshooting/#started-machines-may-have-a-new-ip-address",
            "text": "Example:  Started machines may have new IP addresses. You may need to re-run the `docker-machine env` command.\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 1 of 10.\n...\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 10 of 10.\n[ERROR] Docker daemon failed to start!  The Docker Host (probably called dev) has it's IP changed. The generated TLS Certs are no longer valid and must be regenerated.  Possible causes or relations/patterns:   Another VM was started in VirtualBox.  Machine went to sleep and somehow caused issues with the running VM.   Fix:  Try running:  docker-machine env  If that does not work, you should be able to start the VM directly through docker-machine:  docker-machine start dev  Next, check the IP / TLS status by running:  docker-machine ls  The output will likely report something akin to:  dev       -        virtualbox   Running   tcp://192.168.99.100:2376 Unknown\nUnable to query docker version: Get https://192.168.99.100:2376/v1.15/version: x509: certificate is valid for 192.168.99.101, not 192.168.99.100  Now, regenerate the TLS Certs:  docker-machine regenerate-certs dev -f \nDevtools should now be able to start. Don't forget to run `eval \"$(devtools config)\" after.",
            "title": "Started machines may have a new IP address"
        },
        {
            "location": "/faq/troubleshooting/#containers-started-but-service-not-available",
            "text": "Your Docker Host is running, the project's containers are up, and command-line operations work fine. Why can't you view \nthe site in your web browser?",
            "title": "Containers Started but Service Not Available"
        },
        {
            "location": "/faq/troubleshooting/#dns-services",
            "text": "The DNS services that DevTools spins up may not be working. Run  docker ps  and see that you have a dnsdock and dnsmasq container.  If those services are not running, try  devtools dns  to bring them up, or a full  devtools restart  if that does not work.  devtools dns-records  is also useful to see what containers have registered names.",
            "title": "DNS Services"
        },
        {
            "location": "/faq/troubleshooting/#dns-configuration",
            "text": "It is also possible that the DNS services are running for your environment, but somehow the configuration is wrong. Run  devtools dns-records  and make sure your project has an entry. If not, you may need another restart, or perhaps you are \nmissing  DNSDOCK_NAME  and  DNSDOCK_IMAGE  environment variable entries in your docker-compose.yml manifest.",
            "title": "DNS Configuration"
        },
        {
            "location": "/faq/troubleshooting/#slow-starting-services",
            "text": "Some services, such as Apache Solr or Varnish, can take longer to start up than Apache and PHP-FPM. As a result you might \nload the browser so fast that not all services are available, which in the case of a proxy may prevent the page from \nloading at all. Wait a short time and try reloading the page.",
            "title": "Slow-starting Services"
        },
        {
            "location": "/faq/troubleshooting/#failed-health-checks",
            "text": "Some services such as Varnish depend on others to operate, and have built-in health checks to verify the other service is operating.  If such a health check fails, there could be two problems:   The internal DNS routing between Docker containers is broken. Make sure the\nconfiguration of your services is correct.  The dependency (e.g., Apache behing Varnish) is not yet up and running when Varnish performs its checks.   In either case, you can often repair the problem by performing a clean restart of the broken service.  docker-compose stop proxy\ndocker-compose rm -f proxy\ndocker-compose up -d proxy  Your other services should already be up and functional when this is done, so the health check will not fail on account of (2).   Checking on Varnish Health  If you suspect Varnish may be failing, run  docker exec -it [VARNISH_CONTAINER] varnishlog  and scan for VCL compilation errors.",
            "title": "Failed Health Checks"
        },
        {
            "location": "/faq/troubleshooting/#service-became-non-responsive",
            "text": "Sometimes a service locks up. Apache stops serving results, Solr stops indexing or responding to search queries. These \nthings happen on servers all the time. It may even happen more often on Docker, especially since we are now using more \n\"infrastructure\" in our local environments.  Docker is meant to easily sandbox these problems from the rest of your machine, and to easily resolve these problems by \nallowing you to dump the problem and start over fresh very easily.  Hard reset on a service (as describe above), is very much like a power cycle:  docker-compose stop [BROKEN_SERVICE]\ndocker-compose rm -f [BROKEN_SERVICE]\ndocker-compose up -d [BROKEN_SERVICE]  Sometimes data for a service is volume mounted from outside the container. This persistence is good when the data is \nhealthy, but can be really bad if the data is part of the problem (e.g., broken lockfiles).  docker-machine ssh [MACHINE_NAME]\nrm -Rf /data/[PROJECT]/[DIRECTORY_FOR_SERVICE]  Remember that your service may have configuration or data in another service, you may need to perform this operation against multilpe containers (e.g., Solr)",
            "title": "Service Became Non-Responsive"
        },
        {
            "location": "/faq/troubleshooting/#nfs-conflicts-with-other-environments",
            "text": "Running the Devtools VM in conjunction with other development environments (such as Vagrant) can sometimes cause conflicts \nwith volume mounts. This is due to the fact that the Devtools VM mounts the entirety of  /Users  into the VM on OS X. \nAdditional NFS mounts from other environments that target subdirectories of  /Users  will fail.  The easiest workaround is to keep projects that use non-Devtools environments like Vagrant in a directory  outside  of  /Users , such as  /opt . Alternatively, you can run a single VM at a time and manually clear out  /etc/exports  prior \nto switching environments/projects.",
            "title": "NFS Conflicts with other Environments"
        },
        {
            "location": "/faq/troubleshooting/#migrating-vagrant-boxes-outside-of-users",
            "text": "If you'd like to move your vagrant boxes outside of your home directory, perform the following steps:   Choose a destination folder.  We'll be using /opt/vms for this example. Insure the destination has enough free space. \nTypically this is not a problem because our Macs are one single partition.  Make the new directory, and ensure your userid owns it:   sudo mkdir /opt/vms; sudo chown -R userid:userid /opt/vms  Add  export VAGRANT_HOME=/opt/vms  to ~/.bash_profile  Move your vagrant folders over to /opt/vms.  edit /etc/exports, updating any vagrant mount point to use the new location.  (example: /Users/userid/vagrant/projectx/cms)  While a reboot isn't neccesary, it'll help to make sure nothing is running and using the old mount points.  cd into your new vagrant directory, and do a vagrant up.",
            "title": "Migrating Vagrant boxes outside of /Users:"
        },
        {
            "location": "/faq/docker-for-mac/",
            "text": "Docker for Mac Support\n\n\nDocker for Mac is a native hypervisor implementation of Docker that does not rely on a virtual machine provided by Docker \nMachine.  It is new with some limitations and potential conflicts with DevTools. We will highlight the path to a peaceful \ncoexistence. \n\n\nUsing only the Docker for Mac Binaries\n\n\nDocker for Mac provides \ndocker\n and \ndocker-compose\n binaries in \n/usr/local/bin\n.  This install location conflicts with\nthe binaries provided by Homebrew, but DevTools can use these binaries too.  If you have installed Docker for Mac first, you \nwill get errors when trying to install the \ndocker\n and \ndocker-compose\n binaries via Homebrew. Those errors are fine, as long\nas when all is said and done \ndocker\n, \ndocker-compose\n, and \ndocker-machine\n are all available on your \n$PATH\n.\n\n\nTo use the binaries with your DevTools VM you simply need to run the \neval \"$(devtools config)\"\n command to setup your\nDocker environment.  This will point the \ndocker\n to your VM.  You will need to do this in every shell that you want to \nuse the DevTools VM.  If you then need to transition back to using the Docker for Mac hypervisor, you will need to unset \nthe DevTools \ndocker\n configuration. Use \neval \"$(docker-machine env -u)\"\n to unset all \nDOCKER_*\n environment variables. \n\n\nIf you need to do this often, we recommend setting up aliases to set/unset the env vars.\n\n\nalias dte='eval \n$(devtools config)\n'\nalias dtu='eval \n$(dcoker-machine env -u)\n'\n\n\n\n\nUsing the Docker for Mac Binaries and Hypervisor\n\n\nTo use the Docker for Mac Hypervisor follow the basic instructions below.\n\n\n\n\nDocker for Mac is less performant (early 2017)\n\n\nThe FUSE driver they use to share your host filesystem into the hypervisor/contaienrs is not nearly as performant as\nthe NFS mount we use with the DevTools VM.  Therefore, operations that do either a lot of filesystem reading (like \ndirectory scan) or writing (like restoring DB dumps) will take much longer to perform.  It is advisable to use the\nDevTools VM / Virtualbox for the time being simply for performance reasons.\n\n\n\n\n\n\nNetworking limitation when using the Docker for Mac Hypervisor\n\n\nThere are some \nknown limitations\n\nwith the way networking is implemented with Docker for Mac.  Most notable we can not directly access containers on \ntheir native IP address due to the lack of the docker0 bridge network that exists in the Docker Machine VM implementation.\nThese limitations inhibit the fluid environment that DevTools enables and as such is not natively supported (yet). We\nhave done our best to highlight the issues and some of our ideas for workarounds below. Let us know how it goes if you\nventure down this path.\n\n\n\n\nSetup /data\n\n\nDevTools makes a convention out of a \n/data\n directory within the VM.  To provide the same directory to Docker for Mac, \ncreate a \n/data\n directory in the root of your Mac filesystem.  You may need to open up the permissions so the container(s)\ncan write to it.\n\n\nsudo mkdir /data \n sudo chmod 777 /data\n\n\n\n\nOnce you have created that directory, go into Docker for Mac \n Preferences \n File Sharing and add \n/data\n to the list of \nshares and \nApply \n Restart\n Docker for Mac.  With this \n/data\n directoy setup your Compose files should work on either \nthe Docker for Mac Hypervisor or the DevTools VM.\n\n\nAccessing your Container Services\n\n\nDocker for Mac does not provide a mechanism to route network traffic directly to your containers, they only support \npublishing (binding) ports from your running containers to your host.  This means that all services are accessed on \nlocalhost (127.0.0.1) and share the same port space. (Two web server can't both publish to port 80). The approach we think \nmakes sense (but don't actively support) is:\n\n\n\n\nRun \njwilder/nginx-proxy\n as your only service that binds to port 80\n\n\nStart all of your web containers with the \nVIRTUAL_HOST\n environment variable used by nginx-proxy to specify it's domain name\n\n\nResolve the domain name from the above \nVIRTUAL_HOST\n variable in one of two ways\n\n\nEdit your \n/etc/hosts\n file and point the domain name at \n127.0.0.1\n\n\nUse dnsmasq\n\n\nMake sure dnsdock is not running\n\n\nIn \n/etc/resolver/vm\n have \nnameserver 127.0.0.1\n\n\nRun a dnsmasq container, bind it to port 53, configured to resolve all \n.vm\n addresses to \n127.0.0.1\n\n\n\n\n\n\n\n\nUninstalling Docker for Mac\n\n\nSince Docker for Mac and Homebrew both install the Docker binaries in to \n/usr/local/bin\n after you uninstall Docker for Mac \nyour DevTools environment wont work.  You may see an error like \ncommand not found: docker\n. The Docker for Mac installation \noverwrote the Homebrew based Docker installation, but brew still believes they are installed, so you'll need to unlink and re-link.\n\n\nbrew unlink docker \n brew link docker\nbrew unlink docker-compose \n brew link docker-compose\nbrew unlink docker-machine \n brew link docker-machine",
            "title": "Docker for Mac"
        },
        {
            "location": "/faq/docker-for-mac/#docker-for-mac-support",
            "text": "Docker for Mac is a native hypervisor implementation of Docker that does not rely on a virtual machine provided by Docker \nMachine.  It is new with some limitations and potential conflicts with DevTools. We will highlight the path to a peaceful \ncoexistence.",
            "title": "Docker for Mac Support"
        },
        {
            "location": "/faq/docker-for-mac/#using-only-the-docker-for-mac-binaries",
            "text": "Docker for Mac provides  docker  and  docker-compose  binaries in  /usr/local/bin .  This install location conflicts with\nthe binaries provided by Homebrew, but DevTools can use these binaries too.  If you have installed Docker for Mac first, you \nwill get errors when trying to install the  docker  and  docker-compose  binaries via Homebrew. Those errors are fine, as long\nas when all is said and done  docker ,  docker-compose , and  docker-machine  are all available on your  $PATH .  To use the binaries with your DevTools VM you simply need to run the  eval \"$(devtools config)\"  command to setup your\nDocker environment.  This will point the  docker  to your VM.  You will need to do this in every shell that you want to \nuse the DevTools VM.  If you then need to transition back to using the Docker for Mac hypervisor, you will need to unset \nthe DevTools  docker  configuration. Use  eval \"$(docker-machine env -u)\"  to unset all  DOCKER_*  environment variables.   If you need to do this often, we recommend setting up aliases to set/unset the env vars.  alias dte='eval  $(devtools config) '\nalias dtu='eval  $(dcoker-machine env -u) '",
            "title": "Using only the Docker for Mac Binaries"
        },
        {
            "location": "/faq/docker-for-mac/#using-the-docker-for-mac-binaries-and-hypervisor",
            "text": "To use the Docker for Mac Hypervisor follow the basic instructions below.   Docker for Mac is less performant (early 2017)  The FUSE driver they use to share your host filesystem into the hypervisor/contaienrs is not nearly as performant as\nthe NFS mount we use with the DevTools VM.  Therefore, operations that do either a lot of filesystem reading (like \ndirectory scan) or writing (like restoring DB dumps) will take much longer to perform.  It is advisable to use the\nDevTools VM / Virtualbox for the time being simply for performance reasons.    Networking limitation when using the Docker for Mac Hypervisor  There are some  known limitations \nwith the way networking is implemented with Docker for Mac.  Most notable we can not directly access containers on \ntheir native IP address due to the lack of the docker0 bridge network that exists in the Docker Machine VM implementation.\nThese limitations inhibit the fluid environment that DevTools enables and as such is not natively supported (yet). We\nhave done our best to highlight the issues and some of our ideas for workarounds below. Let us know how it goes if you\nventure down this path.",
            "title": "Using the Docker for Mac Binaries and Hypervisor"
        },
        {
            "location": "/faq/docker-for-mac/#setup-data",
            "text": "DevTools makes a convention out of a  /data  directory within the VM.  To provide the same directory to Docker for Mac, \ncreate a  /data  directory in the root of your Mac filesystem.  You may need to open up the permissions so the container(s)\ncan write to it.  sudo mkdir /data   sudo chmod 777 /data  Once you have created that directory, go into Docker for Mac   Preferences   File Sharing and add  /data  to the list of \nshares and  Apply   Restart  Docker for Mac.  With this  /data  directoy setup your Compose files should work on either \nthe Docker for Mac Hypervisor or the DevTools VM.",
            "title": "Setup /data"
        },
        {
            "location": "/faq/docker-for-mac/#accessing-your-container-services",
            "text": "Docker for Mac does not provide a mechanism to route network traffic directly to your containers, they only support \npublishing (binding) ports from your running containers to your host.  This means that all services are accessed on \nlocalhost (127.0.0.1) and share the same port space. (Two web server can't both publish to port 80). The approach we think \nmakes sense (but don't actively support) is:   Run  jwilder/nginx-proxy  as your only service that binds to port 80  Start all of your web containers with the  VIRTUAL_HOST  environment variable used by nginx-proxy to specify it's domain name  Resolve the domain name from the above  VIRTUAL_HOST  variable in one of two ways  Edit your  /etc/hosts  file and point the domain name at  127.0.0.1  Use dnsmasq  Make sure dnsdock is not running  In  /etc/resolver/vm  have  nameserver 127.0.0.1  Run a dnsmasq container, bind it to port 53, configured to resolve all  .vm  addresses to  127.0.0.1",
            "title": "Accessing your Container Services"
        },
        {
            "location": "/faq/docker-for-mac/#uninstalling-docker-for-mac",
            "text": "Since Docker for Mac and Homebrew both install the Docker binaries in to  /usr/local/bin  after you uninstall Docker for Mac \nyour DevTools environment wont work.  You may see an error like  command not found: docker . The Docker for Mac installation \noverwrote the Homebrew based Docker installation, but brew still believes they are installed, so you'll need to unlink and re-link.  brew unlink docker   brew link docker\nbrew unlink docker-compose   brew link docker-compose\nbrew unlink docker-machine   brew link docker-machine",
            "title": "Uninstalling Docker for Mac"
        },
        {
            "location": "/appendix/glossary/",
            "text": "Glossary\n\n\nHost Machine\n\n\nYour laptop for the purposes of DevTools. This is where your project's source code, your IDE, browsers, etc run as well \nas where the virtual machine acting as the Docker Host runs.\n\n\nDocker Host\n\n\nThis is a Linux-based virtual machine capable of running Docker. One Docker host VM can run multiple containers for \nmultiple projects.\n\n\nDocker Image\n\n\nA read only template that can be instantiated as a running container. An image might supply a service as small as a build \ntool or as large as a database and/or web server. Images are generally single purpose in nature and are then linked together \nto build more complex capabilities.\n\n\nContainer\n\n\nA runtime instance of a Docker Image. This is what contains a service like Apache or MySQL. Several containers can run on \na single Docker Host and they can be linked so that they they know how to communicate with each other.\n\n\nDocker Machine\n\n\nDocker Machine creates the Docker Host virtual machine in which containers run.  This provides the functionality that we \npreviously used Vagrant to accomplish. Under the covers docker-machine starts up a virtual machine running a tiny version \nof Linux.  On Macs this tiny version of Linux is called boot2docker.  All of the Docker commands to build and run containers \nwill actually be executed on the boot2docker virtual machine. On your laptop you will have a single boot2docker virtual \nmachine (running in VirtualBox or VMWare Fusion) and it will host one or more Docker containers. Each project will likely \nhave multiple Docker containers running (web server, database, memcache, search, etc.).\n\n\nDocker Compose\n\n\nDocker Compose is used to manage and coordinate the containers that need to run for a project in an easy to use YAML \nfile. Each project will have a docker-compose file for each Docker environment that the project supports.  For example, \nthe default docker-compose.yml would be used to start containers for local development, and alternate Docker compose \nfiles could be included for starting containers for the integration/stage and other environments.",
            "title": "Glossary"
        },
        {
            "location": "/appendix/glossary/#glossary",
            "text": "",
            "title": "Glossary"
        },
        {
            "location": "/appendix/glossary/#host-machine",
            "text": "Your laptop for the purposes of DevTools. This is where your project's source code, your IDE, browsers, etc run as well \nas where the virtual machine acting as the Docker Host runs.",
            "title": "Host Machine"
        },
        {
            "location": "/appendix/glossary/#docker-host",
            "text": "This is a Linux-based virtual machine capable of running Docker. One Docker host VM can run multiple containers for \nmultiple projects.",
            "title": "Docker Host"
        },
        {
            "location": "/appendix/glossary/#docker-image",
            "text": "A read only template that can be instantiated as a running container. An image might supply a service as small as a build \ntool or as large as a database and/or web server. Images are generally single purpose in nature and are then linked together \nto build more complex capabilities.",
            "title": "Docker Image"
        },
        {
            "location": "/appendix/glossary/#container",
            "text": "A runtime instance of a Docker Image. This is what contains a service like Apache or MySQL. Several containers can run on \na single Docker Host and they can be linked so that they they know how to communicate with each other.",
            "title": "Container"
        },
        {
            "location": "/appendix/glossary/#docker-machine",
            "text": "Docker Machine creates the Docker Host virtual machine in which containers run.  This provides the functionality that we \npreviously used Vagrant to accomplish. Under the covers docker-machine starts up a virtual machine running a tiny version \nof Linux.  On Macs this tiny version of Linux is called boot2docker.  All of the Docker commands to build and run containers \nwill actually be executed on the boot2docker virtual machine. On your laptop you will have a single boot2docker virtual \nmachine (running in VirtualBox or VMWare Fusion) and it will host one or more Docker containers. Each project will likely \nhave multiple Docker containers running (web server, database, memcache, search, etc.).",
            "title": "Docker Machine"
        },
        {
            "location": "/appendix/glossary/#docker-compose",
            "text": "Docker Compose is used to manage and coordinate the containers that need to run for a project in an easy to use YAML \nfile. Each project will have a docker-compose file for each Docker environment that the project supports.  For example, \nthe default docker-compose.yml would be used to start containers for local development, and alternate Docker compose \nfiles could be included for starting containers for the integration/stage and other environments.",
            "title": "Docker Compose"
        },
        {
            "location": "/appendix/architecture/",
            "text": "Architecture\n\n\nDevTools uses a containerization based approach to providing a project environment. Project services running as containers\nare combined with configuration for persistent data storage, DNS services and network manipulation which allows for easy\naccess via names like service.project.vm rather than IP addresses.\n\n\nThe DevTools CLI facilitates setting up a VM to act as a container host on systems which can not host containers natively.\nIt also configures the VM with the following:\n\n\n\n\nFilesystem sharing for high performance file access of the host machine\n\n\nContainer initiation for DNS services\n\n\nNetwork and name resolution configuration\n\n\n\n\nLayered with this core are a set of docker images which provide common project services such as a web server along with\nthe ability to configure these services with commonly desired development options. Any docker image can be used if desired.\n\n\nDocker Compose is used to control containers to provide a complete environment and a set of Yeoman based generators are\nused to help initial project setup to ensure all pieces fit together using the current best known options..\n\n\nContainerization\n\n\nIn order to provide lightweight environments and tooling we use a technical approach called containers.\nContainers attempt to move the unit of environment from server to application. This allows separation of concerns between\nhow an application is configured, how the containers communicate with each other, and where the containers are deployed.\nTake an advanced Drupal stack that includes Apache/PHP, MySQL, Memcache, and SOLR. With each component configured to run\nin its own container, the containers can all run on a single VM for local development and be spread across multiple\nservers for an optimized production deployment. Let us briefly touch on the technology we will be using and how it\nconceptually fits together.\n\n\nDocker\n\n\nThe container implementation we use is called Docker which is explained in the intro: \nWhat is Docker\n?\nThis is the way we capture environment units for our application/services and share them with everyone on the team.\nEnvironments are captured as images, similar to a VM, so when anyone runs that image they all start with the exact same\nset of files. For example, nearly every project needs a web server so we have a container image that can be run\nto provide that service. Our Docker images are also set up to allow for configuration adjustment to enable common\ndevelopment options.\n\n\ndevtools-cli\n\n\nThis is a project that glues all of the hosting aspects of these tools together into an easy to use unit. You can find\ndevtools-cli in our BitBucket repository \nhere\n. There are 2\nbasic services that devtools-cli provides:\n\n\nManage virtual machines for running containers\n\n\nThe devtools binary will manage the creation/configuration/upgrade/start/stop of boot2docker virtual machines (a.k.a\nDocker Hosts) via docker-machine. It ensures that the docker-machine virtual machine is the right version, is named\ncorrectly and configured to run efficiently within Virtualbox, VMWare Fusion or xhyve.\n\n\nNice DNS names and routing for running containers\n\n\nOnce there is a safe environment to run our containers we need a way to route traffic to them and provide easy to\nuse/remember domain names to make accessing these services simple. Domain names for containers are set in the\ndocker-compose yaml files using configuration that the \ndnsdock\n container reads to create a mapping between domain\nname and container.\n\n\nWe use \ndnsdock\n running as a container within the Docker Host. The \ndnsdock\n service, which listens on\n172.17.0.1:53535. The \ndnsdock\n container resolves the *.vm domain names to the IP addresses of the containers.\n\n\nInternal container names will look like \nweb.openatrium.vm\n. All DevTools containers will carry the \n.vm\n extension\nfor name resolution. There is additional information in \nDNS Resolution\n.\n\n\nDocker Hub\n\n\nDocker Hub is where container images are stored and retrieved when your local machine does not already have a copy of\nthe requested container image. Docker Hub can be thought of like GitHub or BitBucket and Docker Hub images can be thought\nof as git repositories. We can make new versions of the images and they can be pushed and pulled to the Docker Hub service.\n\n\nContainer Configuration\n\n\nIf a container wants to offer configurable options it will document how to control it within the README or via Environment\nvariables in the Dockerfile itself. See our Apache / PHP \nDockerfile\n\nfor an example. In this Docker Image, passing environment variables can override the PHP memory limit. Those variables\ncan either be passed on the command line when executing a \ndocker run\n command directly, or in the \nenvironment\n section\nof a docker-compose file. Documentation entries within the \nCommon Tasks\n section provide additional approaches to\ncontainer configuration.",
            "title": "Architecture"
        },
        {
            "location": "/appendix/architecture/#architecture",
            "text": "DevTools uses a containerization based approach to providing a project environment. Project services running as containers\nare combined with configuration for persistent data storage, DNS services and network manipulation which allows for easy\naccess via names like service.project.vm rather than IP addresses.  The DevTools CLI facilitates setting up a VM to act as a container host on systems which can not host containers natively.\nIt also configures the VM with the following:   Filesystem sharing for high performance file access of the host machine  Container initiation for DNS services  Network and name resolution configuration   Layered with this core are a set of docker images which provide common project services such as a web server along with\nthe ability to configure these services with commonly desired development options. Any docker image can be used if desired.  Docker Compose is used to control containers to provide a complete environment and a set of Yeoman based generators are\nused to help initial project setup to ensure all pieces fit together using the current best known options..",
            "title": "Architecture"
        },
        {
            "location": "/appendix/architecture/#containerization",
            "text": "In order to provide lightweight environments and tooling we use a technical approach called containers.\nContainers attempt to move the unit of environment from server to application. This allows separation of concerns between\nhow an application is configured, how the containers communicate with each other, and where the containers are deployed.\nTake an advanced Drupal stack that includes Apache/PHP, MySQL, Memcache, and SOLR. With each component configured to run\nin its own container, the containers can all run on a single VM for local development and be spread across multiple\nservers for an optimized production deployment. Let us briefly touch on the technology we will be using and how it\nconceptually fits together.",
            "title": "Containerization"
        },
        {
            "location": "/appendix/architecture/#docker",
            "text": "The container implementation we use is called Docker which is explained in the intro:  What is Docker ?\nThis is the way we capture environment units for our application/services and share them with everyone on the team.\nEnvironments are captured as images, similar to a VM, so when anyone runs that image they all start with the exact same\nset of files. For example, nearly every project needs a web server so we have a container image that can be run\nto provide that service. Our Docker images are also set up to allow for configuration adjustment to enable common\ndevelopment options.",
            "title": "Docker"
        },
        {
            "location": "/appendix/architecture/#devtools-cli",
            "text": "This is a project that glues all of the hosting aspects of these tools together into an easy to use unit. You can find\ndevtools-cli in our BitBucket repository  here . There are 2\nbasic services that devtools-cli provides:",
            "title": "devtools-cli"
        },
        {
            "location": "/appendix/architecture/#manage-virtual-machines-for-running-containers",
            "text": "The devtools binary will manage the creation/configuration/upgrade/start/stop of boot2docker virtual machines (a.k.a\nDocker Hosts) via docker-machine. It ensures that the docker-machine virtual machine is the right version, is named\ncorrectly and configured to run efficiently within Virtualbox, VMWare Fusion or xhyve.",
            "title": "Manage virtual machines for running containers"
        },
        {
            "location": "/appendix/architecture/#nice-dns-names-and-routing-for-running-containers",
            "text": "Once there is a safe environment to run our containers we need a way to route traffic to them and provide easy to\nuse/remember domain names to make accessing these services simple. Domain names for containers are set in the\ndocker-compose yaml files using configuration that the  dnsdock  container reads to create a mapping between domain\nname and container.  We use  dnsdock  running as a container within the Docker Host. The  dnsdock  service, which listens on\n172.17.0.1:53535. The  dnsdock  container resolves the *.vm domain names to the IP addresses of the containers.  Internal container names will look like  web.openatrium.vm . All DevTools containers will carry the  .vm  extension\nfor name resolution. There is additional information in  DNS Resolution .",
            "title": "Nice DNS names and routing for running containers"
        },
        {
            "location": "/appendix/architecture/#docker-hub",
            "text": "Docker Hub is where container images are stored and retrieved when your local machine does not already have a copy of\nthe requested container image. Docker Hub can be thought of like GitHub or BitBucket and Docker Hub images can be thought\nof as git repositories. We can make new versions of the images and they can be pushed and pulled to the Docker Hub service.",
            "title": "Docker Hub"
        },
        {
            "location": "/appendix/architecture/#container-configuration",
            "text": "If a container wants to offer configurable options it will document how to control it within the README or via Environment\nvariables in the Dockerfile itself. See our Apache / PHP  Dockerfile \nfor an example. In this Docker Image, passing environment variables can override the PHP memory limit. Those variables\ncan either be passed on the command line when executing a  docker run  command directly, or in the  environment  section\nof a docker-compose file. Documentation entries within the  Common Tasks  section provide additional approaches to\ncontainer configuration.",
            "title": "Container Configuration"
        },
        {
            "location": "/appendix/background/",
            "text": "Background\n\n\nThis document covers some of the history of development tooling and explains some of the how and why of the DevTools approach.\n\n\nWhy DevTools\n\n\nDevTools covers an entire toolbox of solutions to accelerate development and smoothly implement best practices. We\nintend to use the DevTools umbrella to help us roll these tools and approaches out to the whole company in a more\nconsistent fashion.\n\n\nAcross a wide variety of projects and clients, keeping a development, integration, staging, production and other\nenvironments synchronized in terms of server configuration and supporting software versions and tooling has always been\na challenge. The multitude of platforms and versions of operating systems and software is only growing. In the past we\nhave used Vagrant in conjunction with a virtual machine (VM) for local development environments, project-based VMs on\nDev Cloud for integration environments and tools like Puppet to try and ensure all of those match each other and the\ndeployment environments.\n\n\nIt\u2019s been better than doing it all by hand but it has required building additional expertise above typical system\nmanagement tools and it\u2019s relatively inefficient to have many project-specific VMs locally. On top of that are the\nvarious, sometimes conflicting, versions of development toolchains which the VMs don\u2019t always address.\n\n\nDevTools is going to address this problem by providing an efficient way to have project/app-specific environments as well\nas development tooling by using a concept called containerization. This lets us focus on items at a service-and-tools\nlevel rather than at a server level and make the details of our hosting implementation more transparent to all technical\nteam members.\n\n\nMapping Concepts From Previous Approaches\n\n\nThere are some important pieces to remember about how containerization is similar and different to concepts you may be\nfamiliar with.\n\n\nVagrant\n\n\nVagrant is being replaced by the combination of Docker Compose and Docker Machine.\n\n\nVirtual Machines\n\n\nFor local development, you should no longer worry about Virtual Machines at a project level as they are replaced by a\nsingle Docker Machine instance. In environments where containers are meant to run on a cluster of hosts, orchestration\ntools like \nKubernetes\n or \nSwarm\n may be used\nto distribute and coordinate containers across multiple Docker Hosts.\n\n\nPuppet / Ansible / configuration management\n\n\nGoodbye, for local environments at least. Docker uses a conceptually different approach to configuration management than\nPuppet. It\u2019s perfectly possible to use tools like Puppet and Ansible from within a Dockerfile to get a container image\nprepared though typically simple shell commands are preferred. The idea is that systems like Puppet are no longer needed\nto manage upgrades across working servers/containers. When there are updates needed you will update the image, pull down\nthe new version of the image to your server and then stop the containers running the old version of the image and start\ncontainers based on the new version of the image.",
            "title": "Background"
        },
        {
            "location": "/appendix/background/#background",
            "text": "This document covers some of the history of development tooling and explains some of the how and why of the DevTools approach.",
            "title": "Background"
        },
        {
            "location": "/appendix/background/#why-devtools",
            "text": "DevTools covers an entire toolbox of solutions to accelerate development and smoothly implement best practices. We\nintend to use the DevTools umbrella to help us roll these tools and approaches out to the whole company in a more\nconsistent fashion.  Across a wide variety of projects and clients, keeping a development, integration, staging, production and other\nenvironments synchronized in terms of server configuration and supporting software versions and tooling has always been\na challenge. The multitude of platforms and versions of operating systems and software is only growing. In the past we\nhave used Vagrant in conjunction with a virtual machine (VM) for local development environments, project-based VMs on\nDev Cloud for integration environments and tools like Puppet to try and ensure all of those match each other and the\ndeployment environments.  It\u2019s been better than doing it all by hand but it has required building additional expertise above typical system\nmanagement tools and it\u2019s relatively inefficient to have many project-specific VMs locally. On top of that are the\nvarious, sometimes conflicting, versions of development toolchains which the VMs don\u2019t always address.  DevTools is going to address this problem by providing an efficient way to have project/app-specific environments as well\nas development tooling by using a concept called containerization. This lets us focus on items at a service-and-tools\nlevel rather than at a server level and make the details of our hosting implementation more transparent to all technical\nteam members.",
            "title": "Why DevTools"
        },
        {
            "location": "/appendix/background/#mapping-concepts-from-previous-approaches",
            "text": "There are some important pieces to remember about how containerization is similar and different to concepts you may be\nfamiliar with.",
            "title": "Mapping Concepts From Previous Approaches"
        },
        {
            "location": "/appendix/background/#vagrant",
            "text": "Vagrant is being replaced by the combination of Docker Compose and Docker Machine.",
            "title": "Vagrant"
        },
        {
            "location": "/appendix/background/#virtual-machines",
            "text": "For local development, you should no longer worry about Virtual Machines at a project level as they are replaced by a\nsingle Docker Machine instance. In environments where containers are meant to run on a cluster of hosts, orchestration\ntools like  Kubernetes  or  Swarm  may be used\nto distribute and coordinate containers across multiple Docker Hosts.",
            "title": "Virtual Machines"
        },
        {
            "location": "/appendix/background/#puppet-ansible-configuration-management",
            "text": "Goodbye, for local environments at least. Docker uses a conceptually different approach to configuration management than\nPuppet. It\u2019s perfectly possible to use tools like Puppet and Ansible from within a Dockerfile to get a container image\nprepared though typically simple shell commands are preferred. The idea is that systems like Puppet are no longer needed\nto manage upgrades across working servers/containers. When there are updates needed you will update the image, pull down\nthe new version of the image to your server and then stop the containers running the old version of the image and start\ncontainers based on the new version of the image.",
            "title": "Puppet / Ansible / configuration management"
        },
        {
            "location": "/appendix/library/",
            "text": "Library\n\n\nTo Be Done",
            "title": "Library"
        },
        {
            "location": "/appendix/library/#library",
            "text": "To Be Done",
            "title": "Library"
        }
    ]
}