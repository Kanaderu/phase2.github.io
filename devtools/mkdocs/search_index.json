{
    "docs": [
        {
            "location": "/",
            "text": "DevTools\n\n\nThis project is designed to creates a Docker Machine based VM, sets up network routes, \na persistent /data store, and runs a DNS service for Docker containers.\n\n\nIf you are brand new to using the DevTools VM it's \nhighly recommended\n\nto read the \nIntro\n document (see the docs directory) for a conceptual overview.\nThere is additional documentation in the docs directory that guides you through \na variety of topics, including project and integration environment setup.  \n\n\nInstallation\n\n\nAs first time setup, install the following:\n\n\n1. Install VirtualBox \n= 5.0 if you aren't on Linux\n\n\nVirtualBox website\n\n\n2. Install DevTools on Mac using Homebrew\n\n\n2.1 Install the DevTools Tap\n\n\nbrew tap phase2/devtools\n\n\n2.2 Install the devtools binary and dependencies\n\n\nbrew install devtools\n\n\n2.3 Startup the container host\n\n\nOnce everything checks out. run the following command to create \n start the new container \nhost (the docker machine). (You will be prompted for your admin password)\n\n\ndevtools start\n\n\n2.4 Configure your shell to use DevTools environment\n\n\nTo configure the shell with the proper DevTools environment, run the following command\nafter the container host has started from the previous step.\n\n\neval \"$(devtools config)\"\n\n\nFor convenience, you may want to make this automatic on every terminal you launch,\nadd the following to your \n.bash_profile\n, \n.zshrc\n or equivalent:\n\n\n# Support for DevTools\neval \n$(devtools config)\n\n\n\n\n\nNote that even with automatic execution, this command must be run in any existing\nterminal windows after any \ndevtools start\n or \ndevtools restart\n commands.",
            "title": "Home"
        },
        {
            "location": "/#devtools",
            "text": "This project is designed to creates a Docker Machine based VM, sets up network routes, \na persistent /data store, and runs a DNS service for Docker containers.  If you are brand new to using the DevTools VM it's  highly recommended \nto read the  Intro  document (see the docs directory) for a conceptual overview.\nThere is additional documentation in the docs directory that guides you through \na variety of topics, including project and integration environment setup.",
            "title": "DevTools"
        },
        {
            "location": "/#installation",
            "text": "As first time setup, install the following:",
            "title": "Installation"
        },
        {
            "location": "/#1-install-virtualbox-50-if-you-arent-on-linux",
            "text": "VirtualBox website",
            "title": "1. Install VirtualBox &gt;= 5.0 if you aren't on Linux"
        },
        {
            "location": "/#2-install-devtools-on-mac-using-homebrew",
            "text": "",
            "title": "2. Install DevTools on Mac using Homebrew"
        },
        {
            "location": "/#21-install-the-devtools-tap",
            "text": "brew tap phase2/devtools",
            "title": "2.1 Install the DevTools Tap"
        },
        {
            "location": "/#22-install-the-devtools-binary-and-dependencies",
            "text": "brew install devtools",
            "title": "2.2 Install the devtools binary and dependencies"
        },
        {
            "location": "/#23-startup-the-container-host",
            "text": "Once everything checks out. run the following command to create   start the new container \nhost (the docker machine). (You will be prompted for your admin password)  devtools start",
            "title": "2.3 Startup the container host"
        },
        {
            "location": "/#24-configure-your-shell-to-use-devtools-environment",
            "text": "To configure the shell with the proper DevTools environment, run the following command\nafter the container host has started from the previous step.  eval \"$(devtools config)\"  For convenience, you may want to make this automatic on every terminal you launch,\nadd the following to your  .bash_profile ,  .zshrc  or equivalent:  # Support for DevTools\neval  $(devtools config)   Note that even with automatic execution, this command must be run in any existing\nterminal windows after any  devtools start  or  devtools restart  commands.",
            "title": "2.4 Configure your shell to use DevTools environment"
        },
        {
            "location": "/00_INTRO/",
            "text": "Overview\n\n\nThis is the knowledge base for our DevTools project. The goal of DevTools is to provide consistent environments \n tooling for our teams to enable delivery of the highest quality work for our clients.\n\n\nBackground / What\u2019s in it for you?\n\n\nDevTools covers an entire toolbox of solutions to accelerate development and smoothly implement best practices.  We intend to use the DevTools umbrella to help us roll these tools and approaches out to the whole company in a more consistent fashion.\n\n\nAcross a wide variety of projects and clients, keeping a development, integration, staging, production and other environments synchronized in terms of server configuration and supporting software versions and tooling has always been a challenge. The multitude of platforms and versions of operating systems and software is only growing. In the past we have used Vagrant in conjunction with a virtual machine (VM) for local development environments, project-based VMs on Dev Cloud for integration environments and tools like Puppet to try and ensure all of those match each other and the deployment environments. \n\n\nIt\u2019s been better than doing it all by hand but it has required building additional expertise above typical system management tools and it\u2019s relatively inefficient to have many project-specific VMs locally. On top of that are the various, sometimes conflicting, versions of development toolchains which the VMs don\u2019t always address.\n\n\nDevTools is going to address this problem by providing an efficient way to have project/app-specific environments as well as development tooling by using a concept called containerization. This lets us focus on items at a service-and-tools level rather than at a server level and make the details of our hosting implementation more transparent to all technical team members .\n\n\nContainerization\n\n\nIn order to provide lightweight environments and tooling we will be using a technical approach called containers.  Containers attempt to move the unit of environment from server to application. This allows separation of concerns between how an application is configured, how the containers communicate with each other, and where the containers are deployed.  Take an advanced Drupal stack that includes Apache/PHP, MySQL, Memcache, and SOLR. With each component configured to run in its own container, the containers can all run on a single VM for local development and be spread across multiple servers for an optimized production deployment. Let us briefly touch on the technology we will be using and how it conceptually fits together.\n\n\nDocker\n\n\nThe container implementation we use is called Docker which is explained in the intro: \nWhat is Docker\n? This is the way we capture environment units for our application/services and share them with everyone on the team.  Environments are captured as images, similar to a VM, so when anyone runs that image they all start with the exact same set of files. For example, nearly every Phase2 project needs a web server so we have a container image that can be run to provide that service. \n\n\nGlossary\n\n\nFor those that want a bit more detail \n\n\n\n\n\n\nHost Machine\n - Your laptop for the purposes of DevTools. This is where your project's source code, your IDE, browsers, etc run as well as where the virtual machine acting as the Docker Host runs.\n\n\n\n\n\n\nDocker Host\n - This is a Linux-based virtual machine capable of running Docker. One Docker host VM can run multiple containers for multiple projects.\n\n\n\n\n\n\nDocker Image\n - A read only template that can be instantiated as a running container. An image might supply a service as small as a build tool or as large as a database and/or web server. Images are generally single purpose in nature and are then linked together to build more complex capabilities.\n\n\n\n\n\n\nContainer\n - A runtime instance of a Docker Image. This is what contains a service like Apache or MySQL. Several containers can run on a single Docker Host and they can be linked so that they they know how to communicate with each other.\n\n\n\n\n\n\nDocker Machine\n\n\nDocker Machine creates the Docker Host virtual machine in which containers run.  This provides the functionality that we previously used Vagrant to accomplish. Under the covers docker-machine starts up a virtual machine running a tiny version of Linux.  On Macs this tiny version of Linux is called boot2docker.  All of the Docker commands to build and run containers will actually be executed on the boot2docker virtual machine. On your laptop you will have a single boot2docker virtual machine (running in VirtualBox or VMWare Fusion) and it will host one or more Docker containers. Each project will likely have multiple Docker containers running (web server, database, memcache, search, etc.).\n\n\nDocker Compose\n\n\nDocker Compose is used to manage and coordinate the containers that need to run for a project in an easy to use YAML file. Each project will have a docker-compose file for each Docker environment that the project supports.  For example, the default docker-compose.yml would be used to start containers for local development, and alternate Docker compose files could be included for starting containers for the integration/stage and other environments.",
            "title": "Introduction"
        },
        {
            "location": "/00_INTRO/#overview",
            "text": "This is the knowledge base for our DevTools project. The goal of DevTools is to provide consistent environments   tooling for our teams to enable delivery of the highest quality work for our clients.",
            "title": "Overview"
        },
        {
            "location": "/00_INTRO/#background-whats-in-it-for-you",
            "text": "DevTools covers an entire toolbox of solutions to accelerate development and smoothly implement best practices.  We intend to use the DevTools umbrella to help us roll these tools and approaches out to the whole company in a more consistent fashion.  Across a wide variety of projects and clients, keeping a development, integration, staging, production and other environments synchronized in terms of server configuration and supporting software versions and tooling has always been a challenge. The multitude of platforms and versions of operating systems and software is only growing. In the past we have used Vagrant in conjunction with a virtual machine (VM) for local development environments, project-based VMs on Dev Cloud for integration environments and tools like Puppet to try and ensure all of those match each other and the deployment environments.   It\u2019s been better than doing it all by hand but it has required building additional expertise above typical system management tools and it\u2019s relatively inefficient to have many project-specific VMs locally. On top of that are the various, sometimes conflicting, versions of development toolchains which the VMs don\u2019t always address.  DevTools is going to address this problem by providing an efficient way to have project/app-specific environments as well as development tooling by using a concept called containerization. This lets us focus on items at a service-and-tools level rather than at a server level and make the details of our hosting implementation more transparent to all technical team members .",
            "title": "Background / What\u2019s in it for you?"
        },
        {
            "location": "/00_INTRO/#containerization",
            "text": "In order to provide lightweight environments and tooling we will be using a technical approach called containers.  Containers attempt to move the unit of environment from server to application. This allows separation of concerns between how an application is configured, how the containers communicate with each other, and where the containers are deployed.  Take an advanced Drupal stack that includes Apache/PHP, MySQL, Memcache, and SOLR. With each component configured to run in its own container, the containers can all run on a single VM for local development and be spread across multiple servers for an optimized production deployment. Let us briefly touch on the technology we will be using and how it conceptually fits together.",
            "title": "Containerization"
        },
        {
            "location": "/00_INTRO/#docker",
            "text": "The container implementation we use is called Docker which is explained in the intro:  What is Docker ? This is the way we capture environment units for our application/services and share them with everyone on the team.  Environments are captured as images, similar to a VM, so when anyone runs that image they all start with the exact same set of files. For example, nearly every Phase2 project needs a web server so we have a container image that can be run to provide that service.",
            "title": "Docker"
        },
        {
            "location": "/00_INTRO/#glossary",
            "text": "For those that want a bit more detail     Host Machine  - Your laptop for the purposes of DevTools. This is where your project's source code, your IDE, browsers, etc run as well as where the virtual machine acting as the Docker Host runs.    Docker Host  - This is a Linux-based virtual machine capable of running Docker. One Docker host VM can run multiple containers for multiple projects.    Docker Image  - A read only template that can be instantiated as a running container. An image might supply a service as small as a build tool or as large as a database and/or web server. Images are generally single purpose in nature and are then linked together to build more complex capabilities.    Container  - A runtime instance of a Docker Image. This is what contains a service like Apache or MySQL. Several containers can run on a single Docker Host and they can be linked so that they they know how to communicate with each other.",
            "title": "Glossary"
        },
        {
            "location": "/00_INTRO/#docker-machine",
            "text": "Docker Machine creates the Docker Host virtual machine in which containers run.  This provides the functionality that we previously used Vagrant to accomplish. Under the covers docker-machine starts up a virtual machine running a tiny version of Linux.  On Macs this tiny version of Linux is called boot2docker.  All of the Docker commands to build and run containers will actually be executed on the boot2docker virtual machine. On your laptop you will have a single boot2docker virtual machine (running in VirtualBox or VMWare Fusion) and it will host one or more Docker containers. Each project will likely have multiple Docker containers running (web server, database, memcache, search, etc.).",
            "title": "Docker Machine"
        },
        {
            "location": "/00_INTRO/#docker-compose",
            "text": "Docker Compose is used to manage and coordinate the containers that need to run for a project in an easy to use YAML file. Each project will have a docker-compose file for each Docker environment that the project supports.  For example, the default docker-compose.yml would be used to start containers for local development, and alternate Docker compose files could be included for starting containers for the integration/stage and other environments.",
            "title": "Docker Compose"
        },
        {
            "location": "/10_TOOLCHAIN/",
            "text": "Phase2 Tooling\n\n\nNow that we\u2019ve covered the technology we\u2019re using, here is a run down on the tooling that ties it all together and that you\u2019ll download to get started.\n\n\ndevtools-cli\n\n\nThis is a Phase2 project that glues all of the hosting aspects of these tools together into an easy to use unit. You can find devtools-cli in our BitBucket repository \nhere\n.  There are 2 basic services that devtools-cli provides:\n\n\nManage virtual machines for running containers\n\n\nThe devtools binary will manage the creation/configuration/upgrade/start/stop of boot2docker virtual machines (a.k.a Docker Hosts) via docker-machine.  It ensures that the docker-machine virtual machine is the right version, is named correctly and configured to run efficiently within Virtualbox, VMWare Fusion or xhyve.\n\n\nNice DNS names and routing for running containers\n\n\nOnce there is a safe environment to run our containers we need a way to route traffic to them and provide easy to use/remember domain names to make accessing these services simple. Domain names for containers are set in the docker-compose yaml files using the \nDNSDOCK_NAME\n and \nDNSDOCK_IMAGE\n environment variables.\n\n\nWe use a pair of services: \ndnsdock\n and \ndnsmasq\n running as containers within the Docker Host. \ndnsmasq\n listens on 172.17.0.1:53 and it is currently configured to send all queries for *.p2devcloud.com to our internal 10.10.7.2 resolver and the rest will be sent to the \ndnsdock\n service, which listens on 172.17.0.1:53535. The \ndnsdock\n container resolves the .vm domain names to the IP addresses of the containers.\n\n\nThe practical effect of this is that you must be on the Phase2 VPN or on the private Wi-Fi of a Phase2 office to get access to *.p2devcloud.com domains, but once you are either on the VPN or in an office, you will bypass the Dev Cloud public proxy.\n\n\nInternal container names will look like \nweb.openatrium.vm\n.  All DevTools containers will carry the \n.vm\n extension for name resolution. There is additional information about these variables in \n20_PROJECT_SETUP.md\n.\n\n\np2docker\n\n\nThe name p2docker refers to a collection of Docker Images that we maintain to provide consistent and easily configurable services to our projects.  If you are attempting to put together a docker-compose configuration file, you should look at the container images provided by p2docker as a source of images to use. You can also look at Docker Hub for other community containers of interest as well. The \np2docker repo\n contains the source for common Phase2 Docker Images that are hosted in the \nPhase2 Docker Hub\n account.\n\n\nDocker Hub\n\n\nDocker Hub is where container images are stored and retrieved when your local machine does not already have a copy of the requested container image.  Docker Hub can be thought of like GitHub or BitBucket and Docker Hub images can be thought of as git repositories. We can make new versions of the images and they can be pushed and pulled to the Docker Hub service.\n\n\nPutting it all together\n\n\nThere are some important pieces to remember about how containerization is similar and different to concepts you may be familiar with.\n\n\nVagrant\n\n\nVagrant is being replaced by the combination of Docker Compose and Docker Machine.\n\n\nVirtual Machines\n\n\nFor local development, you should no longer worry about Virtual Machines as they are replaced by a single Docker Machine instance. In environments where containers are meant to run on a cluster of hosts, orchestration tools like \nKubernetes\n or \nNomad\n may be used to distribute and coordinate containers across multiple Docker Hosts.\n\n\nPuppet\n\n\nGoodbye, for local environments at least. Docker uses a conceptually different approach to configuration management than Puppet. It\u2019s perfectly possible to use Puppet from within a Dockerfile to get a container image prepared though typically simple shell commands are preferred.  The idea is that systems like Puppet are no longer needed to manage upgrades across working servers/containers. When there are updates needed you will update the image, pull down the new version of the image to your server and then stop the containers running the old version of the image and start containers based on the new version of the image.\n\n\nIf a container wants to offer configurable options it will document how to control it within the README or via Environment variables in the Dockerfile itself.  See our Apache / PHP \nDockerfile\n for an example. In this Docker Image, passing environment variables can override the PHP memory limit. Those variables can either be passed on the command line when executing a \ndocker run\n command directly, or in the \nenvironment\n section of a docker-compose file.\n\n\nProject Code\n\n\nThe filesystem within containers is \nephemeral!\n Any changes made there \ndo not persist\n if the container is restarted. (See \"Persistent Data Volume\" below for a storage area that is preserved.)\n\n\nIn typical Docker images the code is built \ndirectly into the container\n at the \n/code\n path. This is a great mechanism that allows the container to be \"self contained\" (pun intended), immutable and not need any checkout/file system. You also know when you run a container exactly what code is in there because you generally don\u2019t change the code unless you rebuild the image.  \n\n\nFor development purposes, however, this is problematic because it is burdensome to rebuild an image for each code change. To solve this, we mount project code from the Host Machine into the running container, effectively overriding the files built directly into the image. The running container is then using the local project file system for the overridden paths rather than the file system built into the container.  This allows a developer to use an IDE and edit code directly on the local file system of the Host Machine, but execute that code within the environment of the running container.\n\n\nNOTE ON PROJECT CODE LOCATION\n\n\nYour project code \nmust\n be located somewhere within your home directory (\n/Users\n for Macs) on your local machine. This is because VirtualBox and VMWare shares your home directory into the Docker Host VM, and only files on the Docker Host VM can be referenced in volume shares from a Docker compose file. Within the volume portions of a docker-compose file there is also a bit of translation that happens for relative paths. If you ask for the ./html directory from your local machine to appear as \n/var/www/html\n using a line like: \n./html:/var/www/html\n that is translated to a full path based on the location of the docker-compose file. If that doesn\u2019t work out to something under your home directory the sharing of files from your Host Machine isn\u2019t going to work. If you specify a full path, it also needs to be from your home directory.\n\n\nPersistent Data Volume\n\n\nDevTools maintains a data volume on the Docker Host that is mounted at \n/data\n into every container. This volume is persistent so long as you do not perform a \ndevtools remove\n operation. This ensures that file access on the VM is done natively for things like MongoDB and MySQL. If you configure a container to write to this area, you should use a project and container based namespace to prevent conflicts as this is a shared resource. For example, you may want to use a namespacing method like \n/data/${DNSDOCK_IMAGE}/${DNSDOCK_NAME}\n as a safe location to write data.\n\n\nAny code from your local directories is directly shared in to the Docker Machine VM via NFS. This means that even if you destroy and re-create your Docker Host, your code will be safe since it lives on the Host Machine.\n\n\nNOTE ON FILE CHANGES WITHIN A CONTAINER\n\n\nAny files that are generated or changed within a running container that you want to persist after the container is stopped \nshould be put onto a volume that is mounted into the container from the local machine\n.  A Docker container represents immutable infrastructure, the files on the image are able to be changed at runtime but typically do not persist. When the container is stopped and run again it \"boots\" the files that were built into the original image. The volume at \n/data\n as mentioned above is a persistent volume that you can use.",
            "title": "Tool Chain"
        },
        {
            "location": "/10_TOOLCHAIN/#phase2-tooling",
            "text": "Now that we\u2019ve covered the technology we\u2019re using, here is a run down on the tooling that ties it all together and that you\u2019ll download to get started.",
            "title": "Phase2 Tooling"
        },
        {
            "location": "/10_TOOLCHAIN/#devtools-cli",
            "text": "This is a Phase2 project that glues all of the hosting aspects of these tools together into an easy to use unit. You can find devtools-cli in our BitBucket repository  here .  There are 2 basic services that devtools-cli provides:",
            "title": "devtools-cli"
        },
        {
            "location": "/10_TOOLCHAIN/#manage-virtual-machines-for-running-containers",
            "text": "The devtools binary will manage the creation/configuration/upgrade/start/stop of boot2docker virtual machines (a.k.a Docker Hosts) via docker-machine.  It ensures that the docker-machine virtual machine is the right version, is named correctly and configured to run efficiently within Virtualbox, VMWare Fusion or xhyve.",
            "title": "Manage virtual machines for running containers"
        },
        {
            "location": "/10_TOOLCHAIN/#nice-dns-names-and-routing-for-running-containers",
            "text": "Once there is a safe environment to run our containers we need a way to route traffic to them and provide easy to use/remember domain names to make accessing these services simple. Domain names for containers are set in the docker-compose yaml files using the  DNSDOCK_NAME  and  DNSDOCK_IMAGE  environment variables.  We use a pair of services:  dnsdock  and  dnsmasq  running as containers within the Docker Host.  dnsmasq  listens on 172.17.0.1:53 and it is currently configured to send all queries for *.p2devcloud.com to our internal 10.10.7.2 resolver and the rest will be sent to the  dnsdock  service, which listens on 172.17.0.1:53535. The  dnsdock  container resolves the .vm domain names to the IP addresses of the containers.  The practical effect of this is that you must be on the Phase2 VPN or on the private Wi-Fi of a Phase2 office to get access to *.p2devcloud.com domains, but once you are either on the VPN or in an office, you will bypass the Dev Cloud public proxy.  Internal container names will look like  web.openatrium.vm .  All DevTools containers will carry the  .vm  extension for name resolution. There is additional information about these variables in  20_PROJECT_SETUP.md .",
            "title": "Nice DNS names and routing for running containers"
        },
        {
            "location": "/10_TOOLCHAIN/#p2docker",
            "text": "The name p2docker refers to a collection of Docker Images that we maintain to provide consistent and easily configurable services to our projects.  If you are attempting to put together a docker-compose configuration file, you should look at the container images provided by p2docker as a source of images to use. You can also look at Docker Hub for other community containers of interest as well. The  p2docker repo  contains the source for common Phase2 Docker Images that are hosted in the  Phase2 Docker Hub  account.",
            "title": "p2docker"
        },
        {
            "location": "/10_TOOLCHAIN/#docker-hub",
            "text": "Docker Hub is where container images are stored and retrieved when your local machine does not already have a copy of the requested container image.  Docker Hub can be thought of like GitHub or BitBucket and Docker Hub images can be thought of as git repositories. We can make new versions of the images and they can be pushed and pulled to the Docker Hub service.",
            "title": "Docker Hub"
        },
        {
            "location": "/10_TOOLCHAIN/#putting-it-all-together",
            "text": "There are some important pieces to remember about how containerization is similar and different to concepts you may be familiar with.",
            "title": "Putting it all together"
        },
        {
            "location": "/10_TOOLCHAIN/#vagrant",
            "text": "Vagrant is being replaced by the combination of Docker Compose and Docker Machine.",
            "title": "Vagrant"
        },
        {
            "location": "/10_TOOLCHAIN/#virtual-machines",
            "text": "For local development, you should no longer worry about Virtual Machines as they are replaced by a single Docker Machine instance. In environments where containers are meant to run on a cluster of hosts, orchestration tools like  Kubernetes  or  Nomad  may be used to distribute and coordinate containers across multiple Docker Hosts.",
            "title": "Virtual Machines"
        },
        {
            "location": "/10_TOOLCHAIN/#puppet",
            "text": "Goodbye, for local environments at least. Docker uses a conceptually different approach to configuration management than Puppet. It\u2019s perfectly possible to use Puppet from within a Dockerfile to get a container image prepared though typically simple shell commands are preferred.  The idea is that systems like Puppet are no longer needed to manage upgrades across working servers/containers. When there are updates needed you will update the image, pull down the new version of the image to your server and then stop the containers running the old version of the image and start containers based on the new version of the image.  If a container wants to offer configurable options it will document how to control it within the README or via Environment variables in the Dockerfile itself.  See our Apache / PHP  Dockerfile  for an example. In this Docker Image, passing environment variables can override the PHP memory limit. Those variables can either be passed on the command line when executing a  docker run  command directly, or in the  environment  section of a docker-compose file.",
            "title": "Puppet"
        },
        {
            "location": "/10_TOOLCHAIN/#project-code",
            "text": "The filesystem within containers is  ephemeral!  Any changes made there  do not persist  if the container is restarted. (See \"Persistent Data Volume\" below for a storage area that is preserved.)  In typical Docker images the code is built  directly into the container  at the  /code  path. This is a great mechanism that allows the container to be \"self contained\" (pun intended), immutable and not need any checkout/file system. You also know when you run a container exactly what code is in there because you generally don\u2019t change the code unless you rebuild the image.    For development purposes, however, this is problematic because it is burdensome to rebuild an image for each code change. To solve this, we mount project code from the Host Machine into the running container, effectively overriding the files built directly into the image. The running container is then using the local project file system for the overridden paths rather than the file system built into the container.  This allows a developer to use an IDE and edit code directly on the local file system of the Host Machine, but execute that code within the environment of the running container.",
            "title": "Project Code"
        },
        {
            "location": "/10_TOOLCHAIN/#note-on-project-code-location",
            "text": "Your project code  must  be located somewhere within your home directory ( /Users  for Macs) on your local machine. This is because VirtualBox and VMWare shares your home directory into the Docker Host VM, and only files on the Docker Host VM can be referenced in volume shares from a Docker compose file. Within the volume portions of a docker-compose file there is also a bit of translation that happens for relative paths. If you ask for the ./html directory from your local machine to appear as  /var/www/html  using a line like:  ./html:/var/www/html  that is translated to a full path based on the location of the docker-compose file. If that doesn\u2019t work out to something under your home directory the sharing of files from your Host Machine isn\u2019t going to work. If you specify a full path, it also needs to be from your home directory.",
            "title": "NOTE ON PROJECT CODE LOCATION"
        },
        {
            "location": "/10_TOOLCHAIN/#persistent-data-volume",
            "text": "DevTools maintains a data volume on the Docker Host that is mounted at  /data  into every container. This volume is persistent so long as you do not perform a  devtools remove  operation. This ensures that file access on the VM is done natively for things like MongoDB and MySQL. If you configure a container to write to this area, you should use a project and container based namespace to prevent conflicts as this is a shared resource. For example, you may want to use a namespacing method like  /data/${DNSDOCK_IMAGE}/${DNSDOCK_NAME}  as a safe location to write data.  Any code from your local directories is directly shared in to the Docker Machine VM via NFS. This means that even if you destroy and re-create your Docker Host, your code will be safe since it lives on the Host Machine.",
            "title": "Persistent Data Volume"
        },
        {
            "location": "/10_TOOLCHAIN/#note-on-file-changes-within-a-container",
            "text": "Any files that are generated or changed within a running container that you want to persist after the container is stopped  should be put onto a volume that is mounted into the container from the local machine .  A Docker container represents immutable infrastructure, the files on the image are able to be changed at runtime but typically do not persist. When the container is stopped and run again it \"boots\" the files that were built into the original image. The volume at  /data  as mentioned above is a persistent volume that you can use.",
            "title": "NOTE ON FILE CHANGES WITHIN A CONTAINER"
        },
        {
            "location": "/20_PROJECT_SETUP/",
            "text": "How to get started\n\n\n\n\n\n\nInstall DevTools via Homebrew. First, tap the Homebrew repository \nbrew tap phase2/devtools\n, then install DevTools \nbrew install devtools\n. \n\n\n\n\n\n\nFollow the instructions in the \nDevTools Index\n to get your environment configured. All of the following sample commands will assume you\u2019ve installed things as suggested in the README.\n\n\n\n\n\n\nGet ready to run containers\n\n\nWhen you want to start the Docker containers for a project, do the following:\n\n\n\n\n\n\nEnsure the Docker Host VM is active by running: \ndevtools start\n\n\n\n\nThis will create a Docker Host if one does not exist already\n\n\nTo customize this Docker Host you can provide the following configuration options.\n\n\nname:\n The Docker Machine name for the VM. Defaults to \ndev\n\n\ndriver:\n The driver to create the Docker Machine with. Choices are \nvirtualbox\n, \nvmwarefuaion\n, and \nxhyve\n. Defaults to \nvirtualbox\n\n\ncpuCount:\n The number of virtual CPU you want to allocate to this VM. Defaults to 2\n\n\nmemSize:\n The size memory you want to configure for this VM, in Megabytes. Defaults to 4096\n\n\ndiskSize:\n The size drive you want to configure for this VM, in Gigabytes. Defaults to 40\n\n\n\n\n\n\n\n\n\n\n\n\nEnsure all terminals you intend to use have \neval \"$(devtools config)\"\n run in them. It is best to put this configuration in your .bashrc/.zshrc, see the main \nDevTools Index\n for more details. This command must be rerun after any start/restart of the Docker Host VM.\n\n\n\n\n\n\nIn the project directory, start the containers with: \ndocker-compose up\n\n\n\n\n\n\nNote: The docker-compose command runs in the foreground as long as the Docker containers are running. \n(It is not hung if there is no output after \"Attaching \n...\")\n\n\n\n\n\n\nLogs from the running containers will stream to the console and be prefixed by their compose names plus an integer (i.e. web_1, db_1, etc)\n\n\n\n\n\n\n\n\n\n\nStart another terminal if you need to run other commands (such as the build container cli)\n\n\n\n\n\n\nStopping the containers for your project\n\n\nYou may want to recoup the resources used by your projects containers and the docker host for other things if you are done with development for a while.  You can stop the containers for a single project only or all containers and the docker host depending on what you are finished using.\n\n\n\n\n\n\nIf you only want to stop the containers for your project, in the project directory, run \ndocker-compose stop\n or press Ctrl-C to stop a docker-compose process running in the foreground and then run \ndocker-compose stop\n to ensure the project containers have stopped.\n\n\n\n\n\n\nIf you want to shut down the docker host as well as any containers, run \ndevtools stop\n\n\n\n\n\n\nCleaning Up\n\n\nFrom time to time you'll want to clean up stopped containers. You'll also want to take special care when finishing a project to release all the resources used by it.\n\n\nFor periodic cleanup of all stopped containers, run the following script while your docker host is running: \ndevtools prune\n\n\nIf you only want to clean up project specific stopped containers, you can run: \ndocker-compose rm\n from your project directory.\n\n\nWhen you are finished with a project, if you used any persistent data storage you'll want to run a command to clean it up. The exact directory to request removal from will depend on your project (see suggested namespace guidelines in the TOOLCHAIN document): \ndocker ssh dev sudo rm -rf /data/PROJECT_DIR\n\n\nSetting up a project\n\n\nTo set up a project rather than just work on one, you'll need to understand how to create a docker-compose file, how to configure DNS for your project's containers and how to configure persistent storage if your project needs it.\n\n\nThe docker-compose file\n\n\nLearn more about Docker Compose here: \nhttps://docs.docker.com/compose/\n\n\nTake a look at \nexample/drupal8\n for an example docker-compose file\n\n\nDNS Names for your containers\n\n\nWithin the environment section of the docker-compose file you can specify variables that will control the DNS name of your containers  \n\n\n\n\n\n\nDNSDOCK_NAME - This is the type of container. Usually something like web, db, cache, etc.\n\n\n\n\n\n\nDNSDOCK_IMAGE - This is generally your project name (e.g fieldnotes, openatrium, etc.)\n\n\n\n\n\n\nAll DNS names will end in \n.vm\n\n\n\n\n\n\nThose items combine so that you can refer to services running in the containers using domain names of the form \nDNSDOCK_NAME.DNSDOCK_IMAGE.vm\n (e.g web.phase2.vm)\n\n\n\n\n\n\nIf you need multiple domains mapped to a container you can use the DNSDOCK_ALIAS setting. It takes a full domain name and can take a comma separated list (e.g. portland.phase2.vm,alexandria.phase2.vm)\n\n\n\n\n\n\nDNS Forwarders\n\n\nDevTools can be configured to use additional name servers to forward DNS requests if the record cannot be resolved by dnsdock.\n\n\nAn example is if you connect to a VPN and need to resolve addresses to private servers within a VPN.  To enable this you need to configure the \nDEVTOOLS_NAMESERVERS\n environment variable to a comma separated list of \nip:port\n (example: \n10.10.7.2:53,8.8.8.8:53\n) before running either \ndevtools start\n or \ndevtools dns\n. We suggest putting this env var configuration in your \n~/.bashrc\n or \n~/.zshrc\n so that it is always present when needed.  If you just need this temporarily, you can pass the configuration in with the \n--nameservers\n command line option to \ndevtools start\n or \ndevtools dns\n. \n\n\nThis configuration will try each forwarder name server, in order, to resolve names until success or all name servers have been exhausted.\n\n\nDNS Command\n\n\nThere is also a \ndevtools dns\n command that will launch and configure our DNS services on any Docker Host. If you want to configure DNS on a Docker Host other than \ndev\n be sure to specify the \n--name\n parameter.\n\n\nDNS Debugging\n\n\nIf you want to see what containers have registered names, use the \ndevtools dns-records\n command. This command will list all registered container names and aliases along with the container's IP address.\n\n\nWorking with Volumes\n\n\nVolumes are a way that you can map directories or individual files into a running container.  This is useful to provide code to run for a generic container, or directories to store data that persist longer than the life of the container, or to even override directories and/or files that exist in an image.  Lets look at a few of those examples.\n\n\nProvide code for a generic container to run\n\n\nThe default phase2/apache-php:php70 is a Web/PHP container that provides only an index file in \n/var/www/html\n that prints out phpinfo().  This is obviously not very useful for an application, so we can provide the an entire Drupal site to run and we do that by mapping our site into the default docroot like this:\n\n\n./build/html:/var/www/html\n\n\nThis takes the Drupal site we have in our local project directory of \nbuild/html\n and it overrides the default content of the images \n/var/www/html\n directory.\n\n\nPersist data longer than the life of the container\n\n\nWhen using a database like mysql the container will store the database files in \n/var/lib/mysql\n and by default that directory will be reset every time the container restarts. This means each time you restart your container you\u2019d need to reinstall your application and database, which can make life difficult. So in order to persist mysql data for longer than the current run of the container we will map a directory from the Docker Host into the container and override the default \n/var/lib/mysql\n directory. The configuration will look something like this.\n\n\n/data/drupal/mysql:/var/lib/mysql\n\n\nNow when your database container creates files in \n/var/lib/mysql\n they are actually saved in the \n/data/drupal/mysql\n directory on the Docker Host. Be sure to namespace your directories inside /data so that separate projects don't conflict with each other. You'll also want to ensure you clean up when you are done with your project to keep from using up all of your disk space. See the cleaning up section for more info.\n\n\nOverride directories and files that exist in an image\n\n\nGenerally the configuration shipped with a Docker Image is meant to be the production configuration. Often, that configuration is not suitable for development and we need to override configurations.  With volumes we have shown earlier how you can override directories, but you can also override individual files too.\n\n\n./config/dev/httpd/httpd.conf:/etc/httpd/httpd.conf\n\n\nThis takes a local \nhttpd.conf\n file from our project and overrides the \n/etc/httpd/httpd.conf\n files that ships with the container. \n\n\nResetting a Docker Container\n\n\nIf you change the docker-compose.yml configuration, for example to add/remove/change an environment variable, or you pull down a new version of a docker image, you can reset the Docker container simply by restarting.\n\n\nHowever, if you wind up changing volume definitions in your docker-compose file you will need to remove your container before it will recognize those changes on a restart.\n\n\nIn the project directory, run: \ndocker-compose rm\n\n\nThis command will remove all stopped containers defined in the docker-compose.yml.  You could also  remove an individual container by running: \ndocker-compose rm \nname in yml\n\n\nAfter removing the container, it will revert to the original state from the Docker image, removing any packages installed or files modified that are not included in a volume mount. Start your containers again with \ndocker-compose up\n and you should have your new volume mounts.\n\n\nCreating a Dockerfile\n\n\nThe Dockerfile you create for your project should represent the application as it will need to run in production. There are many reasons to have a Dockerfile to create an image, but if you don\u2019t intend on running containers in production you can likely skip this part. \n\n\nThe most minimal project container will need to have your code in it.\n\n\n\n\n\n\nStart by determining which Docker image you will need to extend. \n\n\n\n\n\n\nFor the general Drupal use cases you will base your project Dockerfile on apache-php:php70.\n\n\n\n\nFROM phase2/apache-php:php70\n\n\n\n\n\n\n\n\nThen copy your code into the correct place for the container. For a PHP/Drupal project, copy the materialized site code into the container docroot\n\n\n\n\nCOPY ./html /var/www/html/\n\n\n\n\n\n\n\n\nBuild the Dockerfile into an image\n\n\n\n\ndocker build -t \nsome-name\n .\n\n\n\n\n\n\n\n\nOn successful build, test the image by running\n\n\n\n\ndocker run -t \nsome-name\n\n\n\n\n\n\n\n\nHere is the full (simple) Dockerfile\n\n\nFROM phase2/apache-php:php70\n\n# Copy in the site\nCOPY ./html /var/www/html/",
            "title": "Project Setup"
        },
        {
            "location": "/20_PROJECT_SETUP/#how-to-get-started",
            "text": "Install DevTools via Homebrew. First, tap the Homebrew repository  brew tap phase2/devtools , then install DevTools  brew install devtools .     Follow the instructions in the  DevTools Index  to get your environment configured. All of the following sample commands will assume you\u2019ve installed things as suggested in the README.",
            "title": "How to get started"
        },
        {
            "location": "/20_PROJECT_SETUP/#get-ready-to-run-containers",
            "text": "When you want to start the Docker containers for a project, do the following:    Ensure the Docker Host VM is active by running:  devtools start   This will create a Docker Host if one does not exist already  To customize this Docker Host you can provide the following configuration options.  name:  The Docker Machine name for the VM. Defaults to  dev  driver:  The driver to create the Docker Machine with. Choices are  virtualbox ,  vmwarefuaion , and  xhyve . Defaults to  virtualbox  cpuCount:  The number of virtual CPU you want to allocate to this VM. Defaults to 2  memSize:  The size memory you want to configure for this VM, in Megabytes. Defaults to 4096  diskSize:  The size drive you want to configure for this VM, in Gigabytes. Defaults to 40       Ensure all terminals you intend to use have  eval \"$(devtools config)\"  run in them. It is best to put this configuration in your .bashrc/.zshrc, see the main  DevTools Index  for more details. This command must be rerun after any start/restart of the Docker Host VM.    In the project directory, start the containers with:  docker-compose up    Note: The docker-compose command runs in the foreground as long as the Docker containers are running.  (It is not hung if there is no output after \"Attaching  ...\")    Logs from the running containers will stream to the console and be prefixed by their compose names plus an integer (i.e. web_1, db_1, etc)      Start another terminal if you need to run other commands (such as the build container cli)",
            "title": "Get ready to run containers"
        },
        {
            "location": "/20_PROJECT_SETUP/#stopping-the-containers-for-your-project",
            "text": "You may want to recoup the resources used by your projects containers and the docker host for other things if you are done with development for a while.  You can stop the containers for a single project only or all containers and the docker host depending on what you are finished using.    If you only want to stop the containers for your project, in the project directory, run  docker-compose stop  or press Ctrl-C to stop a docker-compose process running in the foreground and then run  docker-compose stop  to ensure the project containers have stopped.    If you want to shut down the docker host as well as any containers, run  devtools stop",
            "title": "Stopping the containers for your project"
        },
        {
            "location": "/20_PROJECT_SETUP/#cleaning-up",
            "text": "From time to time you'll want to clean up stopped containers. You'll also want to take special care when finishing a project to release all the resources used by it.  For periodic cleanup of all stopped containers, run the following script while your docker host is running:  devtools prune  If you only want to clean up project specific stopped containers, you can run:  docker-compose rm  from your project directory.  When you are finished with a project, if you used any persistent data storage you'll want to run a command to clean it up. The exact directory to request removal from will depend on your project (see suggested namespace guidelines in the TOOLCHAIN document):  docker ssh dev sudo rm -rf /data/PROJECT_DIR",
            "title": "Cleaning Up"
        },
        {
            "location": "/20_PROJECT_SETUP/#setting-up-a-project",
            "text": "To set up a project rather than just work on one, you'll need to understand how to create a docker-compose file, how to configure DNS for your project's containers and how to configure persistent storage if your project needs it.",
            "title": "Setting up a project"
        },
        {
            "location": "/20_PROJECT_SETUP/#the-docker-compose-file",
            "text": "Learn more about Docker Compose here:  https://docs.docker.com/compose/  Take a look at  example/drupal8  for an example docker-compose file",
            "title": "The docker-compose file"
        },
        {
            "location": "/20_PROJECT_SETUP/#dns-names-for-your-containers",
            "text": "Within the environment section of the docker-compose file you can specify variables that will control the DNS name of your containers      DNSDOCK_NAME - This is the type of container. Usually something like web, db, cache, etc.    DNSDOCK_IMAGE - This is generally your project name (e.g fieldnotes, openatrium, etc.)    All DNS names will end in  .vm    Those items combine so that you can refer to services running in the containers using domain names of the form  DNSDOCK_NAME.DNSDOCK_IMAGE.vm  (e.g web.phase2.vm)    If you need multiple domains mapped to a container you can use the DNSDOCK_ALIAS setting. It takes a full domain name and can take a comma separated list (e.g. portland.phase2.vm,alexandria.phase2.vm)",
            "title": "DNS Names for your containers"
        },
        {
            "location": "/20_PROJECT_SETUP/#dns-forwarders",
            "text": "DevTools can be configured to use additional name servers to forward DNS requests if the record cannot be resolved by dnsdock.  An example is if you connect to a VPN and need to resolve addresses to private servers within a VPN.  To enable this you need to configure the  DEVTOOLS_NAMESERVERS  environment variable to a comma separated list of  ip:port  (example:  10.10.7.2:53,8.8.8.8:53 ) before running either  devtools start  or  devtools dns . We suggest putting this env var configuration in your  ~/.bashrc  or  ~/.zshrc  so that it is always present when needed.  If you just need this temporarily, you can pass the configuration in with the  --nameservers  command line option to  devtools start  or  devtools dns .   This configuration will try each forwarder name server, in order, to resolve names until success or all name servers have been exhausted.",
            "title": "DNS Forwarders"
        },
        {
            "location": "/20_PROJECT_SETUP/#dns-command",
            "text": "There is also a  devtools dns  command that will launch and configure our DNS services on any Docker Host. If you want to configure DNS on a Docker Host other than  dev  be sure to specify the  --name  parameter.",
            "title": "DNS Command"
        },
        {
            "location": "/20_PROJECT_SETUP/#dns-debugging",
            "text": "If you want to see what containers have registered names, use the  devtools dns-records  command. This command will list all registered container names and aliases along with the container's IP address.",
            "title": "DNS Debugging"
        },
        {
            "location": "/20_PROJECT_SETUP/#working-with-volumes",
            "text": "Volumes are a way that you can map directories or individual files into a running container.  This is useful to provide code to run for a generic container, or directories to store data that persist longer than the life of the container, or to even override directories and/or files that exist in an image.  Lets look at a few of those examples.  Provide code for a generic container to run  The default phase2/apache-php:php70 is a Web/PHP container that provides only an index file in  /var/www/html  that prints out phpinfo().  This is obviously not very useful for an application, so we can provide the an entire Drupal site to run and we do that by mapping our site into the default docroot like this:  ./build/html:/var/www/html  This takes the Drupal site we have in our local project directory of  build/html  and it overrides the default content of the images  /var/www/html  directory.  Persist data longer than the life of the container  When using a database like mysql the container will store the database files in  /var/lib/mysql  and by default that directory will be reset every time the container restarts. This means each time you restart your container you\u2019d need to reinstall your application and database, which can make life difficult. So in order to persist mysql data for longer than the current run of the container we will map a directory from the Docker Host into the container and override the default  /var/lib/mysql  directory. The configuration will look something like this.  /data/drupal/mysql:/var/lib/mysql  Now when your database container creates files in  /var/lib/mysql  they are actually saved in the  /data/drupal/mysql  directory on the Docker Host. Be sure to namespace your directories inside /data so that separate projects don't conflict with each other. You'll also want to ensure you clean up when you are done with your project to keep from using up all of your disk space. See the cleaning up section for more info.  Override directories and files that exist in an image  Generally the configuration shipped with a Docker Image is meant to be the production configuration. Often, that configuration is not suitable for development and we need to override configurations.  With volumes we have shown earlier how you can override directories, but you can also override individual files too.  ./config/dev/httpd/httpd.conf:/etc/httpd/httpd.conf  This takes a local  httpd.conf  file from our project and overrides the  /etc/httpd/httpd.conf  files that ships with the container.",
            "title": "Working with Volumes"
        },
        {
            "location": "/20_PROJECT_SETUP/#resetting-a-docker-container",
            "text": "If you change the docker-compose.yml configuration, for example to add/remove/change an environment variable, or you pull down a new version of a docker image, you can reset the Docker container simply by restarting.  However, if you wind up changing volume definitions in your docker-compose file you will need to remove your container before it will recognize those changes on a restart.  In the project directory, run:  docker-compose rm  This command will remove all stopped containers defined in the docker-compose.yml.  You could also  remove an individual container by running:  docker-compose rm  name in yml  After removing the container, it will revert to the original state from the Docker image, removing any packages installed or files modified that are not included in a volume mount. Start your containers again with  docker-compose up  and you should have your new volume mounts.",
            "title": "Resetting a Docker Container"
        },
        {
            "location": "/20_PROJECT_SETUP/#creating-a-dockerfile",
            "text": "The Dockerfile you create for your project should represent the application as it will need to run in production. There are many reasons to have a Dockerfile to create an image, but if you don\u2019t intend on running containers in production you can likely skip this part.   The most minimal project container will need to have your code in it.    Start by determining which Docker image you will need to extend.     For the general Drupal use cases you will base your project Dockerfile on apache-php:php70.   FROM phase2/apache-php:php70     Then copy your code into the correct place for the container. For a PHP/Drupal project, copy the materialized site code into the container docroot   COPY ./html /var/www/html/     Build the Dockerfile into an image   docker build -t  some-name  .     On successful build, test the image by running   docker run -t  some-name     Here is the full (simple) Dockerfile  FROM phase2/apache-php:php70\n\n# Copy in the site\nCOPY ./html /var/www/html/",
            "title": "Creating a Dockerfile"
        },
        {
            "location": "/30_PROJECT_USAGE/",
            "text": "Project Usage\n\n\nWatches\n\n\nOften we need \nwatches\n running inside of our containers. This could be for webpack, grunt, nodemon, etc.  One of the main challenges with the NFS mounts used in DevTools is that they do not forward filesystem notifications across the NFS mount and into containers, so we need to facilitate that.\n\n\nThere is a command \ndevtools watch [options] \npath\n. Running this on your host will watch for changes and rsync notifications to files and directories under \npath\n into the Docker Machine VM (which will then provide filesystem notifications into the container). These are the options for \ndevtools watch\n\n\n\n\n--machine \nname\n Optional: Specify a machine to send events. It will default to our \ndev\n machine\n\n\n--ignorefile \nfile\n Optional: Specify a file that contains patterns for directories/files to ignore.  Put one entry per line (blank lines and comments are allowed). If not specified it will look for a file named \n.devtools-watch-ignore\n in the working directory and all parent directories.\n\n\n\n\nWhat is the Build container\n\n\nPart of DevTools is a \ndevtools-build\n image.  The idea of the build container is that it will have installed nearly all of the tools you'd need to work on a project and the proper versions so that they work well together.  Everything from drush to gem to npm to composer as well as grunt, bower, yeoman, etc. Providing these tools in a container means that you'll never have to worry about having the right tools installed on your laptop or integration environment to get your job done.\n\n\nHow and why to use the build container\n\n\nThe example Drupal project contains a \nbuild.yml\n Docker Compose file that shows a variety of ways to use the container that we will highlight below.\n\n\nGetting a shell for build/tooling operations\n\n\nGetting a shell into a build container to execute any operations is the simplest approach. You simply want to get access to the \ncli\n container we defined in the compose file.  The command \ndocker-compose -f build.yml run cli\n will start an instance of the \nphase2/devtools-build\n image and run a bash shell for you.  From there you are free to use \ndrush\n, \ngrunt\n or whatever your little heart desires.\n\n\nRunning commands, but not from a dedicated shell\n\n\nAnother concept in the Docker world is starting a container to run a single command and allowing the container stop when the command is completed.  This is great if you run commands infrequently, or don't want to have another container constantly running.  Running your commands on containers in this fashion is also well suited for commands that don't generate any files on the filesystem or if they do, they write those files on to volumes mounted into the container.\n\n\nThe \ndrush\n container defined in the example \nbuild.yml\n file is a container designed specifically to run drush in a single working directory taking only the commands as arguments.  This approach allows us to provide a quick and easy mechanism for running any drush command, such as \nsqlc\n, \ncache-rebuild\n, and others, in your Drupal site quick and easily.\n\n\nThere are also other examples of a \ngrunt\n command container similar to \ndrush\n and an even more specific command container around running a single command, \ndrush make\n to build the site from a make/dependency file.\n\n\nForward/Import your SSH Key into the build container to clone private repos\n\n\nCertain containers like jenkins and devtools-build may need your private key. This is supported by importing your private key into the container via a volume mount.  \n\n\nTo get your private key into the build container, volume mount your key into the container at \n/root/.ssh/devtools.key\n and it will be processed accordingly.\n\n\n~/.ssh/id_rsa:/root/.ssh/devtools.key\n\n\nMultiple Docker Machines / Using other Docker Machines\n\n\nThere are special cases in which you may want to have multiple Docker Hosts running. For example to test the performance differences between VirtualBox and xhyve.  For these cases, all \ndevtools\n commands that interact with a Docker Host now take a \n--name\n flag that will allow you to specify name of the Docker Host. For all commands this name defaults to \ndev\n but you can configure this name if needed.  Also, if you dont want to specify the Docker Host name on every command you can specify the \nDEVTOOLS_ACTIVE_MACHINE\n environment variable to be Docker Machine name of the VM you care to interact with.  This way you can set it once and forget about it.  Unless otherwise specified, the name defaults to \ndev\n for all commands.",
            "title": "Project Usage"
        },
        {
            "location": "/30_PROJECT_USAGE/#project-usage",
            "text": "",
            "title": "Project Usage"
        },
        {
            "location": "/30_PROJECT_USAGE/#watches",
            "text": "Often we need  watches  running inside of our containers. This could be for webpack, grunt, nodemon, etc.  One of the main challenges with the NFS mounts used in DevTools is that they do not forward filesystem notifications across the NFS mount and into containers, so we need to facilitate that.  There is a command  devtools watch [options]  path . Running this on your host will watch for changes and rsync notifications to files and directories under  path  into the Docker Machine VM (which will then provide filesystem notifications into the container). These are the options for  devtools watch   --machine  name  Optional: Specify a machine to send events. It will default to our  dev  machine  --ignorefile  file  Optional: Specify a file that contains patterns for directories/files to ignore.  Put one entry per line (blank lines and comments are allowed). If not specified it will look for a file named  .devtools-watch-ignore  in the working directory and all parent directories.",
            "title": "Watches"
        },
        {
            "location": "/30_PROJECT_USAGE/#what-is-the-build-container",
            "text": "Part of DevTools is a  devtools-build  image.  The idea of the build container is that it will have installed nearly all of the tools you'd need to work on a project and the proper versions so that they work well together.  Everything from drush to gem to npm to composer as well as grunt, bower, yeoman, etc. Providing these tools in a container means that you'll never have to worry about having the right tools installed on your laptop or integration environment to get your job done.",
            "title": "What is the Build container"
        },
        {
            "location": "/30_PROJECT_USAGE/#how-and-why-to-use-the-build-container",
            "text": "The example Drupal project contains a  build.yml  Docker Compose file that shows a variety of ways to use the container that we will highlight below.",
            "title": "How and why to use the build container"
        },
        {
            "location": "/30_PROJECT_USAGE/#getting-a-shell-for-buildtooling-operations",
            "text": "Getting a shell into a build container to execute any operations is the simplest approach. You simply want to get access to the  cli  container we defined in the compose file.  The command  docker-compose -f build.yml run cli  will start an instance of the  phase2/devtools-build  image and run a bash shell for you.  From there you are free to use  drush ,  grunt  or whatever your little heart desires.",
            "title": "Getting a shell for build/tooling operations"
        },
        {
            "location": "/30_PROJECT_USAGE/#running-commands-but-not-from-a-dedicated-shell",
            "text": "Another concept in the Docker world is starting a container to run a single command and allowing the container stop when the command is completed.  This is great if you run commands infrequently, or don't want to have another container constantly running.  Running your commands on containers in this fashion is also well suited for commands that don't generate any files on the filesystem or if they do, they write those files on to volumes mounted into the container.  The  drush  container defined in the example  build.yml  file is a container designed specifically to run drush in a single working directory taking only the commands as arguments.  This approach allows us to provide a quick and easy mechanism for running any drush command, such as  sqlc ,  cache-rebuild , and others, in your Drupal site quick and easily.  There are also other examples of a  grunt  command container similar to  drush  and an even more specific command container around running a single command,  drush make  to build the site from a make/dependency file.",
            "title": "Running commands, but not from a dedicated shell"
        },
        {
            "location": "/30_PROJECT_USAGE/#forwardimport-your-ssh-key-into-the-build-container-to-clone-private-repos",
            "text": "Certain containers like jenkins and devtools-build may need your private key. This is supported by importing your private key into the container via a volume mount.    To get your private key into the build container, volume mount your key into the container at  /root/.ssh/devtools.key  and it will be processed accordingly.  ~/.ssh/id_rsa:/root/.ssh/devtools.key",
            "title": "Forward/Import your SSH Key into the build container to clone private repos"
        },
        {
            "location": "/30_PROJECT_USAGE/#multiple-docker-machines-using-other-docker-machines",
            "text": "There are special cases in which you may want to have multiple Docker Hosts running. For example to test the performance differences between VirtualBox and xhyve.  For these cases, all  devtools  commands that interact with a Docker Host now take a  --name  flag that will allow you to specify name of the Docker Host. For all commands this name defaults to  dev  but you can configure this name if needed.  Also, if you dont want to specify the Docker Host name on every command you can specify the  DEVTOOLS_ACTIVE_MACHINE  environment variable to be Docker Machine name of the VM you care to interact with.  This way you can set it once and forget about it.  Unless otherwise specified, the name defaults to  dev  for all commands.",
            "title": "Multiple Docker Machines / Using other Docker Machines"
        },
        {
            "location": "/XDEBUG/",
            "text": "Getting XDebug setup locally with DevTools\n\n\nGetting \nXDebug\n set up can be a bit challenging \nonly\n because you might not know the locations of files. This guide will walk you through getting setup and will hopefully remove any rabbit-hole fears of using XDebug on your next project!\n\n\nSteps\n\n\n1. Make sure DevTools is up to date.\n\n\nThis will not impact XDebug configuration but it's always a good thing to make sure your tools are up to date! Take this opportunity to do a quick check before going on your way to integrating XDebug =) \n\n\nbrew info devtools\n\n\n\n\nYou should hopefully see:\n\n\nphase2/devtools/devtools: stable 0.2.2\nContainerized platform environment for projects. See https://phase2.github.io/devtools for documentation.\nhttps://phase2.github.com/devtools\n/usr/local/Cellar/devtools/0.1.3 (3 files, 4.3M)\n  Built from source\n/usr/local/Cellar/devtools/0.2.2 (4 files, 4.8M) *\n  Built from source\nFrom: https://github.com/phase2/homebrew-devtools/blob/master/Formula/devtools.rb\n\n\n\n\nIf your output doesn't match do:\n\n\nbrew update\nbrew upgrade devtools\n\n\n\n\n2. Make sure that you have the correct versions of docker, docker-machine, docker-compose\n\n\nCurrently DevTools has a requirement of specific versions of Docker, Docker Machine, and Docker Compose. These versions aren't the latest versions of these packages. If for whatever reason, you were using another version of any of these items, make sure that you run:\n\n\ndevtools doctor\n\n// You need these versions for DevTools:\n[INFO] Docker compatible version 1.9.1 was found\n[INFO] Machine compatible version 0.5.4 was found\n[INFO] Compose compatible version 1.5.2 was found\n\n\n\n\nAlso if you have multiple versions installed, doing \nbrew info docker-compose\n will list the versions you have installed. The one with the \n\"*\"\n will be the version that is active.\n\n\nIf you need to switch versions, use the \nbrew switch\n command and run any additional commands like \nbrew unlink ...\n. (The \nswitch\n command will provide next command steps if you need to link or unlink any formulae). \n\n\nExample:\n\n\nbrew switch docker 1.9.1\n\n\n\n\n3. Make sure your containers are up to date!\n\n\nNow it may have been a while since you last updated your containers. Unfortunately, there's no way to subscribe to Docker Hub image updates at this time. So this is something that you might want to do occasionally, like at the beginning of a sprint :D \n\n\nThis is an important step to take to ensure that you have the latest changes in order to properly finish the XDebug setup.\n\n\n// Stop your containers in case they are running.\ndocker-compose stop\n\n// Pull the latest changes.\ndocker-compose pull\ndocker-compose -f build.yml pull\n\n// Remove your old containers to make sure you're using the latest images.\ndocker-compose rm\n\n// Re-create your containers based on the freshly updated images.\ndocker-compose up -d\n\n\n\n\nThis is shorthand for something like:\n\n\ndocker pull phase2/devtools-build\n\n\n\n\n4. How is XDebug configuration managed with DevTools?\n\n\nXDebug setup is controlled by template (\n.tmpl\n) files. \n\n\nThe XDebug template file\n has the following:\n\n\n; Enable xdebug extension module\n{{ $xdebug := getenv \nPHP_XDEBUG\n }}\n{{ if eq $xdebug \ntrue\n }}\nzend_extension=xdebug.so\n{{ end }}\n\nxdebug.coverage_enable=0\nxdebug.default_enable=1\n\nxdebug.remote_enable=1\nxdebug.remote_connect_back=1\nxdebug.remote_host=localhost // \n Note: This is ignored because xdebug.remote_connect_back is enabled.\nxdebug.remote_port=9000\nxdebug.remote_handler=dbgp\nxdebug.remote_log=/tmp/xdebug.log\nxdebug.remote_autostart=true\n\nxdebug.idekey=\nDEVTOOLS\n\n\n; Drupal 8 requires this be set to 256.\nxdebug.max_nesting_level=256\n\n; see http://xdebug.org/docs/all_settings\n\n\n\n\nIt is located on the www container @ \n/etc/confd/templates/xdebug.ini.tmpl\n. To view the template file, do:\n\n\ndocker ps // Get the list of your running containers\n\n// You should see something like this\n\nCONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                            NAMES\n9616c845b27d        phase2/apache-php:php70     \n/init\n                  56 minutes ago      Up 56 minutes       80/tcp                           your_site_local_www\n\n// Grab the NAME for the container using the \nphase2/apache-php:php70\n image. In this case it's \nyour_site_local_www\n \n\n// Get a bash shell for the www container:\ndocker exec -it your_site_local_www bash\n\n// Your bash shell on the www container:\n\n [root@9616c845b27d /]#\n\n// Checkout the xdebug template:\n\n [root@9616c845b27d /]# cat /etc/confd/templates/xdebug.ini.tmpl\n\n// Checkout the xdebug.ini file (using the template):\n\n [root@9616c845b27d /]# cat /etc/opt/remi/php70/php.d/15-xdebug.ini\n\n\n\n\nThe template file contents get loaded into this 15-xdebug.ini file because of this \n.toml\n file\n:\n\n\n[template]\nsrc = \nxdebug.ini.tmpl\n\ndest = \n/etc/opt/remi/php70/php.d/15-xdebug.ini\n\nuid = 0\ngid = 0\nmode = \n0644\n\nkeys = []\n\n\n\n\nNotice the src and dest keys in this file.\n\n\n5. Overridding the default template from DevTools\n\n\nSometimes you need something different, and that's OK! So the way to go about this is to create your \n.tmpl\n file and overwrite the one that is setup on the www container by default.\n\n\nYou can accomplish this using a good 'ole volume mount:\n\n\nIn your project directory, create a new folder to hold your custom template file. A nice way to organize your docker customizations is by putting them in a directory called: \nenv/local\n:\n\n\nmkdir -p env/local\n\n\n\n\nCreate a file named \nxdebug.ini.tmpl\n and place your customizations. Note: This file overwrites the original template file completely, so if there are lines you want to keep from the original one, be sure to copy them over to this file.\n\n\nIn your \ndocker-compose.yml\n file, add the following to the volumes array of your www container:\n\n\n./env/local/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl\n\n\n\n\nAlso, make sure you have the \nPHP_XDEBUG\n key set to \n\"true\"\n.\n\n\nExample:\n\n\nwww:\n  container_name: your_site_local_www\n  image: phase2/apache-php:php70\n  environment:\n    DNSDOCK_NAME: www\n    DNSDOCK_IMAGE: your-site\n    DOCROOT: /var/www/build/html\n    PHP_XDEBUG: \ntrue\n  // \n Make sure you have this line!\n  links:\n    - db\n  volumes:\n    - .:/var/www/\n    - ./env/local/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl  //  \n ADD THIS LINE\n    - /data/your_site_local/files:/var/www/build/html/sites/default/files\n\n\n\n\nThis tells docker to use your custom template file and place it in the \n/etc/confd/templates/xdebug.ini.tmpl\n location on the www container, effectively overwriting it.\n\n\nIf you make adjustments to your template file while your www container is running, you will have to restart your containers to apply your changes\n\n\ndocker-compose restart\n\n\n\n\nor \n\n\ndocker-compose restart www\n\n\n\n\n6. Final Steps - Let your IDE know about XDebug on your www container.\n\n\nDepending on the IDE you use, the final steps for integrating your XDebug setup with your local environment and your IDE will differ. Here's some steps on how to accomplish this using PHPStorm:\n\n\n1. First of all, you'll to add some settings for your project. Click on the wrench icon in the toolbar:\n\n\n\n\nYou can also get to the project settings by going to: PHPStorm \n Preferences (OSX) or File \n Settings (Windows, Linux).\n\n\n2. Adjust the PHP Project settings.\n\n\nMake sure you have the correct version of PHP selected:\n\n\n\n\n3. Adjust the Debug Project settings.\n\n\n\n\nMake sure that the XDebug Debug port matches the one in the xdebug template file.\n\n\nAccept external connections\n\n\n\n\n\n\n4. For the DBGp Proxy, just ensure that the port is the same.\n\n\nYou can leave the other settings blank.\n\n\n\n\n5. Adjust the Server Project Settings.\n\n\nCreate a new Server by clicking on the \"+\" button. Give your server a name and input the host.\n\n\nBe sure to add the docroot mappings. The example shown here is using the \nGrunt Drupal Tasks\n project structure. There are two mappings in this case. One for the docroot (\nbuild/html\n) and the other for the \nsrc\n directory so that breakpoints can be set in the custom modules in the \nsrc\n directory as well.\n\n\n\n\n5. Validate your debug settings.\n\n\nSelect the \"Web Server Debug Validation\" option from the \"Run\" menu option.\n\n\n\n\nThis will display a dialog window that allows you to validate your settings. Make sure that your \"Path to create validation script\" points to your project docroot and the url is your project url.\n\n\nIf all goes well, clicking the \"Validate\" button should give you something like this:\n\n\n\n\nClick the dialog 'x' (close) button to close this dialog window.\n\n\n6. Restart PHPStorm.\n\n\nIn order to ensure that all your settings are applying, you will need to restart PHPStorm.\n\n\n7. Make sure that you listen for connections!",
            "title": "Xdebug"
        },
        {
            "location": "/XDEBUG/#getting-xdebug-setup-locally-with-devtools",
            "text": "Getting  XDebug  set up can be a bit challenging  only  because you might not know the locations of files. This guide will walk you through getting setup and will hopefully remove any rabbit-hole fears of using XDebug on your next project!",
            "title": "Getting XDebug setup locally with DevTools"
        },
        {
            "location": "/XDEBUG/#steps",
            "text": "",
            "title": "Steps"
        },
        {
            "location": "/XDEBUG/#1-make-sure-devtools-is-up-to-date",
            "text": "This will not impact XDebug configuration but it's always a good thing to make sure your tools are up to date! Take this opportunity to do a quick check before going on your way to integrating XDebug =)   brew info devtools  You should hopefully see:  phase2/devtools/devtools: stable 0.2.2\nContainerized platform environment for projects. See https://phase2.github.io/devtools for documentation.\nhttps://phase2.github.com/devtools\n/usr/local/Cellar/devtools/0.1.3 (3 files, 4.3M)\n  Built from source\n/usr/local/Cellar/devtools/0.2.2 (4 files, 4.8M) *\n  Built from source\nFrom: https://github.com/phase2/homebrew-devtools/blob/master/Formula/devtools.rb  If your output doesn't match do:  brew update\nbrew upgrade devtools",
            "title": "1. Make sure DevTools is up to date."
        },
        {
            "location": "/XDEBUG/#2-make-sure-that-you-have-the-correct-versions-of-docker-docker-machine-docker-compose",
            "text": "Currently DevTools has a requirement of specific versions of Docker, Docker Machine, and Docker Compose. These versions aren't the latest versions of these packages. If for whatever reason, you were using another version of any of these items, make sure that you run:  devtools doctor\n\n// You need these versions for DevTools:\n[INFO] Docker compatible version 1.9.1 was found\n[INFO] Machine compatible version 0.5.4 was found\n[INFO] Compose compatible version 1.5.2 was found  Also if you have multiple versions installed, doing  brew info docker-compose  will list the versions you have installed. The one with the  \"*\"  will be the version that is active.  If you need to switch versions, use the  brew switch  command and run any additional commands like  brew unlink ... . (The  switch  command will provide next command steps if you need to link or unlink any formulae).   Example:  brew switch docker 1.9.1",
            "title": "2. Make sure that you have the correct versions of docker, docker-machine, docker-compose"
        },
        {
            "location": "/XDEBUG/#3-make-sure-your-containers-are-up-to-date",
            "text": "Now it may have been a while since you last updated your containers. Unfortunately, there's no way to subscribe to Docker Hub image updates at this time. So this is something that you might want to do occasionally, like at the beginning of a sprint :D   This is an important step to take to ensure that you have the latest changes in order to properly finish the XDebug setup.  // Stop your containers in case they are running.\ndocker-compose stop\n\n// Pull the latest changes.\ndocker-compose pull\ndocker-compose -f build.yml pull\n\n// Remove your old containers to make sure you're using the latest images.\ndocker-compose rm\n\n// Re-create your containers based on the freshly updated images.\ndocker-compose up -d  This is shorthand for something like:  docker pull phase2/devtools-build",
            "title": "3. Make sure your containers are up to date!"
        },
        {
            "location": "/XDEBUG/#4-how-is-xdebug-configuration-managed-with-devtools",
            "text": "XDebug setup is controlled by template ( .tmpl ) files.   The XDebug template file  has the following:  ; Enable xdebug extension module\n{{ $xdebug := getenv  PHP_XDEBUG  }}\n{{ if eq $xdebug  true  }}\nzend_extension=xdebug.so\n{{ end }}\n\nxdebug.coverage_enable=0\nxdebug.default_enable=1\n\nxdebug.remote_enable=1\nxdebug.remote_connect_back=1\nxdebug.remote_host=localhost //   Note: This is ignored because xdebug.remote_connect_back is enabled.\nxdebug.remote_port=9000\nxdebug.remote_handler=dbgp\nxdebug.remote_log=/tmp/xdebug.log\nxdebug.remote_autostart=true\n\nxdebug.idekey= DEVTOOLS \n\n; Drupal 8 requires this be set to 256.\nxdebug.max_nesting_level=256\n\n; see http://xdebug.org/docs/all_settings  It is located on the www container @  /etc/confd/templates/xdebug.ini.tmpl . To view the template file, do:  docker ps // Get the list of your running containers\n\n// You should see something like this \nCONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                            NAMES\n9616c845b27d        phase2/apache-php:php70      /init                   56 minutes ago      Up 56 minutes       80/tcp                           your_site_local_www\n\n// Grab the NAME for the container using the  phase2/apache-php:php70  image. In this case it's  your_site_local_www  \n\n// Get a bash shell for the www container:\ndocker exec -it your_site_local_www bash\n\n// Your bash shell on the www container:  [root@9616c845b27d /]#\n\n// Checkout the xdebug template:  [root@9616c845b27d /]# cat /etc/confd/templates/xdebug.ini.tmpl\n\n// Checkout the xdebug.ini file (using the template):  [root@9616c845b27d /]# cat /etc/opt/remi/php70/php.d/15-xdebug.ini  The template file contents get loaded into this 15-xdebug.ini file because of this  .toml  file :  [template]\nsrc =  xdebug.ini.tmpl \ndest =  /etc/opt/remi/php70/php.d/15-xdebug.ini \nuid = 0\ngid = 0\nmode =  0644 \nkeys = []  Notice the src and dest keys in this file.",
            "title": "4. How is XDebug configuration managed with DevTools?"
        },
        {
            "location": "/XDEBUG/#5-overridding-the-default-template-from-devtools",
            "text": "Sometimes you need something different, and that's OK! So the way to go about this is to create your  .tmpl  file and overwrite the one that is setup on the www container by default.  You can accomplish this using a good 'ole volume mount:  In your project directory, create a new folder to hold your custom template file. A nice way to organize your docker customizations is by putting them in a directory called:  env/local :  mkdir -p env/local  Create a file named  xdebug.ini.tmpl  and place your customizations. Note: This file overwrites the original template file completely, so if there are lines you want to keep from the original one, be sure to copy them over to this file.  In your  docker-compose.yml  file, add the following to the volumes array of your www container:  ./env/local/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl  Also, make sure you have the  PHP_XDEBUG  key set to  \"true\" .  Example:  www:\n  container_name: your_site_local_www\n  image: phase2/apache-php:php70\n  environment:\n    DNSDOCK_NAME: www\n    DNSDOCK_IMAGE: your-site\n    DOCROOT: /var/www/build/html\n    PHP_XDEBUG:  true   //   Make sure you have this line!\n  links:\n    - db\n  volumes:\n    - .:/var/www/\n    - ./env/local/xdebug.ini.tmpl:/etc/confd/templates/xdebug.ini.tmpl  //    ADD THIS LINE\n    - /data/your_site_local/files:/var/www/build/html/sites/default/files  This tells docker to use your custom template file and place it in the  /etc/confd/templates/xdebug.ini.tmpl  location on the www container, effectively overwriting it.  If you make adjustments to your template file while your www container is running, you will have to restart your containers to apply your changes  docker-compose restart  or   docker-compose restart www",
            "title": "5. Overridding the default template from DevTools"
        },
        {
            "location": "/XDEBUG/#6-final-steps-let-your-ide-know-about-xdebug-on-your-www-container",
            "text": "Depending on the IDE you use, the final steps for integrating your XDebug setup with your local environment and your IDE will differ. Here's some steps on how to accomplish this using PHPStorm:",
            "title": "6. Final Steps - Let your IDE know about XDebug on your www container."
        },
        {
            "location": "/XDEBUG/#1-first-of-all-youll-to-add-some-settings-for-your-project-click-on-the-wrench-icon-in-the-toolbar",
            "text": "You can also get to the project settings by going to: PHPStorm   Preferences (OSX) or File   Settings (Windows, Linux).",
            "title": "1. First of all, you'll to add some settings for your project. Click on the wrench icon in the toolbar:"
        },
        {
            "location": "/XDEBUG/#2-adjust-the-php-project-settings",
            "text": "Make sure you have the correct version of PHP selected:",
            "title": "2. Adjust the PHP Project settings."
        },
        {
            "location": "/XDEBUG/#3-adjust-the-debug-project-settings",
            "text": "Make sure that the XDebug Debug port matches the one in the xdebug template file.  Accept external connections",
            "title": "3. Adjust the Debug Project settings."
        },
        {
            "location": "/XDEBUG/#4-for-the-dbgp-proxy-just-ensure-that-the-port-is-the-same",
            "text": "You can leave the other settings blank.",
            "title": "4. For the DBGp Proxy, just ensure that the port is the same."
        },
        {
            "location": "/XDEBUG/#5-adjust-the-server-project-settings",
            "text": "Create a new Server by clicking on the \"+\" button. Give your server a name and input the host.  Be sure to add the docroot mappings. The example shown here is using the  Grunt Drupal Tasks  project structure. There are two mappings in this case. One for the docroot ( build/html ) and the other for the  src  directory so that breakpoints can be set in the custom modules in the  src  directory as well.",
            "title": "5. Adjust the Server Project Settings."
        },
        {
            "location": "/XDEBUG/#5-validate-your-debug-settings",
            "text": "Select the \"Web Server Debug Validation\" option from the \"Run\" menu option.   This will display a dialog window that allows you to validate your settings. Make sure that your \"Path to create validation script\" points to your project docroot and the url is your project url.  If all goes well, clicking the \"Validate\" button should give you something like this:   Click the dialog 'x' (close) button to close this dialog window.",
            "title": "5. Validate your debug settings."
        },
        {
            "location": "/XDEBUG/#6-restart-phpstorm",
            "text": "In order to ensure that all your settings are applying, you will need to restart PHPStorm.",
            "title": "6. Restart PHPStorm."
        },
        {
            "location": "/XDEBUG/#7-make-sure-that-you-listen-for-connections",
            "text": "",
            "title": "7. Make sure that you listen for connections!"
        },
        {
            "location": "/40_INTEGRATION/",
            "text": "Integration Environments\n\n\nFor integration and other instances the approach is to spin up a Jenkins docker container on one of \nci.p2devcloud.com\n or \nci2.p2devcloud.com\n which then runs a Jenkins instance containing all the jobs needed for your project. Details about how to create the Jenkins config, the job config and the jenkins.yml file used for launching the instance are described in the manual setup section below.\n\n\nYou can see a list of all integration sites currently running by going to \nhttp://index.ci.p2devcloud.com\n and \nhttp://index.ci2.p2devcloud.com\n\n\nHow to get an integration environment going\n\n\nThe good news is that if you have your dev environment running via docker-compose, it should be very straight-forward to pull up an integration environment.  Think of each environment you want to run as having it\u2019s own docker-compose file. See the \nsample integration file\n included in example/drupal8.\n\n\nIf you are using the \nPhase2 Yeoman generator\n (yo p2) to create your project, you will already have default Jenkins jobs created within your env/jenkins folder.\n\n\nFor a quick and easy start:\n\n\n\n\n\n\nMake a copy of docker-compose.yml and name it docker-compose.int.yml\n\n\n\n\n\n\nConfigure volumes\n\n\n\n\nBe sure to remove the line that is mounting your local code into the container\n\n\n\n\n\n\n\n\nConfigure your web container\n\n\n\n\n\n\nAdd an \nexpose\n section, and specify port \n\"80\"\n\n\n\n\nThis will broadcast the ports available to services like nginx-proxy\n\n\n\n\n\n\n\n\nIn the environment section, add a \nVIRTUAL_HOST\n variable. Put the hostname you want for your environment of the format \nname\n.ci.p2devcloud.com\n\n\n\n\n\n\n\n\n\n\nCreate your integration job\n\n\n\n\n\n\nCreate a job that will run every time code is committed to a particular branch (usually \ndevelop\n)\n\n\n\n\n\n\nThe script for that job should run the following commands\n\n\n\n\n\n\ndocker-compose build\n\n\n\n\n\n\ndocker-compose -f docker-compose.int.yml up -d\n\n\n\n\n\n\n\n\n\n\nAn example of this script can be seen here: \nhttp://build.p2devcloud.com/job/Fieldnotes%20Integration/configure\n\n\n\n\n\n\n\n\n\n\nInstead of creating new project tabs on http://build.p2devcloud.com, we are switching to project-specific Jenkins instances for integration. To create your own Jenkins integration server:\n\n\n\n\n\n\nGo to \nhttp://build.ci.p2devcloud.com/job/ci-start\n and run this job with the following parameters:\n\n\n\n\nYour project name (no spaces)\n\n\nThe git url for your repository\n\n\nThe branch to use\n\n\n\n\n\n\n\n\nThis will create your own Jenkins instance -- the url should appear here: \nhttp://index.ci.p2devcloud.com/\n\n\n\n\nYou can add/configure Jenkins plugins by adding a jenkins directory to your env directory. You can modify the config.xml files to your heart's content because the instance on our integration server is your very own configured Jenkin's instance. For an example of a env jenkins directory, checkout \njenkins/env\n.\n\n\n\n\nManually creating Jenkins configuration\n\n\nIf you are not using the Phase2 Yeoman generator, you'll need to create your Jenkins configuration manually before you can create your own Jenkins instance on the ci.p2devcloud.com site.\n\n\n\n\nCreate a folder in your project repository to hold the Jenkins configuration.  Typically this is \nenv/jenkins\n.\n\n\nCreate a \njenkins.xml\n file in the root directory of your project repository.  (\nSee jenkins.xml example\n). This is a docker-compose file that is used to create the docker container that will run Jenkins.\n\n\n\n\nCreate the main Jenkins config.xml file within your env/jenkins folder.  (\nSee config.xml example\n).  The lines that you need to edit for your project are:\n\n\n\n\nworkspaceDir\n/opt/development/YOUR-SERVER-NAME/jenkins/env/workspace/${ITEM_FULL_NAME}\n/workspaceDir\n\n\n\n\nThis defines the path to your workspace for each job.  The \n${ITEM_FULL_NAME}\n will be replaced with each specific job name.  So just change \nYOUR-SERVER-NAME\n to be the name of your project.\n\n\n\n\nYou can create \nlistView\n sections to define tabs across the top of your page to organize your jobs.  The \nincludeRegEx\n tag defines the job name pattern to group jobs into the specific listView tab.\n\n\n\n\n\n\n\n\nCreate any specific Jobs within your \nenv/jenkins/jobs\n folder.  Each job is its own folder containing the \nconfig.xml\n for the specific job.  If you don't create any jobs in your project repo you can still create them interactively once your Jenkins server is running.  However it's a good idea to save the config.xml for each job within your project repository in case you need to rebuild your Jenkins server.\n\n\n\n\nEdit the \nvolumes\n mounts in the main jenkins.xml docker-compose file.  Point to the main \nenv/jenkins/config.xml\n you created in #3, along with the Jobs folder you created in #4.  Also adjust the path for the main workspace folder that you defined in #3 (without the \nITEM_FULL_NAME\n).\n\n\nEdit the \nenvironment\n section of the \njenkins.xml\n docker-compose file for the \nDNSDOCK_IMAGE\n (\nPROJECT_NAME\n) and the \nVIRTUAL_HOST\n (full \nPROJECT_NAME.ci.p2devcloud.com\n or ci2)\n\n\nModify the \nconfig.xml\n volume mount within \njenkins.xml\n for your specific project\n\n\n\n\nMore advanced integration use cases\n\n\nThe above section highlights the most straight-forward integration implementation. There are often a collection of other things that are used when building a full featured CI environment.  We have not figured these all out, but will update this documentation as we formalize the recommended practices around such things as:\n\n\n\n\n\n\nReset to a known version of the database\n\n\n\n\n\n\nUse a version of a production database for each integration build\n\n\n\n\n\n\nBuild a production artifact\n\n\n\n\n\n\nCreate a feature branch environment for review\n\n\n\n\n\n\nCreate a content environment for migration review and manual content migrations\n\n\n\n\n\n\nProper cleanup and removing of an integration environment",
            "title": "Integration"
        },
        {
            "location": "/40_INTEGRATION/#integration-environments",
            "text": "For integration and other instances the approach is to spin up a Jenkins docker container on one of  ci.p2devcloud.com  or  ci2.p2devcloud.com  which then runs a Jenkins instance containing all the jobs needed for your project. Details about how to create the Jenkins config, the job config and the jenkins.yml file used for launching the instance are described in the manual setup section below.  You can see a list of all integration sites currently running by going to  http://index.ci.p2devcloud.com  and  http://index.ci2.p2devcloud.com",
            "title": "Integration Environments"
        },
        {
            "location": "/40_INTEGRATION/#how-to-get-an-integration-environment-going",
            "text": "The good news is that if you have your dev environment running via docker-compose, it should be very straight-forward to pull up an integration environment.  Think of each environment you want to run as having it\u2019s own docker-compose file. See the  sample integration file  included in example/drupal8.  If you are using the  Phase2 Yeoman generator  (yo p2) to create your project, you will already have default Jenkins jobs created within your env/jenkins folder.  For a quick and easy start:    Make a copy of docker-compose.yml and name it docker-compose.int.yml    Configure volumes   Be sure to remove the line that is mounting your local code into the container     Configure your web container    Add an  expose  section, and specify port  \"80\"   This will broadcast the ports available to services like nginx-proxy     In the environment section, add a  VIRTUAL_HOST  variable. Put the hostname you want for your environment of the format  name .ci.p2devcloud.com      Create your integration job    Create a job that will run every time code is committed to a particular branch (usually  develop )    The script for that job should run the following commands    docker-compose build    docker-compose -f docker-compose.int.yml up -d      An example of this script can be seen here:  http://build.p2devcloud.com/job/Fieldnotes%20Integration/configure      Instead of creating new project tabs on http://build.p2devcloud.com, we are switching to project-specific Jenkins instances for integration. To create your own Jenkins integration server:    Go to  http://build.ci.p2devcloud.com/job/ci-start  and run this job with the following parameters:   Your project name (no spaces)  The git url for your repository  The branch to use     This will create your own Jenkins instance -- the url should appear here:  http://index.ci.p2devcloud.com/   You can add/configure Jenkins plugins by adding a jenkins directory to your env directory. You can modify the config.xml files to your heart's content because the instance on our integration server is your very own configured Jenkin's instance. For an example of a env jenkins directory, checkout  jenkins/env .",
            "title": "How to get an integration environment going"
        },
        {
            "location": "/40_INTEGRATION/#manually-creating-jenkins-configuration",
            "text": "If you are not using the Phase2 Yeoman generator, you'll need to create your Jenkins configuration manually before you can create your own Jenkins instance on the ci.p2devcloud.com site.   Create a folder in your project repository to hold the Jenkins configuration.  Typically this is  env/jenkins .  Create a  jenkins.xml  file in the root directory of your project repository.  ( See jenkins.xml example ). This is a docker-compose file that is used to create the docker container that will run Jenkins.   Create the main Jenkins config.xml file within your env/jenkins folder.  ( See config.xml example ).  The lines that you need to edit for your project are:   workspaceDir /opt/development/YOUR-SERVER-NAME/jenkins/env/workspace/${ITEM_FULL_NAME} /workspaceDir   This defines the path to your workspace for each job.  The  ${ITEM_FULL_NAME}  will be replaced with each specific job name.  So just change  YOUR-SERVER-NAME  to be the name of your project.   You can create  listView  sections to define tabs across the top of your page to organize your jobs.  The  includeRegEx  tag defines the job name pattern to group jobs into the specific listView tab.     Create any specific Jobs within your  env/jenkins/jobs  folder.  Each job is its own folder containing the  config.xml  for the specific job.  If you don't create any jobs in your project repo you can still create them interactively once your Jenkins server is running.  However it's a good idea to save the config.xml for each job within your project repository in case you need to rebuild your Jenkins server.   Edit the  volumes  mounts in the main jenkins.xml docker-compose file.  Point to the main  env/jenkins/config.xml  you created in #3, along with the Jobs folder you created in #4.  Also adjust the path for the main workspace folder that you defined in #3 (without the  ITEM_FULL_NAME ).  Edit the  environment  section of the  jenkins.xml  docker-compose file for the  DNSDOCK_IMAGE  ( PROJECT_NAME ) and the  VIRTUAL_HOST  (full  PROJECT_NAME.ci.p2devcloud.com  or ci2)  Modify the  config.xml  volume mount within  jenkins.xml  for your specific project",
            "title": "Manually creating Jenkins configuration"
        },
        {
            "location": "/40_INTEGRATION/#more-advanced-integration-use-cases",
            "text": "The above section highlights the most straight-forward integration implementation. There are often a collection of other things that are used when building a full featured CI environment.  We have not figured these all out, but will update this documentation as we formalize the recommended practices around such things as:    Reset to a known version of the database    Use a version of a production database for each integration build    Build a production artifact    Create a feature branch environment for review    Create a content environment for migration review and manual content migrations    Proper cleanup and removing of an integration environment",
            "title": "More advanced integration use cases"
        },
        {
            "location": "/50_TROUBLESHOOTING/",
            "text": "Troubleshooting\n\n\nSee the following sections for common problems and ways to solve them.\n\n\nRun doctor\n\n\nRun \ndevtools doctor\n to determine if your environment is set to run DevTools.\n\n\nEnsure the environment is setup correctly\n\n\nIt can be useful to ensure everything is in a clean state. The following should ensure that\n\n\n\n\ndevtools stop\n stops the docker machine and cleans up networking\n\n\neval \"$(devtools config)\"\n clears environmental variables docker uses to communicate with the docker host\n\n\ndevtools start\n starts the docker machine\n\n\neval \"$(devtools config)\"\n sets environmental variables docker uses to communicate with the docker host\n\n\n\n\nEnsure your images are up to date\n\n\nFrom time to time images are updated to fix bugs or add functionality. You won't automatically receive these updates but you can fetch them when you hear new ones are available.\n\n\ndocker pull imagename\n can be used if you want to update a specific image. For example, if you wanted to make sure you had the latest dnsdock you'd run \ndocker pull phase2/dnsdock\n.\n\n\ndocker-compose pull\n can be used within a project directory to make sure you've got the latest version of all images in the docker-compose.yml file.\n\n\nConfigure Your Shell\n\n\nIf you do not have any containers listed when running \ndocker ps\n or you get an error message like:\n\n\nGet http:///var/run/docker.sock/v1.20/containers/json: dial unix /var/run/docker.sock: no such file or directory.\n\n* Are you trying to connect to a TLS-enabled daemon without TLS?\n\n* Is your docker daemon up and running?\n\n\n\nOr an error message like:\n\n\nCouldn't connect to Docker daemon - you might need to run `boot2docker up`.\n\n\n\nMake sure your shell has the necessary environment variables by running:\n\n\neval \"$(devtools config)\"\n\n\nReset everything\n\n\nIf a problem continue to persists and the Docker Host is non-responsive, you may need to resort to the nuclear option of blowing everything away and starting over. Note this is a \nnuclear option\n as even your persistent data area will be removed if you don't back it up. If you have any data that needs to be maintained be sure to get a copy of it off of your VM first with the scripts provided.\n\n\nTo wipe everything out and start over\n\n\n\n\n\n\nFirst backup your existing data (if desired) by running \ndevtools data-backup\n. This will sync your entire \n/data\n directory to your host machine.\n\n\n\n\n\n\nThen you can run \ndevtools remove\n This removes the broken Docker Host and it\u2019s state, making way for a clean start.\n\n\n\n\n\n\nNext you can rebuild everything by running \ndevtools start\n. This will create you new Docker Host.\n\n\n\n\n\n\nIf you wish to restore the \n/data\n directory that you previously backed up, then run \ndevtools data-restore\n\n\n\n\n\n\nFiles Not Found\n\n\nIf you get messages about files not being found in the container that should be shared from your host computer, check the following:\n\n\n\n\n\n\nIs the project checked out under the \n/Users\n folder? Only files under the \n/Users\n folder are shared into the Docker Host (and thus containers) by default.\n\n\n\n\n\n\nDoes the \ndocker-compose.yml\n file have a volume mount set up that contains the missing files?\n\n\n\n\n\n\nGet shell in the Docker container via \ndocker exec -it \ncontainer name\n /bin/bash\n and check if the files are shared in the wrong place.\n\n\n\n\n\n\nGet shell in the Docker Machine with \ndocker-machine ssh dev\n and check if you find the files under /Users.\n\n\n\n\n\n\nLog in to Docker Hub\n\n\nIf you encounter the following error about the Docker image not being found when starting a project, it may indicate that your Docker client is not logged into a required private Docker Hub repository:\n\n\nPulling repository phase2/mariadb\n\nError: image phase2/mariadb:latest not found\n\n\n\nTo solve this, run \ndocker login\n and provide the relevant credentials.\n\n\nDocker client and server version incompatibilities\n\n\nIf you see an error similar to this:\n\n\nError response from daemon: client is newer than server (client API version: 1.20, server API version: 1.19)\n\n\n\nYou likely need to upgrade your Docker Machine ISO. Do that with:\n\n\n`devtools upgrade`\n\n\n\nHowever, please check in #devtools-support to ensure that upgrading your Docker Machine is the right course of action.\n\n\nNetwork timed out and can't pull container image\n\n\nExample:\n\n\nPulling cache (phase2/memcache:latest)...\nPulling repository docker.io/phase2/memcache\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/phase2/memcache/images. You may want to check your internet connection or if you are behind a proxy.\n\n\n\n\nTry restarting docker-machine: \ndevtools restart\n\n\nUpstream tracking issue:\n \ndocker/machine #1857\n\n\nStarted machines may have a new IP address\n\n\nExample:\n\n\nStarted machines may have new IP addresses. You may need to re-run the `docker-machine env` command.\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 1 of 10.\n...\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 10 of 10.\n[ERROR] Docker daemon failed to start!\n\n\n\n\nThe Docker VM (probably called dev) has it's IP changed. The generated TLS Certs are no longer valid and must be regenerated.\n\n\nPossible causes or relations/patterns:\n\n\n\n\nAnother VM was started in VirtualBox.\n\n\nMachine went to sleep and somehow caused issues with the running VM.\n\n\n\n\nFix:\n\n\nTry running: \ndocker-machine env\n\n\nIf that does not work, you should be able to start the VM directly through docker-machine: \ndocker-machine start dev\n\n\nNext, check the IP / TLS status by running: \ndocker-machine ls\n\n\nThe output will likely report something akin to:\n\n\ndev       -        virtualbox   Running   tcp://192.168.99.100:2376 Unknown\nUnable to query docker version: Get https://192.168.99.100:2376/v1.15/version: x509: certificate is valid for 192.168.99.101, not 192.168.99.100\n\n\n\n\nNow, regenerate the TLS Certs: \ndocker-machine regenerate-certs dev -f\n\nDevtools should now be able to start. Don't forget to run `eval \"$(devtools config)\" after.\n\n\nContainers Started but Service Not Available\n\n\nDocker-Machine is running, the project's containers are up, and command-line operations work fine. Why can't you view the site in your web browser?\n\n\nDNS Services\n\n\nThe DNS services that DevTools spins up may not be working. Run \ndocker ps\n and see that you have a dnsdock and dnsmasq container.\n\n\nIf those services are not running, try \ndevtools dns\n to bring them up, or a full \ndevtools restart\n if that does not work.\n\n\ndevtools dns-records\n is also useful to see what containers have registered names.\n\n\nDNS Configuration\n\n\nIt is also possible that the DNS services are running for your environment, but somehow the configuration is wrong. Run \ndevtools dns-records\n and make sure your project has an entry. If not, you may need another restart, or perhaps you are missing \nDNSDOCK_NAME\n and \nDNSDOCK_IMAGE\n environment variable entries in your docker-compose.yml manifest.\n\n\nSlow-starting Services\n\n\nSome services, such as Apache Solr or Varnish, can take longer to start up than Apache and PHP-FPM. As a result you might load the browser so fast that not all services are available, which in the case of a proxy may prevent the page from loading at all. Wait a short time and try reloading the page.\n\n\nFailed Health Checks\n\n\nSome services such as Varnish depend on others to operate, and have built-in health checks to verify the other service is operating.\n\n\nIf such a health check fails, there could be two problems:\n\n\n\n\nThe internal DNS routing between Docker containers is broken. Make sure the\nconfiguration of your services is correct.\n\n\nThe dependency (e.g., Apache behing Varnish) is not yet up and running when Varnish performs its checks.\n\n\n\n\nIn either case, you can often repair the problem by performing a clean restart of the broken service.\n\n\ndocker-compose stop proxy\ndocker-compose rm -f proxy\ndocker-compose up -d proxy\n\n\n\n\nYour other services should already be up and functional when this is done, so the health check will not fail on account of (2).\n\n\n\n\nChecking on Varnish Health\n\n\nIf you suspect Varnish may be failing, run \ndocker exec -it [VARNISH_CONTAINER] varnishlog\n and scan for VCL compilation errors.\n\n\n\n\nService Became Non-Responsive\n\n\nSometimes a service locks up. Apache stops serving results, Solr stops indexing or responding to search queries. These things happen on servers all the time. It may even happen more often on Docker, especially since we are now using more \"infrastructure\" in our local environments.\n\n\nDocker is meant to easily sandbox these problems from the rest of your machine, and to easily resolve these problems by allowing you to dump the problem and start over fresh very easily.\n\n\nHard reset on a service (as describe above), is very much like a power cycle:\n\n\ndocker-compose stop [BROKEN_SERVICE]\ndocker-compose rm -f [BROKEN_SERVICE]\ndocker-compose up -d [BROKEN_SERVICE]\n\n\n\n\nSometimes data for a service is volume mounted from outside the container. This persistence is good when the data is healthy, but can be really bad if the data is part of the problem (e.g., broken lockfiles).\n\n\ndocker-machine ssh [MACHINE_NAME]\nrm -Rf /data/[PROJECT]/[DIRECTORY_FOR_SERVICE]\n\n\n\n\nRemember that your service may have configuration or data in another service, you may need to perform this operation against multilpe containers (e.g., Solr)\n\n\nNFS Conflicts with other Environments\n\n\nRunning the Devtools VM in conjunction with other development environments (such as Vagrant) can sometimes cause conflicts with volume mounts. This is due to the fact that the Devtools VM mounts the entirety of \n/Users\n into the VM on OS X. Additional NFS mounts from other environments that target subdirectories of \n/Users\n will fail.\n\n\nThe easiest workaround is to keep projects that use non-Devtools environments like Vagrant in a directory \noutside\n of \n/Users\n, such as \n/opt\n. Alternatively, you can run a single VM at a time and manually clear out \n/etc/exports\n prior to switching environments/projects.\n\n\nMigrating Vagrant boxes outside of /Users:\n\n\nIf you'd like to move your vagrant boxes outside of your home directory, perform the following steps:\n\n\n1) Choose a destination folder.  We'll be using /opt/vms for this example. Insure the destination has enough free space. Typically this is not a problem because our Macs are one single partition.\n\n\n2) Make the new directory, and ensure your userid owns it:  \nsudo mkdir /opt/vms; sudo chown -R userid:userid /opt/vms\n\n\n3) Add \nexport VAGRANT_HOME=/opt/vms\n to ~/.bash_profile\n\n\n4) Move your vagrant folders over to /opt/vms.\n\n\n5) edit /etc/exports, updating any vagrant mount point to use the new location.  (example: /Users/userid/vagrant/projectx/cms)\n\n\n6) While a reboot isn't neccesary, it'll help to make sure nothing is running and using the old mount points.\n\n\n7) cd into your new vagrant directory, and do a vagrant up.",
            "title": "Troubleshooting"
        },
        {
            "location": "/50_TROUBLESHOOTING/#troubleshooting",
            "text": "See the following sections for common problems and ways to solve them.",
            "title": "Troubleshooting"
        },
        {
            "location": "/50_TROUBLESHOOTING/#run-doctor",
            "text": "Run  devtools doctor  to determine if your environment is set to run DevTools.",
            "title": "Run doctor"
        },
        {
            "location": "/50_TROUBLESHOOTING/#ensure-the-environment-is-setup-correctly",
            "text": "It can be useful to ensure everything is in a clean state. The following should ensure that   devtools stop  stops the docker machine and cleans up networking  eval \"$(devtools config)\"  clears environmental variables docker uses to communicate with the docker host  devtools start  starts the docker machine  eval \"$(devtools config)\"  sets environmental variables docker uses to communicate with the docker host",
            "title": "Ensure the environment is setup correctly"
        },
        {
            "location": "/50_TROUBLESHOOTING/#ensure-your-images-are-up-to-date",
            "text": "From time to time images are updated to fix bugs or add functionality. You won't automatically receive these updates but you can fetch them when you hear new ones are available.  docker pull imagename  can be used if you want to update a specific image. For example, if you wanted to make sure you had the latest dnsdock you'd run  docker pull phase2/dnsdock .  docker-compose pull  can be used within a project directory to make sure you've got the latest version of all images in the docker-compose.yml file.",
            "title": "Ensure your images are up to date"
        },
        {
            "location": "/50_TROUBLESHOOTING/#configure-your-shell",
            "text": "If you do not have any containers listed when running  docker ps  or you get an error message like:  Get http:///var/run/docker.sock/v1.20/containers/json: dial unix /var/run/docker.sock: no such file or directory.\n\n* Are you trying to connect to a TLS-enabled daemon without TLS?\n\n* Is your docker daemon up and running?  Or an error message like:  Couldn't connect to Docker daemon - you might need to run `boot2docker up`.  Make sure your shell has the necessary environment variables by running:  eval \"$(devtools config)\"",
            "title": "Configure Your Shell"
        },
        {
            "location": "/50_TROUBLESHOOTING/#reset-everything",
            "text": "If a problem continue to persists and the Docker Host is non-responsive, you may need to resort to the nuclear option of blowing everything away and starting over. Note this is a  nuclear option  as even your persistent data area will be removed if you don't back it up. If you have any data that needs to be maintained be sure to get a copy of it off of your VM first with the scripts provided.  To wipe everything out and start over    First backup your existing data (if desired) by running  devtools data-backup . This will sync your entire  /data  directory to your host machine.    Then you can run  devtools remove  This removes the broken Docker Host and it\u2019s state, making way for a clean start.    Next you can rebuild everything by running  devtools start . This will create you new Docker Host.    If you wish to restore the  /data  directory that you previously backed up, then run  devtools data-restore",
            "title": "Reset everything"
        },
        {
            "location": "/50_TROUBLESHOOTING/#files-not-found",
            "text": "If you get messages about files not being found in the container that should be shared from your host computer, check the following:    Is the project checked out under the  /Users  folder? Only files under the  /Users  folder are shared into the Docker Host (and thus containers) by default.    Does the  docker-compose.yml  file have a volume mount set up that contains the missing files?    Get shell in the Docker container via  docker exec -it  container name  /bin/bash  and check if the files are shared in the wrong place.    Get shell in the Docker Machine with  docker-machine ssh dev  and check if you find the files under /Users.",
            "title": "Files Not Found"
        },
        {
            "location": "/50_TROUBLESHOOTING/#log-in-to-docker-hub",
            "text": "If you encounter the following error about the Docker image not being found when starting a project, it may indicate that your Docker client is not logged into a required private Docker Hub repository:  Pulling repository phase2/mariadb\n\nError: image phase2/mariadb:latest not found  To solve this, run  docker login  and provide the relevant credentials.",
            "title": "Log in to Docker Hub"
        },
        {
            "location": "/50_TROUBLESHOOTING/#docker-client-and-server-version-incompatibilities",
            "text": "If you see an error similar to this:  Error response from daemon: client is newer than server (client API version: 1.20, server API version: 1.19)  You likely need to upgrade your Docker Machine ISO. Do that with:  `devtools upgrade`  However, please check in #devtools-support to ensure that upgrading your Docker Machine is the right course of action.",
            "title": "Docker client and server version incompatibilities"
        },
        {
            "location": "/50_TROUBLESHOOTING/#network-timed-out-and-cant-pull-container-image",
            "text": "Example:  Pulling cache (phase2/memcache:latest)...\nPulling repository docker.io/phase2/memcache\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/phase2/memcache/images. You may want to check your internet connection or if you are behind a proxy.  Try restarting docker-machine:  devtools restart  Upstream tracking issue:   docker/machine #1857",
            "title": "Network timed out and can't pull container image"
        },
        {
            "location": "/50_TROUBLESHOOTING/#started-machines-may-have-a-new-ip-address",
            "text": "Example:  Started machines may have new IP addresses. You may need to re-run the `docker-machine env` command.\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 1 of 10.\n...\n[WARN] Docker daemon not running! Trying again in 3 seconds.  Try 10 of 10.\n[ERROR] Docker daemon failed to start!  The Docker VM (probably called dev) has it's IP changed. The generated TLS Certs are no longer valid and must be regenerated.  Possible causes or relations/patterns:   Another VM was started in VirtualBox.  Machine went to sleep and somehow caused issues with the running VM.   Fix:  Try running:  docker-machine env  If that does not work, you should be able to start the VM directly through docker-machine:  docker-machine start dev  Next, check the IP / TLS status by running:  docker-machine ls  The output will likely report something akin to:  dev       -        virtualbox   Running   tcp://192.168.99.100:2376 Unknown\nUnable to query docker version: Get https://192.168.99.100:2376/v1.15/version: x509: certificate is valid for 192.168.99.101, not 192.168.99.100  Now, regenerate the TLS Certs:  docker-machine regenerate-certs dev -f \nDevtools should now be able to start. Don't forget to run `eval \"$(devtools config)\" after.",
            "title": "Started machines may have a new IP address"
        },
        {
            "location": "/50_TROUBLESHOOTING/#containers-started-but-service-not-available",
            "text": "Docker-Machine is running, the project's containers are up, and command-line operations work fine. Why can't you view the site in your web browser?",
            "title": "Containers Started but Service Not Available"
        },
        {
            "location": "/50_TROUBLESHOOTING/#dns-services",
            "text": "The DNS services that DevTools spins up may not be working. Run  docker ps  and see that you have a dnsdock and dnsmasq container.  If those services are not running, try  devtools dns  to bring them up, or a full  devtools restart  if that does not work.  devtools dns-records  is also useful to see what containers have registered names.",
            "title": "DNS Services"
        },
        {
            "location": "/50_TROUBLESHOOTING/#dns-configuration",
            "text": "It is also possible that the DNS services are running for your environment, but somehow the configuration is wrong. Run  devtools dns-records  and make sure your project has an entry. If not, you may need another restart, or perhaps you are missing  DNSDOCK_NAME  and  DNSDOCK_IMAGE  environment variable entries in your docker-compose.yml manifest.",
            "title": "DNS Configuration"
        },
        {
            "location": "/50_TROUBLESHOOTING/#slow-starting-services",
            "text": "Some services, such as Apache Solr or Varnish, can take longer to start up than Apache and PHP-FPM. As a result you might load the browser so fast that not all services are available, which in the case of a proxy may prevent the page from loading at all. Wait a short time and try reloading the page.",
            "title": "Slow-starting Services"
        },
        {
            "location": "/50_TROUBLESHOOTING/#failed-health-checks",
            "text": "Some services such as Varnish depend on others to operate, and have built-in health checks to verify the other service is operating.  If such a health check fails, there could be two problems:   The internal DNS routing between Docker containers is broken. Make sure the\nconfiguration of your services is correct.  The dependency (e.g., Apache behing Varnish) is not yet up and running when Varnish performs its checks.   In either case, you can often repair the problem by performing a clean restart of the broken service.  docker-compose stop proxy\ndocker-compose rm -f proxy\ndocker-compose up -d proxy  Your other services should already be up and functional when this is done, so the health check will not fail on account of (2).   Checking on Varnish Health  If you suspect Varnish may be failing, run  docker exec -it [VARNISH_CONTAINER] varnishlog  and scan for VCL compilation errors.",
            "title": "Failed Health Checks"
        },
        {
            "location": "/50_TROUBLESHOOTING/#service-became-non-responsive",
            "text": "Sometimes a service locks up. Apache stops serving results, Solr stops indexing or responding to search queries. These things happen on servers all the time. It may even happen more often on Docker, especially since we are now using more \"infrastructure\" in our local environments.  Docker is meant to easily sandbox these problems from the rest of your machine, and to easily resolve these problems by allowing you to dump the problem and start over fresh very easily.  Hard reset on a service (as describe above), is very much like a power cycle:  docker-compose stop [BROKEN_SERVICE]\ndocker-compose rm -f [BROKEN_SERVICE]\ndocker-compose up -d [BROKEN_SERVICE]  Sometimes data for a service is volume mounted from outside the container. This persistence is good when the data is healthy, but can be really bad if the data is part of the problem (e.g., broken lockfiles).  docker-machine ssh [MACHINE_NAME]\nrm -Rf /data/[PROJECT]/[DIRECTORY_FOR_SERVICE]  Remember that your service may have configuration or data in another service, you may need to perform this operation against multilpe containers (e.g., Solr)",
            "title": "Service Became Non-Responsive"
        },
        {
            "location": "/50_TROUBLESHOOTING/#nfs-conflicts-with-other-environments",
            "text": "Running the Devtools VM in conjunction with other development environments (such as Vagrant) can sometimes cause conflicts with volume mounts. This is due to the fact that the Devtools VM mounts the entirety of  /Users  into the VM on OS X. Additional NFS mounts from other environments that target subdirectories of  /Users  will fail.  The easiest workaround is to keep projects that use non-Devtools environments like Vagrant in a directory  outside  of  /Users , such as  /opt . Alternatively, you can run a single VM at a time and manually clear out  /etc/exports  prior to switching environments/projects.",
            "title": "NFS Conflicts with other Environments"
        },
        {
            "location": "/50_TROUBLESHOOTING/#migrating-vagrant-boxes-outside-of-users",
            "text": "If you'd like to move your vagrant boxes outside of your home directory, perform the following steps:  1) Choose a destination folder.  We'll be using /opt/vms for this example. Insure the destination has enough free space. Typically this is not a problem because our Macs are one single partition.  2) Make the new directory, and ensure your userid owns it:   sudo mkdir /opt/vms; sudo chown -R userid:userid /opt/vms  3) Add  export VAGRANT_HOME=/opt/vms  to ~/.bash_profile  4) Move your vagrant folders over to /opt/vms.  5) edit /etc/exports, updating any vagrant mount point to use the new location.  (example: /Users/userid/vagrant/projectx/cms)  6) While a reboot isn't neccesary, it'll help to make sure nothing is running and using the old mount points.  7) cd into your new vagrant directory, and do a vagrant up.",
            "title": "Migrating Vagrant boxes outside of /Users:"
        },
        {
            "location": "/60_FAQ/",
            "text": "FAQs\n\n\nViewing logs from my container service(s)?\n\n\nWhen you start a your containers via \ndocker-compose up\n all of the defined services will start in the foreground. All log output to stdout/stderr within each container will be output the console.  Each entry will be prefixed with the name of the running container to identify the source of the log message.\n\n\nIf log output is not coming directly to the console you can \ndocker exec -it \nname\n /bin/bash\n into the running container and browse the file system for logs. Most common services will provide some log output in \n/var/log\n.\n\n\nWhere do I run a build?\n\n\nYou should run a build from within the build tools container for your project.  Look at the example \ndrupal8/build.yml\n file to see the various way you can configure build containers for your environment.  That docker-compose file contains instructions on how you could use each of those containers for executing build commands on your codebase.\n\n\nHow do I share the output from my build container with my web container?\n\n\nFirst have your build container define a volume to mount your project code into the container, then when you perform a build it will write the output to you local project. Then if your web container defines a volume to mount the build output into the docroot you will have seamless integration of build output to web container running the site.\n\n\nHow do I configure my web container so I can run multiple projects at once from the same container?\n\n\nYou don\u2019t. Seriously. This is a place where you must change your thinking from that of treating a \nserver\n as a unit to treating the \nservice\n as a unit. If you have multiple projects active at once, you\u2019ll have a web serving container active for each of them. This is ok because containers are much lighter weight than full virtual machines, though you do want to be careful about starting too many at once.  Consider that you will have a docker-compose file for each project you are working on, and each docker-compose file represents your application and all the services required to run it.  You could be running multiple docker-compose applications on a single Docker Host.  Realistically, for the performance of your computer you would stop one docker-compose environment before you would run another.\n\n\nHow do I debug or get a shell into my application?\n\n\nThe way to run a command in a container is: \ndocker-compose run \ncontainer name\n \ncommand\n. For example, to get a shell into your web container you might run \ndocker-compose run web /bin/bash\n \n\n\nTo run a series of commands, you must wrap them in a single command using a shell. For example: \ndocker-compose run \nname in yml\n sh -c '\ncommand 1\n \n \ncommand 2\n \n \ncommand 3\n'\n\n\nIn some cases you may want to run a container that is not defined by a docker-compose.yml file, for example to test a new container configuration. Use docker run to start a new container with a given image: \ndocker run -it \nimage name\n \ncommand\n\n\nThe docker run command accepts command line options to specify volume mounts, environment variables, the working directory, and more. \n\n\nHow do I connect to an existing container that is already running\n\n\nThere is also a docker exec command that can be used to connect to a container that is already running.  \n\n\n\n\n\n\nUse \ndocker ps\n to get the name of the existing container\n\n\n\n\n\n\nUse the command \ndocker exec -it \ncontainer name\n /bin/bash\n to get a bash shell in the container\n\n\n\n\n\n\nGenerically, use \ndocker exec -it \ncontainer name\n \ncommand\n to execute whatever command you specify in the container.\n\n\n\n\n\n\nHow do I see what containers are running on my Docker Host?\n\n\nIf you want to see how many containers are present within your Docker Host VM and check on the status of them just run \ndocker ps\n This will show you the containers running, the image they are based on, the ports they expose and the name of the container.\n\n\nTo see all the containers on the Docker Host both running and stopped use the command  \ndocker ps -a\n\n\nWhy do I have so many containers / cleanup?\n\n\nAny time you finish a project or you need to \"reset\" things, you should clean up your containers for a project by running \ndocker-compose rm\n. That will remove the instances for the containers specified in your docker compose file.\n\n\nAdditionally you can run \ndevtools prune\n to clear out all stopped containers and any dangling images.\n\n\nPerformance monitoring of containers\n\n\nIf you need some insight into how many resources a given Docker container may be using, take advantage of the command \ndocker stats \ncontainer name\n.  This handy command will show you CPU%, Memory%, Memory Usage vs Limit, and Network I/O.  It is rudimentary but can be very useful in the first line of inspection on a container.\n\n\nI previously used boot2docker instead of this docker-machine. What's the difference?\n\n\nDevTools still uses the boot2docker \nvirtual machine\n. The \"boot2docker CLI\" has been phased out in favor of docker-machine. docker-machine still uses the boot2docker linux distribution. docker-machine spins up a vm named \ndev\n in Virtualbox or VMWare Fusion, whereas boot2docker previously spun up a vm named \nboot2docker\n. \n\n\nCan I get .vm addresses working with an existing Docker machine?\n\n\nYes, with an important caveat that containers will not be able to resolve .vm addresses without reconfiguring the daemon.\n\n\nAs of v0.3.0 a \ndevtools dns\n command has been added. It can accept a \n--name\n parameter to run on an existing docker-machine virtual machine.\n\n\nWhen we start a machine with \ndevtools start\n, we do the following things:\n\n\n\n\nStart a machine with the \n-dns=172.17.0.1\n Docker daemon option set so that all containers will try dnsdock for DNS\n\n\nRun dnsdock bound to \n172.17.0.1:53\n to provide .vm addresses for all containers\n\n\nSet up Mac OS X to route 172.17.0.1/16 to the Docker virtual machine's IP so the host machine can access containers direct\n\n\nSet up \n/etc/resolver/vm\n so that OS X will look up .vm addresses through DNS queries to \n172.17.0.1\n\n\n\n\nIf you run \ndevtools dns --name=$DOCKER_MACHINE_NAME\n, every step except the first will run, so your OS X host will be able to reach containers by their .vm addresses but other containers will not. This is the major difference between creating a machine with \ndevtools start\n and applying the DNS configuration to an existing machine with \ndevtools dns\n.",
            "title": "FAQ"
        },
        {
            "location": "/60_FAQ/#faqs",
            "text": "",
            "title": "FAQs"
        },
        {
            "location": "/60_FAQ/#viewing-logs-from-my-container-services",
            "text": "When you start a your containers via  docker-compose up  all of the defined services will start in the foreground. All log output to stdout/stderr within each container will be output the console.  Each entry will be prefixed with the name of the running container to identify the source of the log message.  If log output is not coming directly to the console you can  docker exec -it  name  /bin/bash  into the running container and browse the file system for logs. Most common services will provide some log output in  /var/log .",
            "title": "Viewing logs from my container service(s)?"
        },
        {
            "location": "/60_FAQ/#where-do-i-run-a-build",
            "text": "You should run a build from within the build tools container for your project.  Look at the example  drupal8/build.yml  file to see the various way you can configure build containers for your environment.  That docker-compose file contains instructions on how you could use each of those containers for executing build commands on your codebase.",
            "title": "Where do I run a build?"
        },
        {
            "location": "/60_FAQ/#how-do-i-share-the-output-from-my-build-container-with-my-web-container",
            "text": "First have your build container define a volume to mount your project code into the container, then when you perform a build it will write the output to you local project. Then if your web container defines a volume to mount the build output into the docroot you will have seamless integration of build output to web container running the site.",
            "title": "How do I share the output from my build container with my web container?"
        },
        {
            "location": "/60_FAQ/#how-do-i-configure-my-web-container-so-i-can-run-multiple-projects-at-once-from-the-same-container",
            "text": "You don\u2019t. Seriously. This is a place where you must change your thinking from that of treating a  server  as a unit to treating the  service  as a unit. If you have multiple projects active at once, you\u2019ll have a web serving container active for each of them. This is ok because containers are much lighter weight than full virtual machines, though you do want to be careful about starting too many at once.  Consider that you will have a docker-compose file for each project you are working on, and each docker-compose file represents your application and all the services required to run it.  You could be running multiple docker-compose applications on a single Docker Host.  Realistically, for the performance of your computer you would stop one docker-compose environment before you would run another.",
            "title": "How do I configure my web container so I can run multiple projects at once from the same container?"
        },
        {
            "location": "/60_FAQ/#how-do-i-debug-or-get-a-shell-into-my-application",
            "text": "The way to run a command in a container is:  docker-compose run  container name   command . For example, to get a shell into your web container you might run  docker-compose run web /bin/bash    To run a series of commands, you must wrap them in a single command using a shell. For example:  docker-compose run  name in yml  sh -c ' command 1     command 2     command 3 '  In some cases you may want to run a container that is not defined by a docker-compose.yml file, for example to test a new container configuration. Use docker run to start a new container with a given image:  docker run -it  image name   command  The docker run command accepts command line options to specify volume mounts, environment variables, the working directory, and more.",
            "title": "How do I debug or get a shell into my application?"
        },
        {
            "location": "/60_FAQ/#how-do-i-connect-to-an-existing-container-that-is-already-running",
            "text": "There is also a docker exec command that can be used to connect to a container that is already running.      Use  docker ps  to get the name of the existing container    Use the command  docker exec -it  container name  /bin/bash  to get a bash shell in the container    Generically, use  docker exec -it  container name   command  to execute whatever command you specify in the container.",
            "title": "How do I connect to an existing container that is already running"
        },
        {
            "location": "/60_FAQ/#how-do-i-see-what-containers-are-running-on-my-docker-host",
            "text": "If you want to see how many containers are present within your Docker Host VM and check on the status of them just run  docker ps  This will show you the containers running, the image they are based on, the ports they expose and the name of the container.  To see all the containers on the Docker Host both running and stopped use the command   docker ps -a",
            "title": "How do I see what containers are running on my Docker Host?"
        },
        {
            "location": "/60_FAQ/#why-do-i-have-so-many-containers-cleanup",
            "text": "Any time you finish a project or you need to \"reset\" things, you should clean up your containers for a project by running  docker-compose rm . That will remove the instances for the containers specified in your docker compose file.  Additionally you can run  devtools prune  to clear out all stopped containers and any dangling images.",
            "title": "Why do I have so many containers / cleanup?"
        },
        {
            "location": "/60_FAQ/#performance-monitoring-of-containers",
            "text": "If you need some insight into how many resources a given Docker container may be using, take advantage of the command  docker stats  container name .  This handy command will show you CPU%, Memory%, Memory Usage vs Limit, and Network I/O.  It is rudimentary but can be very useful in the first line of inspection on a container.",
            "title": "Performance monitoring of containers"
        },
        {
            "location": "/60_FAQ/#i-previously-used-boot2docker-instead-of-this-docker-machine-whats-the-difference",
            "text": "DevTools still uses the boot2docker  virtual machine . The \"boot2docker CLI\" has been phased out in favor of docker-machine. docker-machine still uses the boot2docker linux distribution. docker-machine spins up a vm named  dev  in Virtualbox or VMWare Fusion, whereas boot2docker previously spun up a vm named  boot2docker .",
            "title": "I previously used boot2docker instead of this docker-machine. What's the difference?"
        },
        {
            "location": "/60_FAQ/#can-i-get-vm-addresses-working-with-an-existing-docker-machine",
            "text": "Yes, with an important caveat that containers will not be able to resolve .vm addresses without reconfiguring the daemon.  As of v0.3.0 a  devtools dns  command has been added. It can accept a  --name  parameter to run on an existing docker-machine virtual machine.  When we start a machine with  devtools start , we do the following things:   Start a machine with the  -dns=172.17.0.1  Docker daemon option set so that all containers will try dnsdock for DNS  Run dnsdock bound to  172.17.0.1:53  to provide .vm addresses for all containers  Set up Mac OS X to route 172.17.0.1/16 to the Docker virtual machine's IP so the host machine can access containers direct  Set up  /etc/resolver/vm  so that OS X will look up .vm addresses through DNS queries to  172.17.0.1   If you run  devtools dns --name=$DOCKER_MACHINE_NAME , every step except the first will run, so your OS X host will be able to reach containers by their .vm addresses but other containers will not. This is the major difference between creating a machine with  devtools start  and applying the DNS configuration to an existing machine with  devtools dns .",
            "title": "Can I get .vm addresses working with an existing Docker machine?"
        },
        {
            "location": "/99_LINUX/",
            "text": "Phase2 DevTools VM for Linux\n\n\nWhen running Docker containers on Linux, it is not necessary to run the Docker Machine VM. The instructions here describe how to run DevTools projects on Linux.\n\n\nLinux requirements\n\n\n\n\nThe phase2/dnsdock container, used to support automatic creation and maintenance of DNS namespace for the containers\n\n\nThis is a public container that is only about 12M; you may freely pull it\n\n\n\n\n\n\nUse of one of three options to forward DNS queries to the dnsdock container (see \nLinux DNS configuration options\n below\n\n\n\n\nLinux installation on Fedora 22+\n\n\n\n\nInstall Docker 1.9.1 and docker-compose\n\n\nsudo dnf install docker docker-compose\n\n\n\n\n\n\nAdd your user to the Docker group\n\n\nsudo usermod -aG docker $USER\n\n\n\n\n\n\nLog out, then back in, in order to pick up your new group assignments\n\n\nSet the DNS configuration for dnsdock, as well as known RFC-1918 address space\n\n\nPlease note that the following command will over-write your existing Docker daemon configuration file.  Please set the -dns=172.17.0.1 option manually as an alternative\n\n\necho 'OPTIONS=-dns=172.17.0.1' | sudo tee /etc/sysconfig/docker\n\n\n\n\n\n\nSet up the docker0 network as trusted\n\n\nsudo firewall-cmd --zone=trusted --add-interface=docker0 \n sudo firewall-cmd --zone=trusted --add-interface=docker0 --permanent\n\n\n\n\n\n\nStart the docker daemon\n\n\nsudo systemctl start docker\n\n\n\n\n\n\n\n\nLinux installation on Ubuntu/Linux Mint/Debian\n\n\n\n\nInstall Docker 1.9.1\n\n\ncurl -sSL https://get.docker.com/ | sh\n\n\n\n\n\n\nInstall Pip\n\n\nsudo apt-get install python-pip\n\n\n\n\n\n\nInstall docker-compose\n\n\nsudo pip install docker-compose\n\n\n\n\n\n\nAdd your user to the Docker group\n\n\nsudo usermod -aG docker $USER\n\n\n\n\n\n\nLog out, then back in, in order to pick up your new group assignments\n\n\nSet the DNS configuration for dnsdock, as well as known RFC-1918 address space\n\n\nPlease note that the following command will over-write your existing Docker daemon configuration file.  Please set the -dns=172.17.0.1 option manually as an alternative\n\n\necho 'OPTIONS=-dns=172.17.0.1' | sudo tee /etc/default/docker\n\n\n\n\n\n\nStart the docker daemon\n\n\nsudo start docker\n\n\n\n\n\n\n\n\nLinux DNS configuration options\n\n\nMethod 1: dnsmasq via NetworkManager\n\n\nThis method works well with no other needed software provided that you have unfettered access to your system's configuration, and are using NetworkManager to maintain your networking stack\n\n\n\n\nAdd the line dns=dnsmasq to /etc/NetworkManager/NetworkManager.conf under the [main] configuration stanza. This will cause NetworkManager to spawn and use a dnsmasq process for all name resolution.\nIf you already have a local configuration, ensure that it is not configured to start on system boot.\n\n\nAdd a single rule to direct all DNS lookups for .vm addresses to the 172.17.0.1 address.\n\n\necho 'server=/vm/172.17.0.1' | sudo tee /etc/NetworkManager/dnsmasq.d/dnsdock.conf\n\n\n\n\n\n\nRestart NetworkManager, either through systemd, or by simply rebooting.  To restart via systemd:\n\n\nsystemctl restart NetworkManager\n\n\n\n\n\n\nRun the dnsdock container\n\n\ndocker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock phase2/dnsdock\n\n\nNote\n: if you want this container to run automatically when the docker daemon starts, add the \n--restart=always\n flag to the above command.\n\n\n\n\n\n\n\n\nMethod 2: dnsdock as main resolver\n\n\nThis method will probably only work well if this is a fixed computer or server with a consistent single upstream DNS server. If you meet these criteria, you can very easily use this to set up .vm resolution for containers an delegate the rest to your normal DNS server.\n\n\nThis example assumes that the upstream DNS server for a Linux workstation is 192.168.0.1.\n\n\n\n\n\n\nRun the dnsdock container, specifying your upstream DNS server at the end.\n\n\n\n\ndocker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock phase2/dnsdock /opt/bin/dnsdock -domain=vm -nameserver='192.168.0.1:53'\n\n\nNote\n: if you want this container to run automatically when the docker daemon starts, add the \n--restart=always\n flag to the above command.\n\n\n\n\n\n\n\n\nConfigure 172.17.0.1 as your first DNS resolver in your network configuration. The method for doing this may differ based on whether you are using a desktop environment or running Linux on a server, but that nameserver should end up as the first 'nameserver' line in your /etc/resolv.conf file.\n\n\n\n\n\n\nMethod 3: libnss-resolver\n\n\nlibnss-resolver is an app that adds Mac-style /etc/resolver/$FQDN files to the Linux NSS resolution stack to query a different DNS server for any .vm address.  It may be the easiest option for most installations.\n\n\nThere are releases for Fedora 20, Ubuntu 12.04 and Ubuntu 14.04.\n\n\n\n\nInstall libnss-resolver from https://github.com/azukiapp/libnss-resolver/releases\n\n\nSet up .vm hostname resolution\n\n\necho 'nameserver 172.17.0.1:53' | sudo tee /etc/resolver/vm\n\n\n\n\n\n\nRun the dnsdock container\n\n\ndocker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock phase2/dnsdock\n\n\nNote\n: if you want this container to run automatically when the docker daemon starts, add the \n--restart=always\n flag to the above command.\n\n\n\n\n\n\n\n\nDNS resolution tests\n\n\nOnce you have your environment set up, you can use the following tests to ensure things are running properly.\n\n\n\n\ndig @172.17.0.1 dnsdock.devtools.vm.\n\n\nYou should get a 172.17.0.0/16 address.\n\n\n\n\n\n\nping dnsdock.devtools.vm\n\n\nYou should get echo replies from a 172.17.0.0/16 address.\n\n\n\n\n\n\ngetent hosts dnsdock.devtools.vm\n\n\nYou should get a 172.17.0.0/16 address.",
            "title": "LINUX"
        },
        {
            "location": "/99_LINUX/#phase2-devtools-vm-for-linux",
            "text": "When running Docker containers on Linux, it is not necessary to run the Docker Machine VM. The instructions here describe how to run DevTools projects on Linux.",
            "title": "Phase2 DevTools VM for Linux"
        },
        {
            "location": "/99_LINUX/#linux-requirements",
            "text": "The phase2/dnsdock container, used to support automatic creation and maintenance of DNS namespace for the containers  This is a public container that is only about 12M; you may freely pull it    Use of one of three options to forward DNS queries to the dnsdock container (see  Linux DNS configuration options  below",
            "title": "Linux requirements"
        },
        {
            "location": "/99_LINUX/#linux-installation-on-fedora-22",
            "text": "Install Docker 1.9.1 and docker-compose  sudo dnf install docker docker-compose    Add your user to the Docker group  sudo usermod -aG docker $USER    Log out, then back in, in order to pick up your new group assignments  Set the DNS configuration for dnsdock, as well as known RFC-1918 address space  Please note that the following command will over-write your existing Docker daemon configuration file.  Please set the -dns=172.17.0.1 option manually as an alternative  echo 'OPTIONS=-dns=172.17.0.1' | sudo tee /etc/sysconfig/docker    Set up the docker0 network as trusted  sudo firewall-cmd --zone=trusted --add-interface=docker0   sudo firewall-cmd --zone=trusted --add-interface=docker0 --permanent    Start the docker daemon  sudo systemctl start docker",
            "title": "Linux installation on Fedora 22+"
        },
        {
            "location": "/99_LINUX/#linux-installation-on-ubuntulinux-mintdebian",
            "text": "Install Docker 1.9.1  curl -sSL https://get.docker.com/ | sh    Install Pip  sudo apt-get install python-pip    Install docker-compose  sudo pip install docker-compose    Add your user to the Docker group  sudo usermod -aG docker $USER    Log out, then back in, in order to pick up your new group assignments  Set the DNS configuration for dnsdock, as well as known RFC-1918 address space  Please note that the following command will over-write your existing Docker daemon configuration file.  Please set the -dns=172.17.0.1 option manually as an alternative  echo 'OPTIONS=-dns=172.17.0.1' | sudo tee /etc/default/docker    Start the docker daemon  sudo start docker",
            "title": "Linux installation on Ubuntu/Linux Mint/Debian"
        },
        {
            "location": "/99_LINUX/#linux-dns-configuration-options",
            "text": "",
            "title": "Linux DNS configuration options"
        },
        {
            "location": "/99_LINUX/#method-1-dnsmasq-via-networkmanager",
            "text": "This method works well with no other needed software provided that you have unfettered access to your system's configuration, and are using NetworkManager to maintain your networking stack   Add the line dns=dnsmasq to /etc/NetworkManager/NetworkManager.conf under the [main] configuration stanza. This will cause NetworkManager to spawn and use a dnsmasq process for all name resolution.\nIf you already have a local configuration, ensure that it is not configured to start on system boot.  Add a single rule to direct all DNS lookups for .vm addresses to the 172.17.0.1 address.  echo 'server=/vm/172.17.0.1' | sudo tee /etc/NetworkManager/dnsmasq.d/dnsdock.conf    Restart NetworkManager, either through systemd, or by simply rebooting.  To restart via systemd:  systemctl restart NetworkManager    Run the dnsdock container  docker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock phase2/dnsdock  Note : if you want this container to run automatically when the docker daemon starts, add the  --restart=always  flag to the above command.",
            "title": "Method 1: dnsmasq via NetworkManager"
        },
        {
            "location": "/99_LINUX/#method-2-dnsdock-as-main-resolver",
            "text": "This method will probably only work well if this is a fixed computer or server with a consistent single upstream DNS server. If you meet these criteria, you can very easily use this to set up .vm resolution for containers an delegate the rest to your normal DNS server.  This example assumes that the upstream DNS server for a Linux workstation is 192.168.0.1.    Run the dnsdock container, specifying your upstream DNS server at the end.   docker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock phase2/dnsdock /opt/bin/dnsdock -domain=vm -nameserver='192.168.0.1:53'  Note : if you want this container to run automatically when the docker daemon starts, add the  --restart=always  flag to the above command.     Configure 172.17.0.1 as your first DNS resolver in your network configuration. The method for doing this may differ based on whether you are using a desktop environment or running Linux on a server, but that nameserver should end up as the first 'nameserver' line in your /etc/resolv.conf file.",
            "title": "Method 2: dnsdock as main resolver"
        },
        {
            "location": "/99_LINUX/#method-3-libnss-resolver",
            "text": "libnss-resolver is an app that adds Mac-style /etc/resolver/$FQDN files to the Linux NSS resolution stack to query a different DNS server for any .vm address.  It may be the easiest option for most installations.  There are releases for Fedora 20, Ubuntu 12.04 and Ubuntu 14.04.   Install libnss-resolver from https://github.com/azukiapp/libnss-resolver/releases  Set up .vm hostname resolution  echo 'nameserver 172.17.0.1:53' | sudo tee /etc/resolver/vm    Run the dnsdock container  docker run -d --name=dnsdock -e DNSDOCK_NAME=dnsdock -e DNSDOCK_IMAGE=devtools -p 172.17.0.1:53:53/udp -v /var/run/docker.sock:/var/run/docker.sock phase2/dnsdock  Note : if you want this container to run automatically when the docker daemon starts, add the  --restart=always  flag to the above command.",
            "title": "Method 3: libnss-resolver"
        },
        {
            "location": "/99_LINUX/#dns-resolution-tests",
            "text": "Once you have your environment set up, you can use the following tests to ensure things are running properly.   dig @172.17.0.1 dnsdock.devtools.vm.  You should get a 172.17.0.0/16 address.    ping dnsdock.devtools.vm  You should get echo replies from a 172.17.0.0/16 address.    getent hosts dnsdock.devtools.vm  You should get a 172.17.0.0/16 address.",
            "title": "DNS resolution tests"
        }
    ]
}